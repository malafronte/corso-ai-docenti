---
title: Uso responsabile, etica e sicurezza dell'AI a scuola
description: Intelligenza Artificiale a scuola - Guida per un uso responsabile, etico e sicuro
---

## Introduzione

L'avvento dell'Intelligenza Artificiale (AI) sta segnando una trasformazione epocale in ogni settore della società e il mondo dell'istruzione non fa eccezione. Da strumento di supporto per la personalizzazione didattica a risorsa per l'ottimizzazione dei processi amministrativi, le potenzialità dell'AI per la scuola sono tanto vaste quanto entusiasmanti. Tuttavia, come ogni grande innovazione tecnologica, essa porta con sé interrogativi complessi e sfide significative che non possono essere ignorate. Accanto alle straordinarie opportunità, emergono questioni cruciali in termini di etica, sicurezza dei dati, equità e responsabilità.

La scuola, in quanto agenzia educativa fondamentale per la formazione dei cittadini di domani, ha il dovere di affrontare questa transizione non in modo passivo o reattivo, ma con un approccio proattivo, critico e governato. Non si tratta semplicemente di "usare" l'AI, ma di integrarla in modo consapevole, allineandola con i principi pedagogici, i valori costituzionali e il quadro normativo che regola il sistema di istruzione.

Questo articolo si propone come una guida esaustiva per i docenti della scuola secondaria di secondo grado, con l'obiettivo di fornire un quadro completo per navigare le complessità dell'AI nella didattica. La nostra analisi si fonderà su due pilastri fondamentali. Da un lato, esamineremo il quadro normativo europeo, con particolare riferimento al Regolamento sull'Intelligenza Artificiale (noto come **AI Act**)[^1], che stabilisce le regole per un'AI affidabile e antropocentrica. Dall'altro, ci avvarremo di un modello pratico e concreto di policy scolastica, il **"Documento di Indirizzo Strategico per l'Integrazione dell'Intelligenza Artificiale"** dell'Istituto Greppi (d'ora in poi "Documento di Indirizzo")[^2], che traduce i principi normativi in azioni operative per la comunità scolastica.

Attraverso un percorso strutturato in capitoli, affronteremo la normativa di riferimento, le strategie didattiche per promuovere l'onestà accademica nell'era dell'AI generativa, il processo di costruzione di una policy d'istituto e le profonde implicazioni etiche legate ai bias algoritmici e alla responsabilità umana. L'obiettivo finale è quello di equipaggiare ogni docente, a prescindere dalla disciplina di insegnamento, con le conoscenze e gli strumenti necessari per diventare un attore protagonista di un'innovazione responsabile, sicura e realmente al servizio della crescita di ogni studente.

## Capitolo 1: Il quadro normativo di riferimento per la scuola

L'integrazione dell'Intelligenza Artificiale nel contesto scolastico non può prescindere da una solida comprensione del quadro giuridico che ne regola l'utilizzo. La scuola, in quanto pubblica amministrazione che tratta dati particolarmente sensibili di soggetti vulnerabili come i minori, è chiamata a un rigore normativo ancora maggiore. Le due colonne portanti di questo quadro sono il Regolamento Generale sulla Protezione dei Dati (GDPR)[^3] e, più specificamente per il nostro ambito, il nuovo Regolamento europeo sull'Intelligenza Artificiale (AI Act)[^1].

### 1.1 L'AI Act Europeo: la bussola per la didattica

L'AI Act[^1] rappresenta la prima legislazione orizzontale al mondo sull'AI e stabilisce un modello per la sua governance basato su un approccio stratificato in base al rischio (*risk-based approach*). Come evidenziato nel "Documento di Indirizzo"[^2], lo scopo del regolamento è "promuovere la diffusione di un'intelligenza artificiale (AI) antropocentrica e affidabile, garantendo nel contempo un livello elevato di protezione della salute, della sicurezza e dei diritti fondamentali". Per la scuola, questo si traduce in un obbligo non solo di cogliere le opportunità, ma anche di governare i rischi. L'AI Act[^1] classifica i sistemi di AI in diverse categorie, ognuna con obblighi specifici.

#### Pratiche di AI vietate (Articolo 5)

L'articolo 5 dell'AI Act[^1] elenca una serie di pratiche considerate inaccettabili perché contrarie ai valori fondamentali dell'Unione Europea. Per il contesto scolastico, è essenziale comprendere e interdire categoricamente l'uso di sistemi che:

- **Utilizzano tecniche subliminali o manipolative:** È vietato l'uso di sistemi che distorcono il comportamento degli individui in modo da causare un danno fisico o psicologico significativo. Questo principio protegge l'autonomia di giudizio e la vulnerabilità psicologica degli studenti da tecnologie che potrebbero influenzarli senza che ne siano consapevoli.

- **Sfruttano le vulnerabilità di gruppi specifici:** La normativa vieta esplicitamente l'uso di AI che sfrutti le vulnerabilità legate a età, disabilità o situazione socio-economica per alterare il comportamento in modo dannoso. La popolazione studentesca, in particolare i minori, rientra a pieno titolo in questa categoria di protezione speciale.

- **Effettuano "punteggio sociale" (social scoring):** È proibito l'uso di sistemi di AI da parte di autorità pubbliche (come la scuola) per classificare l'affidabilità delle persone sulla base del loro comportamento sociale o delle loro caratteristiche personali, qualora ciò porti a un trattamento pregiudizievole o sproporzionato. Il principio di non classificazione aprioristica delle persone è un caposaldo etico da applicare rigorosamente in ambito educativo.

- **Inferiscono le emozioni in contesti educativi:** Di cruciale e diretta applicazione per la scuola è il divieto, sancito dall'art. 5 dell'AI Act[^1], di utilizzare sistemi di AI "per inferire le emozioni di una persona fisica nell'ambito degli istituti di istruzione", salvo per motivi medici o di sicurezza. Ciò significa che è illegale l'uso di software che pretendano di analizzare l'espressione facciale o il tono della voce di uno studente durante una lezione o una verifica per valutarne il livello di attenzione, la comprensione o la sincerità. L'eccezione per motivi di sicurezza deve essere interpretata in modo estremamente restrittivo e sempre sotto supervisione umana qualificata.

#### Sistemi di AI ad alto rischio (Articolo 6 e Allegato III)

Questa è la categoria di maggior impatto per le istituzioni scolastiche. Un sistema di AI è classificato come "ad alto rischio" quando il suo utilizzo può avere un impatto significativo sui diritti fondamentali e sulla sicurezza delle persone. L'Allegato III dell'AI Act[^1] identifica esplicitamente i sistemi utilizzati nel settore **"Istruzione e formazione professionale"** come potenzialmente ad alto rischio. Nello specifico, rientrano in questa categoria i sistemi destinati a:

- **Determinare l'accesso o l'ammissione a istituti di istruzione:** Ad esempio, un software che selezioni automaticamente le candidature per un corso a numero chiuso o che assegni gli studenti alle classi sulla base di determinati parametri.

- **Valutare i risultati dell'apprendimento:** Rientrano in questa definizione i sistemi di correzione automatizzata di compiti, test o esami che abbiano un impatto determinante sulla valutazione finale dello studente e, di conseguenza, sul suo percorso formativo. L'uso di un software per correggere un quiz a scelta multipla a scopo formativo può essere a basso rischio, ma se lo stesso software è usato per un esame finale, il sistema diventa ad alto rischio.

- **Monitorare e rilevare comportamenti vietati durante le prove:** I software di *proctoring* che utilizzano l'AI per monitorare gli studenti durante gli esami a distanza (analizzando suoni, movimenti o sguardi) sono un esempio lampante di sistemi ad alto rischio.

L'adozione di un sistema ad alto rischio impone alla scuola, in qualità di "utilizzatore" (*deployer*), una serie di obblighi stringenti. Come sottolinea il "Documento di Indirizzo"[^2], questi includono la necessità di garantire una **sorveglianza umana efficace** (art. 14 dell'AI Act[^1]), utilizzare i sistemi secondo le istruzioni del fornitore, monitorarne il funzionamento e, aspetto fondamentale, condurre una **Valutazione d'impatto sui diritti fondamentali (FRIA)** prima di mettere in uso il sistema (art. 27 dell'AI Act[^1]). **La responsabilità della scuola non è solo tecnica, ma anche etica e giuridica**.

##### FRIA[^5] - Fundamental Rights Impact Assessment

Una Valutazione d'Impatto sui Diritti Fondamentali (FRIA)[^5] è un'analisi strutturata richiesta per i sistemi di Intelligenza Artificiale ad alto rischio nell'ambito dell'AI Act. Lo scopo della FRIA è identificare, valutare e mitigare i potenziali effetti negativi che un sistema di AI potrebbe avere sui diritti fondamentali delle persone.

- **Scopo**: La FRIA è una misura proattiva che mira a mettere i diritti umani al centro dello sviluppo dell'AI. Cerca di bilanciare l'innovazione tecnologica con l'uso etico e responsabile dell'AI.
- **Ambito di applicazione**: A differenza di una Valutazione d'Impatto sulla Protezione dei Dati (DPIA) ai sensi del GDPR, che si concentra principalmente sulla privacy dei dati, una FRIA ha un ambito molto più ampio. Copre un'intera gamma di diritti delineati nella Carta dei diritti fondamentali dell'UE, tra cui la libertà di espressione, il diritto al lavoro, la non discriminazione e altro ancora.
- **Evento scatenante**: Una FRIA deve essere condotta dal "deployer" (l'entità che utilizza il sistema di AI) prima che un sistema di AI ad alto rischio venga messo in uso.
- **Entità coinvolte**: L'obbligo di condurre una FRIA si applica agli enti pubblici e alle entità private che forniscono servizi pubblici e che utilizzano sistemi di AI ad alto rischio.

**Componenti chiave di una FRIA:**

Secondo l'AI Act dell'UE, una FRIA dovrebbe includere i seguenti elementi:

- **Uso previsto**: Una chiara descrizione dello scopo previsto del sistema di AI.
- **Ambito di utilizzo**: L'ambito geografico e temporale previsto per l'implementazione del sistema.
- **Persone interessate**: Un'identificazione delle persone e dei gruppi che potrebbero essere interessati dal sistema.
- **Conformità legale**: Verifica che l'uso del sistema sia conforme alle leggi pertinenti dell'UE e nazionali sui diritti fondamentali.
- **Impatto prevedibile**: Una valutazione dell'impatto ragionevolmente prevedibile sui diritti fondamentali.
- **Gruppi vulnerabili**: Identificazione di rischi specifici di danni che possono colpire persone emarginate o vulnerabili.
- **Impatto ambientale**: L'impatto ambientale negativo ragionevolmente prevedibile del sistema.
- **Piano di mitigazione**: Una strategia dettagliata per mitigare i danni e gli impatti negativi identificati.
- **Governance**: Un piano per la governance del sistema, comprese le misure per la supervisione umana, la gestione dei reclami e il ricorso.

**Esempio di applicazione di una FRIA:**

Un esempio potenziale di un sistema di AI ad alto rischio che richiede una FRIA potrebbe essere un sistema di reclutamento basato sull'AI. La FRIA valuterebbe il rischio che il sistema escluda candidati in base all'etnia o al sesso, violando così il diritto fondamentale alla non discriminazione. La valutazione identificherebbe e pianificherebbe la mitigazione di tali pregiudizi prima che il sistema venga implementato.

#### Sistemi a rischio limitato (Articolo 50)

Questi sistemi sono soggetti a obblighi di trasparenza, come definito nell'articolo 50 dell'AI Act[^1]. Chi interagisce con essi deve essere sempre consapevole di avere a che fare con una macchina. Nel contesto scolastico, gli esempi più comuni sono:

- **Chatbot per l'orientamento o il supporto didattico:** Gli studenti devono essere chiaramente informati che stanno dialogando con un sistema di AI e non con un essere umano.

- **Sistemi che generano contenuti (deepfake):** Se un docente utilizza un sistema di AI per creare un video didattico con un avatar, un'immagine per una presentazione o un testo da analizzare, deve essere chiaramente indicato che il contenuto è stato generato o manipolato artificialmente.

### 1.2 I Principi del GDPR nell'Era dell'AI

**Ogni volta che un sistema di AI tratta dati personali il suo utilizzo deve essere pienamente conforme al GDPR[^3]**. Il "Documento di Indirizzo"[^2], nel suo paragrafo 1.2.2, fornisce un vademecum operativo essenziale per la scuola, che agisce come Titolare del Trattamento.

#### La base giuridica: il compito di interesse pubblico

Il trattamento di dati personali è lecito solo se si fonda su una delle sei basi giuridiche previste dall'articolo 6 del GDPR[^3]. Per un'istituzione scolastica pubblica, la base giuridica preminente è l'**esecuzione di un compito di interesse pubblico** (art. 6, par. 1, lett. e del GDPR[^3]). L'interesse pubblico perseguito dalla scuola è la sua missione istituzionale: l'istruzione, l'educazione e la formazione degli studenti. Pertanto, qualsiasi trattamento di dati tramite AI deve essere strettamente **necessario e proporzionato** al raggiungimento di finalità educative, didattiche o amministrative.

È fondamentale, come evidenziato nel "Documento di Indirizzo"[^2], **evitare di fare affidamento sul consenso** come base giuridica per i trattamenti essenziali. A causa del chiaro squilibrio di potere tra la scuola e l'interessato (studente/famiglia), il consenso difficilmente potrebbe essere considerato "liberamente prestato". Può essere utilizzato solo per attività puramente facoltative e non essenziali (es. la partecipazione a un progetto extracurricolare che fa uso di AI).

#### L'obbligatorietà della Valutazione di Impatto (DPIA e FRIA)

Come indicato nelle Linee Guida del Ministero dell'Istruzione e del Merito[^4] e ribadito nel "Documento di Indirizzo"[^2], l'uso di sistemi di AI in ambito scolastico rende quasi sempre **obbligatoria una Valutazione di Impatto sulla Protezione dei Dati (DPIA)** ai sensi dell'art. 35 del GDPR[^3]. Si tratta infatti di un "uso di nuove tecnologie" applicato su "larga scala" a dati di "soggetti vulnerabili", tre condizioni che attivano l'obbligo di DPIA.

##### DPIA[^6] - Valutazione di Impatto sulla Protezione dei Dati

La Valutazione di Impatto sulla Protezione dei Dati (DPIA)[^6], dall'inglese *Data Protection Impact Assessment*, è una procedura che identifica, valuta e gestisce i rischi per i diritti e le libertà delle persone fisiche derivanti dai trattamenti di dati personali. È prevista dall'articolo 35 del Regolamento Generale sulla Protezione dei Dati (GDPR) dell'Unione Europea.

**Scopo della DPIA:**

Lo scopo principale della DPIA è consentire al titolare del trattamento dati di dimostrare la conformità al GDPR e di attuare misure adeguate per affrontare i rischi rilevati. Funziona come uno strumento di responsabilizzazione (*accountability*). 

**Quando è obbligatoria la DPIA:**

La DPIA è obbligatoria quando un trattamento di dati presenta un **rischio elevato** per i diritti e le libertà delle persone. In particolare, il GDPR ne prevede l'obbligo in tre situazioni principali:

1. **Valutazione sistematica e su larga scala** di aspetti personali relativi a persone fisiche, come la profilazione automatizzata.
2. **Trattamento su larga scala** di categorie particolari di dati (dati sensibili) o dati relativi a condanne penali e reati.
3. **Sorveglianza sistematica su larga scala** di un'area accessibile al pubblico.

Il titolare del trattamento deve sempre valutare, in base alla natura, all'ambito, al contesto e alle finalità del trattamento, se sia necessario effettuare una DPIA.

**Chi la conduce e in che momento:**

- **Responsabilità**: La responsabilità finale di condurre la DPIA ricade sul **titolare del trattamento**.
- **Tempistiche**: La DPIA deve essere svolta **prima** di avviare il trattamento dei dati personali. In questo modo, le misure di sicurezza e le garanzie necessarie possono essere integrate fin dalle fasi iniziali della progettazione (il cosiddetto principio di *Privacy by Design*).

**Contenuto minimo di una DPIA:**

Secondo l'articolo 35 del GDPR, la DPIA deve contenere almeno:

1. **Descrizione del trattamento:** Quali dati vengono trattati? Per quali finalità? Chi vi ha accesso?

2. **Valutazione di necessità e proporzionalità:** L'uso dell'AI è davvero necessario? Esistono alternative meno intrusive per raggiungere lo stesso obiettivo?

3. **Analisi dei rischi per i diritti e le libertà:** Quali sono i potenziali rischi? Ad esempio:

    - **Discriminazione algoritmica (Bias):** Un software di valutazione potrebbe penalizzare studenti con background linguistici non standard.

    - **Violazione della privacy:** Un attacco informatico potrebbe esporre dati accademici e personali sensibili.

    - **Errore di valutazione:** Un sistema di correzione automatica potrebbe non comprendere una risposta corretta ma formulata in modo creativo.

    - **Effetto di sorveglianza (*chilling effect*):** La percezione di essere costantemente monitorati potrebbe inibire la creatività degli studenti.

4. **Individuazione delle misure di mitigazione:** Quali contromisure tecniche (es. pseudonimizzazione, crittografia) e organizzative (es. supervisione umana obbligatoria, formazione dei docenti, procedure di ricorso) verranno adottate?

**Differenza con la FRIA:**

Mentre la DPIA si concentra sulla protezione dei dati personali e sulla privacy, la Valutazione di Impatto sui Diritti Fondamentali (FRIA) è un concetto più ampio, introdotto dall'AI Act, che esamina l'impatto di un sistema di AI su tutti i diritti fondamentali stabiliti dalla Carta dei diritti fondamentali dell'UE, non solo quelli legati ai dati personali. In alcuni casi, come con i sistemi di AI ad alto rischio, la FRIA può essere integrata all'interno della DPIA esistente.

La DPIA non è un mero adempimento burocratico, ma un'analisi sistematica che la scuola deve compiere *prima* di adottare un sistema di AI per comprenderne, valutarne e mitigarne i rischi. La valutazione deve considerare:

Quando un sistema è classificato come "ad alto rischio" dall'AI Act[^1], la DPIA deve essere integrata con gli elementi di una **FRIA (Fundamental Rights Impact Assessment)**, analizzando in modo ancora più approfondito l'impatto sui diritti fondamentali come la dignità umana, la non discriminazione e la libertà di espressione.

##### La Metodologia HUDERIA per la Valutazione dei Rischi dell'AI

Per supportare organizzazioni e istituzioni nella conduzione di valutazioni d'impatto complete e strutturate, il Consiglio d'Europa ha sviluppato la metodologia **HUDERIA** (*Human Dignity, Democracy and the Rule of Law Risk and Impact Assessment*)[^7],[^8]. Questa metodologia rappresenta un framework innovativo e pratico specificamente progettato per la valutazione del rischio e dell'impatto dei sistemi di intelligenza artificiale sui diritti umani e sui principi democratici fondamentali.

**Caratteristiche distintive di HUDERIA:**

- **Approccio olistico centrato sui diritti:** HUDERIA va oltre la semplice conformità normativa, ponendo al centro della valutazione la dignità umana, la democrazia e lo stato di diritto. La metodologia esamina come un sistema di AI possa impattare non solo sui diritti individuali, ma anche sulle istituzioni democratiche e sui processi di partecipazione civica.

- **Framework operativo strutturato:** HUDERIA fornisce un percorso passo-passo per identificare, analizzare e mitigare i rischi connessi all'implementazione di sistemi di AI. Include modelli, checklist e strumenti pratici che guidano l'organizzazione attraverso l'intero processo di valutazione.

- **Integrazione con la normativa europea:** La metodologia è stata progettata per essere complementare ai requisiti dell'AI Act e del GDPR, permettendo alle istituzioni di condurre una valutazione unificata che soddisfi simultaneamente gli obblighi di DPIA e FRIA.

- **Adattabilità al contesto:** Pur fornendo una struttura rigorosa, HUDERIA è sufficientemente flessibile da essere adattata alle specificità di diversi settori, incluso quello educativo, e a sistemi di AI con diversi livelli di rischio.

**Applicazione nel contesto scolastico:**

Per le istituzioni scolastiche che intendono adottare sistemi di AI ad alto rischio, l'utilizzo della metodologia HUDERIA può rappresentare un valore aggiunto significativo. La metodologia aiuta a:

- Identificare in modo sistematico tutti i potenziali impatti sui diritti degli studenti, considerando aspetti come il diritto all'educazione, la non discriminazione, la privacy e lo sviluppo della personalità.

- Valutare l'impatto sui processi democratici interni alla scuola, come la partecipazione degli studenti e delle famiglie alle decisioni che li riguardano.

- Documentare in modo trasparente e verificabile il processo decisionale, dimostrando la dovuta diligenza (*due diligence*) nell'adozione di tecnologie potenzialmente ad alto impatto.

- Coinvolgere in modo strutturato tutte le parti interessate (studenti, docenti, famiglie, DPO) nel processo di valutazione, promuovendo un approccio partecipativo e democratico all'innovazione tecnologica.

L'adozione di HUDERIA, pur non essendo obbligatoria, rappresenta una buona pratica riconosciuta a livello europeo e può fornire alle scuole un solido strumento metodologico per affrontare con rigore e responsabilità le sfide etiche e normative poste dall'integrazione dell'intelligenza artificiale nei processi educativi.

### 1.3 Riepilogo operativo: L'IA in classe tra opportunità e livelli di rischio

Dopo aver esplorato il quadro normativo di riferimento, è fondamentale tradurre i principi astratti dell'AI Act[^1] e del GDPR[^3] in una guida operativa concreta per i docenti. Non tutte le applicazioni dell'Intelligenza Artificiale in ambito scolastico presentano lo stesso livello di rischio, e di conseguenza non tutte richiedono le stesse procedure di valutazione e protezione. Questa sezione fornisce una **"mappa del rischio"** per orientare le scelte quotidiane dei docenti, classificando i principali scenari d'uso secondo un modello a semaforo: verde (rischio basso), giallo (rischio intermedio) e rosso (rischio alto).

La classificazione proposta si basa su tre criteri fondamentali:

1. **Il tipo di dati trattati:** L'IA elabora solo contenuti generici o dati personali degli studenti?
2. **Il grado di autonomia decisionale:** L'IA fornisce un supporto al docente o prende decisioni autonome che impattano sullo studente?
3. **L'impatto sui diritti fondamentali:** Quanto è significativo l'effetto dell'uso dell'IA sul percorso formativo, la privacy e l'equità del trattamento degli studenti?

#### 1.3.1 Rischio basso: Il docente al centro della creazione didattica

**Scenario Tipico:** Il docente utilizza un modello di IA generativa (come ChatGPT, Gemini, Claude o Microsoft Copilot) in modo autonomo e privato per supportare la propria attività di progettazione didattica. Gli studenti non interagiscono direttamente con il sistema e non vengono trattati dati personali degli alunni.

**Esempi concreti di utilizzo a basso rischio:**

- **Progettazione di griglie di valutazione:** Il docente chiede all'IA di generare una bozza di rubrica valutativa per una presentazione orale di storia, specificando i criteri (contenuto, esposizione, capacità argomentativa, uso delle fonti). Il docente poi personalizza, integra e adatta la griglia alla propria didattica.

- **Semplificazione e differenziazione di testi:** Per uno studente con Disturbi Specifici dell'Apprendimento (DSA) o Bisogni Educativi Speciali (BES), il docente utilizza l'IA per riscrivere un brano di un manuale in una forma linguisticamente più accessibile, mantenendo i concetti chiave. Il testo semplificato viene poi verificato dal docente prima di essere utilizzato.

- **Generazione di idee e brainstorming:** Prima di progettare un'unità didattica sulla Rivoluzione Industriale, il docente chiede all'IA di suggerire approcci didattici innovativi, attività laboratoriali o collegamenti interdisciplinari. Le idee fungono da stimolo per la creatività del docente, non da soluzione preconfezionata.

- **Preparazione della struttura di una lezione:** Il docente richiede all'IA di organizzare i contenuti di un argomento complesso (es. il sistema immunitario) in una sequenza logica di spiegazione, con suggerimenti su tempi e metodologie.

- **Creazione di verifiche e quiz:** Il docente usa l'IA per generare domande a scelta multipla, vero/falso o a risposta aperta su un argomento specifico, che poi rivede, seleziona e adatta al livello della classe.

**Perché il rischio è classificato come basso?**

- **Nessun trattamento di dati personali degli studenti:** L'IA non "vede" né elabora alcuna informazione relativa agli alunni. I prompt del docente contengono solo contenuti disciplinari generici.

- **Supervisione umana totale:** L'output dell'IA è sempre e interamente mediato dal docente. Il sistema funge da "assistente" o "strumento di brainstorming", mai da decisore autonomo.

- **Responsabilità chiara e indiscussa:** La responsabilità pedagogica, didattica e professionale del materiale prodotto rimane al 100% in capo al docente. L'IA è uno strumento, esattamente come un libro di testo o un motore di ricerca.

- **Conformità normativa automatica:** Questo tipo di utilizzo non configura un "trattamento di dati personali" ai sensi del GDPR[^3] e non rientra nelle categorie di sistemi ad alto rischio dell'AI Act[^1].

**Raccomandazioni operative:**

- **Verifica critica dell'output:** Anche in scenari a basso rischio, il docente deve sempre verificare l'accuratezza fattuale, la correttezza linguistica e l'assenza di bias negli output generati dall'IA.

- **Citazione trasparente (facoltativa ma consigliata):** Se si condivide con gli studenti un materiale che è stato in parte generato dall'IA (es. una sintesi), è buona pratica pedagogica dichiararlo, educando alla trasparenza.

**Conclusione:** Questo utilizzo **non richiede DPIA, FRIA o autorizzazioni specifiche** ed è pienamente conforme alla normativa vigente. Rappresenta l'ambito in cui l'IA può liberare tempo prezioso del docente, permettendogli di concentrarsi sugli aspetti più creativi, relazionali e strategici della professione.

#### 1.3.2 Rischio intermedio: quando l'input include dati degli studenti (anonimizzati)

**Scenario Tipico:** Il docente desidera utilizzare gli elaborati prodotti dagli studenti (temi, saggi, relazioni, risposte a domande aperte) come input per un sistema di IA, al fine di ottenere analisi aggregate, sintesi o strumenti di supporto alla didattica personalizzata.

**Esempi concreti di utilizzo a rischio intermedio:**

- **Analisi delle difficoltà comuni:** Il docente raccoglie 25 temi scritti dagli studenti su un argomento (es. "L'impatto della globalizzazione") e, dopo averli **accuratamente anonimizzati**, li fornisce all'IA per identificare gli errori grammaticali più frequenti, i concetti fraintesi o le lacune argomentative ricorrenti. L'analisi aggregata aiuta il docente a progettare interventi didattici mirati.

- **Creazione di sintesi o mappe concettuali collettive:** A partire dalle risposte anonimizzate degli studenti a una domanda di ricerca, il docente chiede all'IA di generare una mappa concettuale che integri le diverse prospettive emerse, da utilizzare come base per una discussione in classe.

- **Supporto alla valutazione formativa:** Il docente utilizza l'IA per ottenere un primo feedback strutturato su bozze di elaborati anonimizzati, che poi integra con la propria valutazione qualitativa e contestuale.

**Perché il rischio è classificato come intermedio?**

- **Trattamento di dati personali (potenzialmente sensibili):** Anche se lo scopo è didattico, gli elaborati degli studenti contengono dati personali. Il testo scritto da uno studente può rivelare opinioni, condizioni di salute, orientamento religioso o altre informazioni sensibili.

- **Rischio di re-identificazione:** Se l'anonimizzazione non è condotta correttamente (es. si lascia un nome in una citazione, un riferimento a un evento personale specifico), lo studente potrebbe essere identificabile.

- **Uso di piattaforme esterne:** Se il docente utilizza piattaforme pubbliche non controllate dall'istituto, si pone il problema della destinazione dei dati e della loro eventuale conservazione o utilizzo per l'addestramento di modelli.

**Cosa fare? Procedure obbligatorie:**

1. **Conduzione di una DPIA (Data Protection Impact Assessment):**

    Prima di avviare questa pratica, la scuola deve condurre una DPIA ai sensi dell'art. 35 del GDPR[^3]. La valutazione deve:

    - Descrivere il trattamento: quali dati, per quale finalità, con quale strumento.

    - Analizzare la necessità e la proporzionalità: esiste un'alternativa meno invasiva per raggiungere lo stesso obiettivo didattico?

    - Identificare i rischi: rischio di re-identificazione, violazione della privacy, uso improprio dei dati da parte del fornitore.

    - Definire le misure di mitigazione (vedi punto successivo).

2. **Anonimizzazione rigorosa e documentata:**

    Non è sufficiente rimuovere il nome e il cognome. Un'anonimizzazione efficace richiede:

    - Rimozione di tutti i **dati identificativi diretti:** nome, cognome, codice fiscale, indirizzo, numero di telefono.

    - Rimozione o generalizzazione di **quasi-identificatori:** riferimenti a eventi personali specifici (es. "quando mio padre è stato ricoverato"), nomi di luoghi molto specifici (es. "nella mia scuola, l'Istituto Greppi di Monticello Brianza" → "nella mia scuola"), date precise.

    - **Sostituzione con pseudonimi:** Assegnare a ogni studente un codice alfanumerico casuale (es. "ST_047") che permetta al docente di risalire all'identità solo tramite una tabella di corrispondenza conservata separatamente e in modo sicuro.

3. **Selezione di piattaforme conformi:**

    - Dare priorità a strumenti approvati e configurati dalla scuola tramite contratti di Responsabile del Trattamento (art. 28 GDPR[^3]).

    - **Evitare** l'uso di versioni gratuite e pubbliche di chatbot (es. ChatGPT free) che non offrono garanzie sulla localizzazione dei dati e sul loro non utilizzo per l'addestramento.

4. **Informativa agli studenti e alle famiglie:**

    Anche se i dati sono anonimizzati, è buona pratica (e in alcuni casi obbligatoria) informare studenti e famiglie dell'uso didattico dell'IA per l'analisi aggregata degli elaborati, spiegando le finalità e le misure di protezione adottate.

5. **Conservazione temporanea e cancellazione:**

    I dati devono essere conservati solo per il tempo strettamente necessario all'analisi e poi cancellati in modo sicuro.

**Conclusione:** L'uso degli elaborati degli studenti come input per l'IA è legittimo e può offrire significativi vantaggi didattici, ma **richiede sempre una DPIA e l'adozione di rigorose misure di protezione**, in primis un'anonimizzazione verificabile e documentata.

#### 1.3.3 Rischio intermedio-alto: chatbot didattici per l'interazione diretta con gli studenti

**Scenario tipico:** Il docente crea o configura un assistente virtuale basato sull'IA (es. un GPT personalizzato, un chatbot con Retrieval-Augmented Generation alimentato da dispense del docente, un assistente su Microsoft Copilot) e lo mette a disposizione degli studenti per supportarli nell'apprendimento autonomo.

**Esempi concreti di utilizzo:**

- **Recupero di un debito formativo:** Un docente di matematica crea un chatbot che spiega, con esempi e passaggi guidati, come risolvere equazioni di secondo grado. Gli studenti con insufficienza possono interagire con il bot in modo autonomo per esercitarsi.

- **Approfondimento personalizzato:** Un docente di filosofia configura un assistente che risponde a domande sul pensiero di Kant, basandosi su materiali didattici pre-caricati. Gli studenti possono porre domande e ottenere spiegazioni personalizzate.

- **Supporto allo studio e alla preparazione di verifiche:** Un chatbot fornisce quiz auto-valutativi, suggerimenti di studio e chiarimenti su dubbi relativi a un argomento specifico del programma.

**Perché il rischio è classificato come intermedio-alto?**

- **Interazione diretta studente-macchina:** Il controllo del docente sull'interazione è indiretto e postumo. Non può supervisionare in tempo reale ogni conversazione.

- **Raccolta di dati personali tramite l'interazione:** Ogni domanda che lo studente pone al chatbot è un dato che rivela il suo livello di conoscenza, le sue lacune, i suoi dubbi. Se la piattaforma registra queste interazioni, si configura un trattamento di dati personali su larga scala.

- **Rischio di risposte errate o fuorvianti:** L'IA può "allucinare" (inventare informazioni false ma plausibili), fornire spiegazioni incomplete o concettualmente errate, fuorviando lo studente.

- **Rischio di bias e discriminazione:** L'IA potrebbe rispondere in modo diverso a studenti con stili di domanda differenti (es. penalizzando chi usa un linguaggio informale o fa errori grammaticali), generando disuguaglianze.

- **Questioni di equità nell'accesso:** Se il chatbot è accessibile solo da casa, potrebbe creare un vantaggio per studenti con migliore connettività e device, aggravando il divario digitale.

**Cosa fare? Procedure fortemente raccomandate:**

1. **Conduzione di una DPIA approfondita:**

    La DPIA deve analizzare:

    - **Flusso dei dati:** Dove vengono registrate le conversazioni? Per quanto tempo? Chi vi ha accesso? I dati vengono utilizzati per addestrare il modello?

    - **Sicurezza della piattaforma:** Il fornitore offre garanzie sulla crittografia, sull'autenticazione degli utenti e sulla protezione da accessi non autorizzati?

    - **Impatto sulla didattica:** Quali sono i rischi di un uso acritico da parte degli studenti? Come garantire che il chatbot supporti e non sostituisca l'apprendimento attivo?

2. **Valutazione della qualità e accuratezza del sistema:**

    Il docente deve testare estensivamente il chatbot prima di renderlo disponibile, verificando:

    - L'accuratezza delle risposte su un campione rappresentativo di domande.

    - La capacità del sistema di ammettere i propri limiti ("Non sono sicuro, chiedi al docente").

    - L'assenza di contenuti inappropriati o bias evidenti.

3. **Informativa trasparente e consenso (se necessario):**

    - Gli studenti devono essere chiaramente informati che stanno interagendo con un sistema di IA, non con un essere umano.

    - Deve essere spiegato quali dati vengono raccolti e per quale finalità.

    - Se l'uso è facoltativo, potrebbe essere necessario raccogliere il consenso delle famiglie (per i minorenni).

4. **Supervisione pedagogica continua:**

    - Il docente deve monitorare l'uso del chatbot (es. analizzando le domande più frequenti, i punti di difficoltà ricorrenti).

    - Deve essere sempre disponibile un canale diretto per chiedere chiarimenti al docente umano.

    - Periodicamente, il docente dovrebbe discutere in classe l'esperienza d'uso del chatbot, educando gli studenti a un utilizzo critico.

5. **Clausole contrattuali stringenti con il fornitore:**

    Se si utilizza una piattaforma esterna, il contratto deve garantire:

    - Localizzazione dei dati nell'UE.

    - Divieto di utilizzo dei dati degli studenti per finalità diverse da quelle didattiche.

    - Diritto alla cancellazione dei dati al termine dell'attività.

    - Garanzie di sicurezza informatica certificate.

**Conclusione:** L'uso di chatbot didattici è un'applicazione promettente dell'IA per la personalizzazione dell'apprendimento, ma presenta rischi significativi. **È fortemente raccomandata una DPIA** e, in alcuni casi, potrebbe essere opportuno condurre anche una FRIA se l'impatto sui diritti degli studenti (equità, non discriminazione, diritto all'istruzione) è particolarmente rilevante.

#### 1.3.4 Rischio alto: la "linea rossa" della valutazione automatizzata

**Scenario da evitare:** Utilizzare un sistema di IA per correggere e valutare in modo automatico e definitivo gli elaborati degli studenti, con un impatto diretto e determinante sul voto finale e, di conseguenza, sul percorso scolastico dell'alunno.

**Esempi di pratiche ad alto rischio (da evitare o da sottoporre a rigidissima valutazione):**

- **Correzione automatica di temi e saggi:** Un software di IA analizza un tema scritto da uno studente e assegna autonomamente un voto basandosi su criteri di grammatica, coerenza, ricchezza lessicale e aderenza alla traccia. Il voto viene registrato senza una revisione sostanziale del docente.

- **Valutazione di presentazioni orali tramite analisi vocale:** Un sistema analizza la registrazione di un'esposizione orale dello studente, valutando la fluenza, il tono, le pause e assegnando un punteggio.

- **Sistemi di proctoring con valutazione automatica del comportamento:** Durante un esame online, un'IA monitora i movimenti oculari, le espressioni facciali e i rumori ambientali dello studente e genera un "indice di sospetto" di comportamento scorretto, che influenza la valutazione finale.

**Perché il rischio è classificato come alto?**

Questo tipo di utilizzo concentra tutti i rischi più gravi identificati dall'AI Act[^1] e dal GDPR[^3]:

1. **Trattamento massivo di dati personali (spesso sensibili):**

    - L'IA "impara" dagli elaborati, accumulando una grande quantità di dati personali.

    - Nel caso di analisi vocale o facciale, si trattano dati biometrici, classificati come "categorie particolari di dati" dall'art. 9 GDPR[^3], con protezioni ancora più stringenti.

2. **Rischio elevato di bias e discriminazione algoritmica:**

    - Un sistema addestrato prevalentemente su elaborati di studenti madrelingua può penalizzare ingiustamente studenti con background linguistico diverso.

    - Algoritmi di analisi del testo possono avere bias culturali, premiando determinate strutture argomentative o stili di scrittura e penalizzandone altre, in assenza di qualsiasi giustificazione pedagogica.

    - Sistemi di riconoscimento vocale o facciale hanno dimostrato in numerosi studi tassi di errore significativamente più alti su persone con tonalità di pelle più scura o accenti non standard, configurando una discriminazione sistemica.

3. **Mancanza di trasparenza e spiegabilità (*explainability*):**

    - Come si arriva esattamente a quel voto? Quali criteri ha utilizzato l'algoritmo? In molti sistemi di IA avanzati (reti neurali profonde), il processo decisionale è una "scatola nera" anche per gli stessi sviluppatori.

    - Questa opacità viola il principio di trasparenza e rende impossibile per lo studente (e per la famiglia) comprendere e contestare efficacemente la valutazione, violando il diritto al contraddittorio.

4. **Impatto diretto e significativo sui diritti fondamentali:**

    - Una valutazione errata può compromettere il percorso scolastico dello studente, influenzando l'ammissione alla classe successiva, l'accesso a percorsi formativi superiori e, in ultima analisi, le opportunità di vita.

    - Ciò configura un **sistema di AI ad alto rischio** ai sensi dell'Allegato III, punto 3 dell'AI Act[^1], che elenca esplicitamente i sistemi "destinati a essere utilizzati per valutare i risultati dell'apprendimento" negli istituti di istruzione.

5. **Violazione del principio di supervisione umana:**

    - L'art. 14 dell'AI Act[^1] impone che i sistemi ad alto rischio siano progettati per consentire una supervisione umana efficace. Una valutazione automatizzata e definitiva abdica completamente a questo principio.

##### Cosa dovrebbe fare una scuola che volesse comunque esplorare questa strada? (procedura eccezionale e altamente sconsigliata)

Se, per ragioni eccezionali e in contesti molto specifici (es. un progetto di ricerca pedagogica), una scuola volesse sperimentare sistemi di valutazione assistita da IA, sarebbe obbligata a:

1. **Condurre una DPIA e una FRIA complete:**

    Le valutazioni devono essere estremamente dettagliate, coinvolgere il DPO, esperti esterni di etica dell'IA e rappresentanti di studenti e famiglie.

2. **Garantire una supervisione umana reale e sostanziale:**

    L'IA può fornire un punteggio o un feedback preliminare, ma la decisione finale, motivata e documentata, deve sempre essere presa dal docente. Il docente deve avere la formazione, il tempo e gli strumenti per contestare e modificare il suggerimento dell'algoritmo.

3. **Implementare meccanismi di ricorso chiari:**

    Lo studente deve avere il diritto di richiedere una rivalutazione umana completa, senza alcuna penalizzazione.

4. **Testare e validare il sistema per l'assenza di bias:**

    Prima dell'uso su studenti reali, il sistema deve essere testato su dataset diversificati per verificare che non penalizzi sistematicamente gruppi specifici (studenti non madrelingua, con DSA, di determinati background culturali).

5. **Trasparenza totale:**

    Studenti e famiglie devono essere pienamente informati dell'uso dell'IA, dei criteri utilizzati, dei limiti del sistema e delle garanzie di protezione.

6. **Limitazione temporale e sperimentale:**

    L'uso deve essere circoscritto, monitorato e soggetto a revisione periodica.

**Conclusione e raccomandazione forte:**

Come sottolineato dal "Documento di Indirizzo"[^2] e dalla dottrina dominante in materia di etica dell'IA, **l'uso di sistemi di valutazione completamente automatizzata degli studenti è una pratica ad altissimo rischio, fortemente sconsigliata e, nella maggior parte dei casi, incompatibile con i principi di una didattica responsabile e antropocentrica**. La valutazione è un atto pedagogico complesso, che richiede comprensione del contesto, empatia, capacità di incoraggiamento e un giudizio professionale che, allo stato attuale della tecnologia e delle nostre conoscenze etiche, non può e non deve essere delegato a una macchina. **Richiede DPIA, FRIA e, soprattutto, una profonda riflessione sulla compatibilità di questa pratica con la missione educativa della scuola.**

#### 1.3.5 Tabella riassuntiva: il "semaforo" dell'IA a scuola

Per facilitare la consultazione rapida e fornire uno strumento decisionale immediato ai docenti, riassumiamo quanto esposto in una tabella sinottica organizzata secondo il modello a semaforo.

| **Livello di Rischio** | **Tipologia di Attività** | **Esempi Concreti** | **Trattamento Dati Personali?** | **Azioni Richieste** | **Note Operative** |
|---|---|---|---|---|---|
| 🟢 **BASSO** | Creazione di materiali didattici da parte del docente, senza coinvolgimento di dati degli studenti | Generazione di griglie di valutazione; Semplificazione testi per BES/DSA; Brainstorming di idee per lezioni; Creazione di quiz e verifiche (bozze) | ❌ No | ✅ **Nessuna azione formale richiesta** - Verifica critica dell'output - Citazione trasparente (consigliata) | Uso libero e consapevole. L'IA è uno strumento al servizio del docente. |
| 🟡 **INTERMEDIO** | Uso di elaborati degli studenti (anonimizzati) come input per analisi aggregate | Analisi delle difficoltà comuni in un compito; Creazione di sintesi collettive; Supporto alla valutazione formativa | ✅ Sì (anonimizzati) | ⚠️ **DPIA obbligatoria** - Anonimizzazione rigorosa e documentata - Uso di piattaforme conformi al GDPR - Informativa a studenti/famiglie - Conservazione temporanea | Legittimo se condotto con le dovute garanzie. Focus sulla protezione dei dati. |
| 🟡 **INTERMEDIO-ALTO** | Chatbot didattici o assistenti virtuali per l'interazione diretta con gli studenti | Chatbot per recupero debiti; Assistente per approfondimenti; Quiz auto-valutativi interattivi | ✅ Sì (dati di interazione) | ⚠️ **DPIA fortemente raccomandata** - Valutazione qualità e accuratezza - Informativa trasparente - Supervisione pedagogica continua - Contratti stringenti con fornitori | Potenziale elevato, ma richiede governance attenta. Monitorare equità e accesso. |
| 🔴 **ALTO** | Valutazione automatizzata e definitiva degli studenti con impatto sul voto finale | Correzione automatica di temi con voto finale; Valutazione di esposizioni orali via IA; Proctoring con scoring del comportamento | ✅ Sì (massivo, spesso biometrici) | 🚫 **DPIA + FRIA obbligatorie** - **Pratica fortemente sconsigliata** - Se inevitabile: supervisione umana reale, trasparenza totale, test anti-bias, meccanismi di ricorso | Sistema ad alto rischio (AI Act, All. III). Incompatibile con una didattica antropocentrica. Evitare. |

**Legenda:**

- 🟢 **Verde (Rischio Basso):** Procedere liberamente, mantenendo un approccio critico e responsabile.
- 🟡 **Giallo (Rischio Intermedio/Intermedio-Alto):** Procedere con cautela, dopo aver condotto le valutazioni di impatto richieste e adottato misure di protezione adeguate.
- 🔴 **Rosso (Rischio Alto):** Fermarsi e riflettere. Questa pratica richiede una valutazione approfondissima e, nella maggior parte dei casi, dovrebbe essere evitata in favore di approcci che mantengano la centralità del giudizio umano.

**Raccomandazione finale:**

Questa mappa del rischio è uno strumento guida, non un sostituto del giudizio professionale del docente e della consultazione con il DPO e con gli organi di governance della scuola. Di fronte a qualsiasi dubbio o a situazioni non chiaramente classificabili, il principio precauzionale suggerisce di adottare il livello di protezione superiore e di chiedere supporto agli esperti. L'obiettivo non è bloccare l'innovazione, ma governarla in modo che sia realmente al servizio dell'apprendimento e del benessere di ogni studente.

## Capitolo 2: Il dilemma del plagio e l'onestà accademica

L'ascesa dei modelli linguistici di grandi dimensioni (LLM) come GPT-4 ha introdotto una nuova e complessa sfida per il mondo dell'istruzione: la ridefinizione del concetto di plagio e di onestà accademica. Se uno studente può generare un tema, un saggio o la soluzione a un problema in pochi secondi, come possiamo valutare le sue reali competenze? La tentazione di un approccio puramente repressivo, basato sulla caccia al testo generato dall'AI, è forte, ma rischia di essere inefficace e pedagogicamente controproducente. Un approccio più maturo e sostenibile sposta il focus dalla repressione alla prevenzione, attraverso una ri-progettazione consapevole delle attività didattiche.

### 2.1 Riconoscere l'uso dell'AI: strumenti e limiti

Sono emersi numerosi strumenti, spesso chiamati "AI detector", che promettono di identificare se un testo è stato scritto da un umano o generato da un'intelligenza artificiale. Questi software analizzano caratteristiche del testo come la "perplessità" (la prevedibilità delle parole) e la "burstiness" (la variazione nella lunghezza delle frasi), che tendono a essere diverse tra la scrittura umana e quella artificiale.

Tuttavia, è fondamentale essere consapevoli dei loro limiti:

- **Affidabilità limitata:** Nessuno di questi strumenti è accurato al 100%. La loro efficacia varia a seconda del modello di AI utilizzato per generare il testo, della complessità dell'argomento e della lingua. Modelli più recenti e sofisticati sono sempre più difficili da individuare.

- **Rischio di falsi positivi:** Il limite più pericoloso è la possibilità che lo strumento segnali erroneamente come artificiale un testo scritto da un essere umano. Questo può accadere con studenti che hanno uno stile di scrittura molto strutturato o con persone non madrelingua che tendono a usare frasi più semplici e prevedibili. Basare una decisione disciplinare o una valutazione negativa unicamente sull'output di un AI detector è ingiusto e rischioso.

- **Evoluzione continua:** Gli sviluppatori di modelli di AI lavorano costantemente per rendere i loro output sempre più indistinguibili da quelli umani, in una sorta di "corsa agli armamenti" tecnologica che rende gli strumenti di rilevamento rapidamente obsoleti.

Pertanto, gli AI detector possono essere usati come un primo campanello d'allarme, un indizio che suggerisce un approfondimento, ma **mai come prova definitiva**. La valutazione finale deve basarsi sul dialogo con lo studente, su verifiche orali e sull'analisi complessiva del suo lavoro.

### 2.2 Progettare compiti "a prova di AI"

La strategia più efficace non è inseguire l'AI, ma renderne l'uso scorretto meno vantaggioso o irrilevante. Si tratta di progettare compiti e verifiche che valutino competenze di ordine superiore, quelle che (almeno per ora) l'AI non possiede: il pensiero critico, la creatività, l'esperienza personale, la capacità di sintesi originale e di argomentazione. Come suggerisce il "Documento di Indirizzo"[^2], si tratta di considerare l'AI come un **"compagno cognitivo" (*****cognitive partner*****)**, uno strumento da utilizzare e interrogare, non una scorciatoia da sfruttare.

Ecco alcuni esempi pratici di strategie didattiche:

- **Richiedere analisi critiche degli output dell'AI:** Invece di chiedere "Scrivi un saggio sulla Rivoluzione Francese", si può assegnare: "Usa un modello di AI per generare un saggio sulla Rivoluzione Francese. Poi, scrivi una relazione in cui analizzi l'output: quali sono i suoi punti di forza? Quali errori o imprecisioni contiene? Quali prospettive o interpretazioni storiografiche ignora? Quali bias (ad esempio, una visione eurocentrica) puoi identificare nel testo?". Questo tipo di compito non solo neutralizza il plagio, ma sviluppa competenze di *AI literacy* e pensiero critico.

- **Basarsi sull'esperienza personale e sul contesto locale:** Compiti che richiedono agli studenti di collegare i concetti studiati alla loro vita, alla loro comunità o a eventi recenti sono intrinsecamente "a prova di AI". Ad esempio: "Intervista un tuo parente che ha vissuto gli anni '70 e confronta il suo racconto con le fonti storiche che abbiamo studiato" oppure "Analizza l'impatto economico di quella nuova azienda sul nostro territorio".

- **Utilizzare fonti specifiche e recenti:** L'AI generativa ha una "conoscenza" che si ferma a una certa data e spesso non ha accesso a documenti specifici (come un articolo scientifico pubblicato la settimana scorsa o una dispensa fornita dal docente). Assegnare compiti che richiedono l'analisi di tali fonti rende l'AI meno utile.

- **Privilegiare la discussione e la presentazione orale:** La capacità di discutere, argomentare e rispondere a domande in tempo reale rimane una competenza prettamente umana. Le presentazioni orali, i dibattiti in classe (*debate*), le interrogazioni e le discussioni di gruppo sono strumenti di valutazione eccellenti.

- **Svolgere il lavoro in classe:** Una parte significativa del processo di scrittura o di risoluzione di problemi può essere svolta in classe, sotto la supervisione del docente. Questo non significa tornare a un modello puramente trasmissivo, ma creare momenti di "laboratorio" in cui gli studenti lavorano individualmente o in gruppo, potendo contare sul supporto del docente (e, perché no, anche di un uso guidato e trasparente dell'AI).

### 2.3 Le App più usate dagli studenti: conoscerle per guidarle

Per guidare gli studenti verso un uso corretto, è essenziale che i docenti conoscano gli strumenti che essi utilizzano quotidianamente. Tra le applicazioni di AI generativa più diffuse troviamo:

#### App AI più usate tra gli studenti adolescenti (13-19 anni) in Italia e in Europa - Report generato con Perplexity AI ad ottobre 2025

Le applicazioni basate sull'intelligenza artificiale si sono rapidamente diffuse tra gli studenti adolescenti sia in Italia che in Europa, diventando strumenti quotidiani per l'apprendimento, lo studio e l'intrattenimento. I dati più recenti rivelano un panorama in rapida evoluzione, con livelli di adozione significativi e differenze tra i vari paesi europei.

##### Le app AI più utilizzate in Italia

In Italia, l'uso dell'intelligenza artificiale tra gli studenti è in forte crescita. Secondo i dati più recenti, **il 78% degli studenti italiani utilizza regolarmente strumenti di intelligenza artificiale per lo studio**, mentre **il 37% degli studenti usa ChatGPT**, una percentuale significativamente superiore rispetto alla media della popolazione generale (20,7% degli adulti tra 18 e 74 anni).[globalist+2](https://www.globalist.it/media/2025/06/30/boom-di-chat-gpt-in-italia-ma-lia-piu-usata-e-unaltra/)​

Le applicazioni AI più popolari tra gli studenti italiani sono:

**ChatGPT** rappresenta lo strumento dominante, utilizzato da circa **8,8 milioni di italiani** ad aprile 2025. Tra gli studenti delle scuole superiori, la penetrazione raggiunge il **65% tra i 16-18 anni**, con il **71% degli studenti delle superiori** che lo utilizza regolarmente. Gli studenti lo impiegano principalmente per cercare informazioni (87%), elaborare testi (66%), creare immagini (46%), presentazioni (45%) e video o musica (34%).[tecnicadellascuola+4](https://www.tecnicadellascuola.it/giovani-senza-regole-schiavi-di-internet-e-smartphone-connessi-3-5-ore-al-giorno-tra-i-richiami-dei-genitori-urge-formazione-studio-moige-istituto-piepoli)​

**Google Gemini** si posiziona al secondo posto con **2,8 milioni di utenti** mensili in Italia, seguito da **Microsoft Copilot** con **2,7 milioni di utilizzatori**.[vincos+2](https://vincos.it/2025/06/28/le-app-di-intelligenza-artificiale-piu-usate-dagli-italiani-aprile-2025/)​

Un dato particolarmente interessante riguarda **Character AI**, un'app che permette di dialogare con chatbot personalizzati modellati su personaggi famosi. Pur avendo "solo" **119.000 utenti in Italia**, questa piattaforma registra il **tempo di utilizzo più elevato**: quasi **20 ore mensili per utente**, principalmente tra i giovani e in prevalenza donne.[globalist+1](https://www.globalist.it/media/2025/06/30/boom-di-chat-gpt-in-italia-ma-lia-piu-usata-e-unaltra/)​

Altri strumenti utilizzati includono **Perplexity AI** (270.000 utenti), **Claude di Anthropic** (158.000 utenti), e **Grok** (54.000 utenti).[infodata.ilsole24ore+2](https://www.infodata.ilsole24ore.com/2025/07/02/ogni-mese-88-milioni-di-italiani-usano-chatgpt-lapp-e-usata-dal-37-degli-studenti/)​

Per quanto riguarda le app educative specifiche, **Duolingo** è ampiamente utilizzato per l'apprendimento delle lingue, mentre **Quizlet** e **Grammarly** supportano rispettivamente lo studio attraverso flashcard digitali e il miglioramento della scrittura.[letuelezioni+2](https://www.letuelezioni.it/blog/migliori-app-interattive-apprendimento)​

##### Le app AI più utilizzate in Europa

A livello europeo, i dati mostrano tendenze simili ma con significative variazioni tra paesi. Secondo un'indagine condotta su **7.000 studenti tra i 12 e i 17 anni** in sette paesi europei (Germania, Spagna, Grecia, Turchia, Portogallo, Regno Unito e Romania), l'adozione dell'AI è in forte crescita.[skillsuploadjr](https://skillsuploadjr.eu/docs/contents/AI_in_European_schools.pdf)​

**ChatGPT** emerge come lo strumento AI più utilizzato dagli insegnanti nelle classi europee, con **il 47% dei docenti** che lo raccomanda agli studenti. A livello personale, **il 48% degli studenti europei** utilizza ChatGPT, con variazioni significative: in Spagna raggiunge il **54%**, mentre in altri paesi europei si attesta su percentuali leggermente inferiori.[programs+1](https://programs.com/resources/students-using-ai/)​

Dopo ChatGPT, gli strumenti più raccomandati dagli insegnanti europei sono:[skillsuploadjr+1](https://skillsuploadjr.eu/docs/contents/AI_in_European_schools.pdf)​

- **Google Lens**: 24% (con un picco del 37% in Turchia)

- **Duolingo**: 23% (raggiunge il 34% in Romania ma solo il 13% in Germania)

- **Google Gemini**: 22% (31% nel Regno Unito e 33% in Turchia)

- **Apple Siri**: 20% (28% nel Regno Unito, 32% in Turchia)

- **Snapchat 'My AI'**: 14%

- **Grammarly**: 7% (19% nel Regno Unito)

- **Midjourney**: 3%

- **DeepL**: 3%

###### Divario digitale a scuola tra i paesi europei

Uno degli aspetti più rilevanti emersi dalle ricerche è il **divario digitale** nell'accesso agli strumenti AI tra i paesi europei. Mentre **il 44% degli studenti in Germania** e il **43% in Romania** hanno accesso costante a dispositivi con capacità AI, questa percentuale scende drasticamente in altri paesi: solo **il 29% in Grecia**, **il 20% in Francia** e **il 10% in Italia e Francia** per quanto riguarda l'accesso a strumenti AI a scuola.[gostudent+2](https://www.gostudent.org/en-gb/press-releases/is-ai-in-schools-failing-students-gostudent-report-reveals-demand-gap/)​

Il Regno Unito emerge come leader nell'accesso complessivo a strumenti digitali e AI nelle scuole, mentre la regione DACH (Germania, Austria, Svizzera) mostra livelli di adozione significativamente superiori rispetto ai paesi del sud Europa.[innobu+2](https://www.innobu.com/kids-and-ai-the-75b-education-revolution-no-one-saw-coming/)​

##### Modalità e frequenza d'uso

I dati sulla frequenza d'uso rivelano che **il 51% degli studenti italiani** utilizza l'IA generativa settimanalmente, con **1 studente su 4** che la usa quotidianamente. A livello europeo, **il 77% degli adolescenti tra i 13 e i 18 anni** utilizza strumenti AI nel 2024, raddoppiando rispetto al 37% del 2023.[gostudent+2](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

Gli studenti utilizzano principalmente l'AI per:[orizzontescuola+1](https://www.orizzontescuola.it/intelligenza-artificiale-solo-l11-dei-docenti-ne-ha-conoscenza-approfondita-ma-il-54-lo-usa-a-scopi-didattici-tra-gli-studenti-il-60-lo-usa-per-lo-studio-i-dati/)​

- **65%**: compiti e saggi

- **71%**: cercare informazioni

- **60%**: svolgere compiti

- **33%**: imparare

- **21%**: come assistente personale

- **18%**: rispondere a test

Tuttavia, solo **il 21% degli studenti** ha ricevuto una formazione adeguata sui rischi e le potenzialità dell'IA, evidenziando un'importante lacuna formativa che preoccupa educatori e famiglie.[tecnicadellascuola](https://www.tecnicadellascuola.it/giovani-senza-regole-schiavi-di-internet-e-smartphone-connessi-3-5-ore-al-giorno-tra-i-richiami-dei-genitori-urge-formazione-studio-moige-istituto-piepoli)​

##### Strumenti specializzati per l'educazione

Oltre ai chatbot generalisti, diversi strumenti AI specializzati stanno guadagnando popolarità tra gli studenti europei:

**Per l'apprendimento delle lingue**: **Duolingo** domina con percentuali di utilizzo variabili (dal 13% in Germania al 34% in Romania), affiancato da **DeepL** per le traduzioni.[programs+1](https://programs.com/resources/students-using-ai/)​

**Per lo studio e la memorizzazione**: **Quizlet** è ampiamente utilizzato per creare flashcard digitali e quiz interattivi, con oltre **60 milioni di utenti globali** tra studenti e insegnanti.[prnewswire](https://www.prnewswire.com/news-releases/quizlets-how-america-learns-report-explores-the-future-of-education-through-the-lens-of-ai-digital-learning-and-student-success-302506174.html)​

**Per la scrittura**: **Grammarly** supporta il miglioramento della scrittura, particolarmente popolare nel Regno Unito (19% di raccomandazioni da parte degli insegnanti).[skillsuploadjr+1](https://skillsuploadjr.eu/docs/contents/AI_in_European_schools.pdf)​

**Per la ricerca**: **Perplexity AI** e **Google Gemini** vengono sempre più utilizzati come motori di ricerca potenziati dall'AI, con Gemini che raggiunge **450 milioni di utenti attivi mensili** a livello globale a metà 2025.[sqmagazine](https://sqmagazine.co.uk/chatgpt-vs-google-gemini-statistics/)​

##### Tendenze emergenti

Un fenomeno preoccupante riguarda l'uso di **AI companion** o chatbot emotivi. Secondo recenti studi, **il 72% degli adolescenti** ha utilizzato AI companion, con **metà di loro** che li usa regolarmente. Questa tendenza è particolarmente pronunciata con piattaforme come **Character AI**, dove gli adolescenti sviluppano legami emotivi con personaggi virtuali, sollevando preoccupazioni tra esperti di salute mentale.[arxiv+3](https://arxiv.org/html/2507.15783)​

##### Prospettive future

L'adozione dell'AI nell'educazione è destinata a crescere ulteriormente. **Il 62% degli studenti** vorrebbe che gli insegnanti conoscessero meglio l'IA, mentre **il 74% riconosce l'importanza dell'AI per il futuro professionale**. Tuttavia, permangono sfide significative: solo **il 28% dei docenti italiani** riceve formazione specifica sull'uso dell'IA in classe, e il **64% delle famiglie italiane** è favorevole all'introduzione di strumenti IA nell'istruzione pubblica.[gostudent+1](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

#### App AI più usate dagli studenti adolescenti (13-19 anni) per materia specifica - Report generato con Perplexity AI ad ottobre 2025

L'intelligenza artificiale ha trasformato profondamente non solo il modo generale di studiare, ma anche l'approccio degli studenti adolescenti alle singole discipline scolastiche. Le applicazioni AI si sono specializzate per rispondere a esigenze didattiche specifiche, offrendo supporto mirato in matematica, lingue, scienze e materie umanistiche. Parallelamente, alcuni strumenti sono diventati mezzi per completare i compiti senza un reale apprendimento, sollevando preoccupazioni etiche tra educatori e famiglie.

##### Matematica: le app AI più utilizzate

Per la matematica, la categoria di app AI più popolare tra gli studenti è quella dei "math solver", strumenti che permettono di fotografare o digitare problemi matematici ricevendo soluzioni dettagliate passo dopo passo.

**Photomath di Google** emerge come l'app matematica più utilizzata, con una base utenti di oltre **300 milioni di studenti globalmente**. L'app consente di scansionare problemi matematici stampati o scritti a mano e ricevere soluzioni istantanee con spiegazioni dettagliate. La versione base è gratuita, mentre la versione premium (9,99$/mese) offre animazioni tutorial e metodi di soluzione alternativi. Gli studenti italiani la conoscono bene, con articoli dedicati che ne evidenziano sia i vantaggi didattici sia i rischi di dipendenza.[ai-tutor+5](https://ai-tutor.ai/blog/best-math-ai-apps/)​

**Google Lens** si posiziona come una delle migliori per la comprensione dei concetti matematici, non solo fornendo soluzioni ma aiutando gli studenti a capire il "perché" dietro ogni passaggio.

Secondo la ricerca, **il 23% degli insegnanti europei raccomanda strumenti matematici basati sull'IA** ai propri studenti, evidenziando l'integrazione di questi strumenti nella didattica formale.[skillsuploadjr+1](https://skillsuploadjr.eu/docs/contents/AI_in_European_schools.pdf)​

##### Fisica e Scienze: strumenti AI specializzati

Per la fisica, **Wolfram Alpha** domina come strumento computazionale avanzato, capace di risolvere problemi di meccanica, termodinamica, ottica, meccanica quantistica e fisica nucleare. Gli studenti lo utilizzano per calcoli complessi, formule fisiche e costanti scientifiche, con la versione Pro che parte da 5$/mese.[wolframalpha+2](https://www.wolframalpha.com/examples/science-and-technology/physics)​

Per la chimica, studi recenti mostrano che gli studenti utilizzano ChatGPT per risolvere problemi specifici, con valutazioni di soddisfazione che variano in base al livello educativo: gli studenti delle scuole medie valutano la correttezza delle risposte chimiche con una media di 4,26/5, mentre gli universitari scendono a 2,67/5, evidenziando limiti nella precisione per argomenti avanzati.[pubs.acs](https://pubs.acs.org/doi/10.1021/acs.jchemed.4c00212)​

Per la biologia, sono emersi strumenti specializzati come **BiologyBuddy.ai** (basato su GPT-4 per esami di biologia A-level), **TutorBin Biology AI Solver** (che analizza foto di problemi biologici), e **StudyMonkey Biology Tutor** (tutor AI disponibile 24/7 per domande di biologia).[tutorbin+3](https://tutorbin.com/biology-ai-solver)​

##### Lingue straniere: l'inglese e oltre

Per l'apprendimento delle lingue straniere, **Duolingo** rimane lo strumento dominante con percentuali di raccomandazione da parte degli insegnanti europei che variano significativamente: **34% in Romania, 23% in media europea, ma solo 13% in Germania**. La piattaforma ha introdotto **Duolingo Max** con funzionalità AI personalizzate.[programs+2](https://programs.com/resources/students-using-ai/)​

**DeepL** è diventato lo strumento di traduzione preferito dagli studenti europei per i compiti, superando Google Translate per accuratezza. Uno studio condotto su studenti di inglese come lingua straniera mostra che il **63% riporta un aumento del vocabolario** grazie all'uso di DeepL, con studenti che lo utilizzano principalmente per tradurre paragrafi (media 3,78/5), saggi (3,72/5) e testi dall'inglese alla propria lingua madre. DeepL supporta traduzione in **52 lingue**, rendendolo particolarmente versatile.[quillbot+4](https://quillbot.com/translate/english-to-italian)​

**Grammarly** è raccomandato dal **7% degli insegnanti europei in media, ma sale al 19% nel Regno Unito**, dimostrando differenze geografiche nell'adozione. Gli insegnanti europei raccomandano gli **assistenti di scrittura AI nel 29% dei casi** e gli **strumenti di apprendimento linguistico basati su IA nel 29%**.[gostudent+2](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

##### Lingua italiana e grammatica

Per lo studio della grammatica italiana e della propria lingua madre, gli studenti utilizzano prevalentemente **ChatGPT** e **Grammarly**, che supporta anche l'italiano. **QuillBot** offre controllo grammaticale e stilistico in italiano, mentre si stanno diffondendo assistenti di scrittura AI integrati in piattaforme come **Microsoft Copilot** e **Google Gemini** per revisione testi, formulazione di saggi e miglioramento dello stile.[quillbot+5](https://quillbot.com/grammar-check)​

**Il 75% degli studenti italiani che usano IA lo fanno per scrivere contenuti testuali**, con il **16% che usa specificamente l'IA per scrivere temi**.[skuola+1](https://www.skuola.net/news/social-trend/chatgpt-boom-studenti-ultimo-anno-scolastico.html)​

##### Storia, materie umanistiche e ricerca

Per storia e materie umanistiche, **ChatGPT** rappresenta lo strumento principale, utilizzato da **il 65% degli studenti italiani per fare compiti e scrivere saggi**. Il **75% degli studenti usa l'IA per temi e progetti, con un incremento del 10% rispetto all'anno precedente**.[futuroprossimo+2](https://www.futuroprossimo.it/2025/09/studenti-2-0-copioni-infallibili-chatgpt-ha-messo-in-crisi-la-scuola/)​

Uno studio condotto su studenti francesi e italiani (età 13-25 anni) evidenzia che gli studenti di discipline umanistiche utilizzano ChatGPT con frequenza diversa rispetto agli studenti di materie scientifiche, con differenze di genere: **i maschi mostrano tassi di utilizzo più elevati, particolarmente in contesti scientifici**.[arxiv](https://arxiv.org/html/2412.17486v1)​

Per la ricerca accademica, strumenti come **Perplexity AI** (270.000 utenti in Italia) e **Google Gemini** (2,8 milioni di utenti italiani) stanno guadagnando terreno come motori di ricerca potenziati dall'AI, alternativi a ChatGPT per la ricerca di informazioni.[universitybox+2](https://www.universitybox.com/ai-per-studenti-le-migliori-intelligenze-artificiali-per-lo-studio-2025/)​

##### App utilizzate in modo non lecito per i compiti

La questione dell'uso improprio dell'IA per completare i compiti senza apprendimento rappresenta una preoccupazione crescente. I dati italiani ed europei rivelano un fenomeno significativo:

**ChatGPT** è lo strumento più utilizzato in modo improprio: **il 65% degli studenti italiani tra 16 e 18 anni lo usa per fare compiti e scrivere saggi**, con **il 59% che ammette di usarlo per svolgere compiti**. L'uso è esploso: **dal 86% al 97% degli studenti italiani tra 16-18 anni** ha utilizzato ChatGPT nell'ultimo anno scolastico, con **il 51% che lo usa settimanalmente e il 19% quotidianamente** (raddoppiato rispetto all'anno precedente).[tg24.sky+2](https://tg24.sky.it/tecnologia/2024/05/20/intelligenza-artificiale-scuola-chat-gpt)​

**Il 21% degli studenti europei ammette di usare l'intelligenza artificiale per superare verifiche ed esami**, mentre **il 18% la utilizza per rispondere a test**.[letuelezioni+2](https://www.letuelezioni.it/blog/statistiche-copiare-imbrogli-scuola-aggiornato)​

Geograficamente, l'uso improprio è più diffuso nelle grandi città italiane: **Napoli (60%), Torino (60%), Milano (56%) e Roma (53%)**.[tg24.sky](https://tg24.sky.it/tecnologia/2024/05/20/intelligenza-artificiale-scuola-chat-gpt)​

Per la matematica, **Photomath** è considerata "una piaga" da molti insegnanti su forum educativi, preoccupati che gli studenti la usino per copiare senza comprendere i procedimenti. Lo stesso vale per **Symbolab** e **Cymath**, che permettono di ottenere soluzioni complete semplicemente fotografando i problemi.[symbolab+4](https://www.symbolab.com/)​

##### Consapevolezza critica e preoccupazioni

Nonostante l'uso massiccio, emerge una **crescente consapevolezza critica**: **il 58% degli studenti italiani è favorevole a un monitoraggio dell'uso dell'IA per evitare il plagio**, e **solo il 25% ritiene ChatGPT completamente affidabile, mentre il 54% esprime dubbi**.[gostudent+3](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

**Il 64% degli studenti esprime preoccupazione per un uso illimitato dell'IA sia a scuola che nel mondo del lavoro**, dimostrando che molti giovani comprendono i rischi etici associati a questi strumenti.[letuelezioni+2](https://www.letuelezioni.it/blog/statistiche-copiare-imbrogli-scuola-aggiornato)​

Tuttavia, **solo il 21% degli studenti ha ricevuto formazione adeguata sui rischi e le potenzialità dell'IA**, e **solo il 18% ha ricevuto indicazioni dalla scuola sull'uso dell'IA**, evidenziando una lacuna formativa critica che lascia gli studenti soli nell'affrontare queste tecnologie potenti.[tecnicadellascuola+1](https://www.tecnicadellascuola.it/giovani-senza-regole-schiavi-di-internet-e-smartphone-connessi-3-5-ore-al-giorno-tra-i-richiami-dei-genitori-urge-formazione-studio-moige-istituto-piepoli)​

##### Il divario tra uso e formazione

Un dato particolarmente significativo riguarda il divario tra uso e formazione: **l'89% degli studenti universitari italiani usa l'IA per studiare, ma il 70% degli adolescenti non riceve formazione in IA**. **Solo il 28% degli studenti impara a usare l'IA a scuola, mentre il 29% lo fa autonomamente tramite social media**.[nucamp+2](https://www.nucamp.co/blog/coding-bootcamp-italy-ita-education-the-complete-guide-to-using-ai-in-the-education-industry-in-italy-in-2025)​

Gli insegnanti stessi sono impreparati: **solo il 28% dei docenti italiani riceve formazione specifica sull'uso dell'IA in classe**, e **il 75% dei docenti non ha ricevuto alcuna formazione sull'IA, anche se il 56% la richiede esplicitamente**.[gostudent+1](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

##### Richiesta di nuovi metodi di valutazione

La diffusione di questi strumenti sta spingendo verso una trasformazione dei metodi di valutazione: **l'86% dei docenti italiani auspica l'introduzione di nuovi metodi di valutazione basati sulla simulazione** (Simulation-Based Assessment), superando la media europea. **Il 74% degli insegnanti europei preferisce valutazioni basate su simulazioni**, ritenute più efficaci rispetto ai metodi tradizionali come compiti e verifiche.[letuelezioni](https://www.letuelezioni.it/blog/statistiche-copiare-imbrogli-scuola-aggiornato)​

**Il 35% dei professori considera il tema poco efficace, poiché gli studenti tendono a copiare utilizzando l'IA**, evidenziando come i tradizionali metodi di valutazione stiano perdendo efficacia nell'era dell'intelligenza artificiale.[letuelezioni](https://www.letuelezioni.it/blog/statistiche-copiare-imbrogli-scuola-aggiornato)​

##### Prospettiva futura

Nonostante le preoccupazioni, **l'80% degli studenti desidera imparare a usare l'IA in modo utile per il proprio futuro**, e non solo per copiare. **Il 73% degli studenti italiani crede che l'IA sarà una componente fissa dello studio entro i prossimi 5 anni**, mentre **il 68% prevede di continuare a utilizzarla**.[gostudent+1](https://www.gostudent.org/it-it/blog/statistiche-uso-ia-da-parte-di-studenti-come-perch%C3%A9-quando)​

La sfida principale resta quella di educare studenti e docenti a un uso etico e consapevole di questi strumenti, trasformandoli da mezzi per aggirare l'apprendimento a veri alleati per comprendere meglio le materie e sviluppare competenze critiche essenziali per il futuro.

## Capitolo 3: costruire una Policy d'Istituto sull'AI

L'integrazione dell'Intelligenza Artificiale nella vita scolastica non può essere lasciata all'iniziativa individuale o all'improvvisazione. Un approccio frammentato e non governato rischia di creare disuguaglianze, esporre l'istituto a rischi legali e di sicurezza, e vanificare le potenzialità educative della tecnologia. Per questo motivo, ogni scuola ha bisogno di una **AI Policy**, un documento strategico che definisca una visione, stabilisca regole chiare e assegni responsabilità precise.

### 3.1 Perché ogni scuola ha bisogno di una AI Policy

Utilizzando il "Documento di Indirizzo"[^2] come modello, possiamo comprendere l'importanza cruciale di una policy d'istituto. Un tale documento serve a:

- **Garantire la conformità normativa:** Stabilisce le procedure per assicurare che ogni uso dell'AI sia conforme all'AI Act[^1] e al GDPR[^3], proteggendo l'istituto, il personale e gli studenti da rischi legali.

- **Promuovere un'innovazione etica:** Definisce i principi etici (equità, trasparenza, centralità umana) che devono guidare l'adozione di qualsiasi strumento, assicurando che la tecnologia sia al servizio del progetto educativo e non viceversa.

- **Creare un quadro di riferimento comune:** Fornisce a dirigenti, docenti, personale, studenti e famiglie un insieme di regole e linee guida chiare e condivise, riducendo l'incertezza e promuovendo pratiche coerenti in tutto l'istituto.

- **Orientare le scelte strategiche:** Funge da bussola per le decisioni future in materia di investimenti, formazione e sviluppo didattico, assicurando che l'integrazione dell'AI sia "consapevole, etica e normativamente corretta".

- **Gestire i rischi:** Permette di identificare, valutare e mitigare in modo proattivo i rischi legati alla privacy, alla sicurezza informatica, ai bias algoritmici e all'onestà accademica.

Una AI Policy non è un manuale tecnico, ma un documento di governance che traduce una visione educativa in pratica quotidiana.

### 3.2 Gli attori e le responsabilità

Una policy efficace deve definire chiaramente "chi fa che cosa". Basandosi sulla struttura del Capitolo 2 del "Documento di Indirizzo"[^2], possiamo delineare i ruoli e le azioni concrete per le diverse figure scolastiche.

#### Governance (Dirigente Scolastico e Consiglio d'Istituto)

La responsabilità primaria della guida strategica ricade sugli organi di governo della scuola.

- **Azioni concrete:**

    - **Istituzione di un Gruppo di Lavoro per l'AI:** Un team multidisciplinare (presieduto dal Dirigente e composto da DPO, Animatore Digitale, docenti referenti, personale ATA, studenti e genitori) con il mandato di mappare i bisogni, valutare le proposte di adozione di nuovi strumenti e supervisionare l'attuazione della policy.

    - **Integrazione nei documenti strategici:** La visione sull'AI deve essere integrata nel Piano Triennale dell'Offerta Formativa (PTOF), definendo traguardi di competenza specifici (es. nel curricolo di Educazione Civica Digitale), un piano di formazione per il personale e criteri chiari per l'uso dell'AI nei processi valutativi.

    - **Definizione di un budget dedicato:** Stanziamento di fondi specifici per l'acquisizione di software, la formazione e l'adeguamento delle infrastrutture.

#### Conformità Normativa (Responsabile della Protezione dei Dati - DPO)

Il DPO è la figura cardine per garantire la conformità al GDPR[^3] e all'AI Act[^1].

- **Azioni concrete:**

    - **Creazione di un "Registro dei Trattamenti AI":** Una sezione specifica del Registro delle Attività di Trattamento (ex Art. 30 GDPR[^3]) che documenti per ogni sistema di AI la finalità, la base giuridica, i dati trattati e la classificazione del rischio.

    - **Gestione delle DPIA/FRIA:** Sviluppare una procedura standard e supportare la scuola nella conduzione delle Valutazioni di Impatto prima dell'adozione di ogni nuovo strumento.

    - **Revisione dei contratti con i fornitori:** Verificare che ogni fornitore di servizi di AI sia nominato Responsabile del Trattamento tramite un contratto conforme all'Art. 28 del GDPR[^3] e che offra adeguate garanzie sulla sicurezza e la localizzazione dei dati.

#### Implementazione (Animatore Digitale)

L'Animatore Digitale ha il ruolo di coordinatore pedagogico e tecnico dell'implementazione.

- **Azioni concrete:**

    - **Formazione dei docenti:** Progettare e coordinare un piano di formazione continua, differenziato per livelli di competenza, sui principi etici, normativi e sull'uso didattico degli strumenti. Un esempio concreto di modulo formativo potrebbe includere:

        > **Attività laboratoriale:** discussione guidata e stesura collaborativa di una bozza di "Patto di corresponsabilità" o di linee guida per l'uso etico dell'AI in classe, da condividere con studenti e famiglie.
        >
        > **Materiali forniti:** articoli su etica e AI, link alla normativa di riferimento, esempi di policy sull'AI adottate da altre scuole/università.

    - **Creazione di una "Software Library":** Curare un elenco ragionato e approvato di strumenti di AI sicuri ed efficaci. Per ogni strumento, la libreria deve indicare la finalità didattica, il livello di rischio (con link alla relativa DPIA) e una guida all'uso. Questo serve a orientare i docenti verso software già valutati, evitando l'uso incontrollato di piattaforme non verificate.

#### Uso didattico (Docenti)

I docenti sono gli attori principali dell'integrazione dell'AI nel processo di apprendimento.

- **Azioni concrete:**

    - **Formazione continua:** Partecipare attivamente alle iniziative di formazione per acquisire le competenze necessarie.

    - **Uso responsabile:** Utilizzare prioritariamente gli strumenti della "Software Library" e non inserire mai dati personali di studenti in piattaforme pubbliche non approvate.

    - **Progettazione didattica critica:** Integrare l'AI come "compagno cognitivo" e non come sostituto del pensiero, progettando attività che richiedano di valutare e criticare i suoi output.

    - **Valutazione umana e trasparente:** Mantenere la centralità del proprio giudizio professionale. Gli strumenti di AI possono essere un supporto, ma la responsabilità della valutazione finale è e deve rimanere del docente.

### 3.3 "Cose da NON Fare": una guida pratica

Una policy efficace deve essere anche prescrittiva. Basandosi sulla sezione 3.4 del "Documento di Indirizzo"[^2], ecco una checklist chiara e diretta delle azioni da evitare assolutamente:

- **NON usare l'AI per la valutazione finale e completamente automatizzata degli studenti.** Le decisioni che hanno un impatto significativo sul percorso di uno studente devono sempre prevedere una supervisione e una validazione umana.

- **NON inserire dati personali di studenti (nomi, temi, dati sensibili) in piattaforme di AI generative pubbliche e generiche (es. la versione gratuita di ChatGPT).** Si devono usare solo gli strumenti approvati e configurati dalla scuola che garantiscano la privacy.

- **NON adottare un nuovo strumento di AI senza aver prima consultato il DPO e aver completato la procedura di valutazione del rischio (DPIA).** L'approccio "fai da te" espone l'istituto a gravi rischi.

- **NON dare per scontato che l'output di un'AI sia corretto, completo o imparziale.** Il docente ha la responsabilità professionale di verificare ogni contenuto prima di usarlo a scopo didattico.

- **NON basare decisioni disciplinari (es. un'accusa di plagio) unicamente sull'output di un "AI detector".**

- **NON ignorare l'obbligo di trasparenza.** La natura artificiale di un chatbot o di un contenuto generato da AI deve essere sempre dichiarata agli studenti.

## Capitolo 4: rischi, bias e implicazioni etiche profonde

Oltre alle questioni normative e di sicurezza, l'uso dell'AI nella didattica solleva profonde implicazioni etiche che toccano il cuore della missione educativa della scuola. Un approccio responsabile richiede di guardare oltre la superficie della tecnologia per interrogarsi sui suoi effetti più profondi sull'equità, la trasparenza e la natura stessa dell'apprendimento.

### 4.1 Oltre la privacy: i bias algoritmici

Uno dei rischi etici più insidiosi dell'AI è il **bias algoritmico**. I sistemi di AI apprendono dai dati con cui vengono addestrati. Se questi dati riflettono pregiudizi, stereotipi e disuguaglianze presenti nella società, l'AI non solo li imparerà, ma potrà anche perpetuarli e amplificarli su larga scala. Questo è in netto contrasto con il principio di **equità**, menzionato come cardine nel "Documento di Indirizzo"[^2], secondo cui l'AI deve "promuovere l'equità, garantendo che tutti abbiano pari accesso alle opportunità e ai benefici".

Nel contesto educativo, i bias possono manifestarsi in modi diversi e dannosi:

- **Bias linguistico e culturale:** Un sistema di valutazione del testo addestrato prevalentemente su testi in inglese standard potrebbe penalizzare uno studente che usa una variante linguistica regionale o che scrive con una struttura sintattica influenzata dalla sua lingua madre. Allo stesso modo, un'AI che genera esempi o problemi potrebbe proporre scenari culturalmente stereotipati o irrilevanti per studenti con background diversi.

- **Bias socio-economico:** Un sistema di ammissione predittivo potrebbe, basandosi su dati storici, associare un codice postale di una zona a basso reddito a una minore probabilità di successo accademico, creando una profezia che si autoavvera e perpetuando la disuguaglianza.

- **Bias di genere e di rappresentazione:** Un'AI per la generazione di immagini, se non correttamente istruita, potrebbe associare determinate professioni (es. ingegnere, infermiere) a un genere specifico, rinforzando stereotipi dannosi.

Combattere i bias richiede una vigilanza costante. La scuola deve scegliere fornitori che dimostrino di lavorare attivamente per mitigare i bias nei loro modelli, ma soprattutto deve formare i docenti a riconoscere e a decostruire criticamente gli output dell'AI insieme agli studenti, trasformando un rischio in un'opportunità di educazione alla cittadinanza digitale.

### 4.2 L'Effetto "scatola nera" e la responsabilità umana

Molti dei modelli di AI più avanzati, in particolare le reti neurali profonde, funzionano come una "scatola nera" (*black box*). Siamo in grado di osservare i dati in ingresso e l'output in uscita, ma i processi interni che portano a una determinata decisione sono così complessi da essere difficilmente interpretabili persino per i loro stessi creatori.

Questo problema della non-trasparenza pone una questione fondamentale di responsabilità. Se un'AI commette un errore in una valutazione, di chi è la colpa? Del programmatore? Della scuola che ha adottato lo strumento? Del docente che lo ha utilizzato?

La risposta normativa ed etica, come sottolineato in più punti del "Documento di Indirizzo"[^2] e nell'AI Act[^1], è inequivocabile: la **centralità e la responsabilità finale devono sempre rimanere umane**. Nessuna decisione critica che riguardi la vita e il percorso formativo di uno studente può essere interamente delegata a una macchina. Il docente non è un semplice "operatore" di un sistema, ma il garante del processo educativo. L'AI può fornire dati, analisi, suggerimenti, ma il giudizio finale, la valutazione contestualizzata, la decisione pedagogica e la responsabilità che ne deriva sono e devono rimanere una prerogativa irrinunciabile dell'essere umano. Questo principio non è un ostacolo all'innovazione, ma la sua più importante garanzia etica.

## Guida alla co-progettazione di un patto etico per l'uso dell'Intelligenza Artificiale a scuola

### Premessa: governare la complessità, costruire il futuro

L'irruzione dell'Intelligenza Artificiale generativa nel panorama educativo rappresenta un punto di non ritorno, una trasformazione tecnologica e culturale di portata paragonabile all'avvento di Internet. Strumenti capaci di generare testi, immagini, codice e soluzioni a problemi complessi in pochi istanti sono ormai entrati nella pratica quotidiana degli studenti, ridefinendo i paradigmi tradizionali dell'apprendimento, della valutazione e dell'onestà accademica. Di fronte a questa realtà, le istituzioni scolastiche si trovano a un bivio: subire il cambiamento in modo passivo e reattivo, oscillando tra divieti inefficaci e un'adozione acritica, oppure scegliere di governare la complessità, assumendo un ruolo proattivo nella definizione di un nuovo equilibrio.

Questa guida si colloca risolutamente in questa seconda prospettiva. Il suo scopo è fornire un modello operativo per la co-progettazione di un **"Patto di Corresponsabilità per l'Uso Etico dell'AI"**, uno strumento strategico fondamentale per ogni istituto che desideri integrare l'innovazione tecnologica in modo consapevole, sicuro e allineato alla propria missione educativa. L'approccio proposto non è quello di fornire una soluzione preconfezionata, bensì di avviare un processo collaborativo che coinvolga l'intera comunità educante, a partire dal corpo docente.

La finalità ultima di questa attività laboratoriale è duplice. In primo luogo, si intende elevare il livello di consapevolezza collettiva, trasformando le percezioni individuali -- spesso un misto di entusiasmo, preoccupazione e incertezza -- in una comprensione strutturata delle implicazioni normative, etiche e didattiche dell'AI. In secondo luogo, l'obiettivo è eminentemente pratico: tradurre la riflessione in azione, dotando la scuola di un documento di riferimento chiaro, condiviso e operativo.

Un Patto di Corresponsabilità non è un mero regolamento, ma un manifesto culturale. È la dichiarazione pubblica di come una comunità sceglie di relazionarsi con una tecnologia potente, definendo i principi irrinunciabili, i confini da rispettare e gli impegni reciproci che legano studenti, docenti, famiglie e l'istituzione stessa. Attraverso il dialogo guidato e la scrittura collaborativa, i docenti diventano i primi architetti di questo nuovo patto formativo, ponendo le basi per una cultura dell'innovazione responsabile che sappia cogliere le immense opportunità dell'AI senza mai abdicare al primato del pensiero critico, della creatività e della centralità della persona umana.

### Descrizione dell'attività laboratoriale: un percorso in quattro fasi

Il laboratorio è concepito come un percorso strutturato della durata di circa due ore, progettato per essere condotto con gruppi di docenti di scuola secondaria di secondo grado. L'approccio è maieutico e costruttivista: il ruolo del facilitatore è quello di guidare la discussione, fornire stimoli e strumenti, ma il contenuto e il prodotto finale emergono dal lavoro collettivo dei partecipanti.

#### Finalità pedagogiche e strumenti

L'attività si prefigge di raggiungere i seguenti obiettivi:

- **Analisi Critica:** Sviluppare una comprensione approfondita del quadro normativo (AI Act, GDPR) e dei concetti etici chiave (bias, trasparenza, equità) legati all'uso dell'AI in contesti educativi.

- **Progettazione Didattica:** Riflettere sulle modifiche necessarie alle pratiche di insegnamento e valutazione per promuovere l'onestà accademica e valorizzare le competenze umane nell'era dell'AI.

- **Costruzione di Comunità:** Rafforzare il dialogo professionale e la coesione del corpo docente attorno a una sfida comune, favorendo la nascita di un linguaggio e di un approccio condivisi.

- **Produzione Concreta:** Elaborare una bozza avanzata di "Patto di Corresponsabilità" che possa servire come base per il successivo coinvolgimento di studenti e famiglie e per l'integrazione nei documenti ufficiali dell'istituto (PTOF, Regolamento d'Istituto).

Gli strumenti necessari per la conduzione del laboratorio sono semplici e accessibili: uno spazio che favorisca la discussione, una lavagna (tradizionale o digitale) per la mappatura delle idee, un proiettore e un computer con accesso a un editor di testo collaborativo (es. Google Docs) per la stesura collettiva del documento.

#### Fase 1: mappatura delle percezioni e brainstorming guidato (durata: 20 minuti)

**Razionale:** Ogni processo di cambiamento deve partire dall'ascolto e dalla comprensione del punto di vista dei suoi attori. Questa fase iniziale ha lo scopo di far emergere il "non detto": le speranze, le paure, le incertezze e le convinzioni dei docenti riguardo all'AI. Creare una mappa concettuale condivisa permette di stabilire un terreno comune, legittimare tutte le posizioni e focalizzare la discussione successiva sui temi realmente sentiti come prioritari dal gruppo.

**Istruzioni operative per il facilitatore:**

1. **Introduzione e Posizionamento (5 min):** Dopo aver accolto i partecipanti, il facilitatore introduce gli obiettivi del laboratorio, enfatizzando la natura collaborativa e il fine pratico dell'incontro. È cruciale posizionare l'attività non come un momento "top-down" di imposizione di regole, ma come un'opportunità "bottom-up" di co-costruzione di una policy che rispecchi l'identità e le esigenze dell'istituto.

2. **Lancio dello Stimolo (15 min):** Il facilitatore pone al gruppo una domanda aperta e potente, pensata per sollecitare una risposta sia razionale che emotiva. La domanda suggerita è: *"Pensando all'uso che i vostri studenti fanno dell'Intelligenza Artificiale oggi, qual è la vostra più grande preoccupazione e, al contempo, la vostra più grande speranza?"*

3. Il facilitatore modera il giro di interventi, trascrivendo sulla lavagna le parole chiave e i concetti che emergono. È importante non giudicare né filtrare le risposte, ma accoglierle tutte. Progressivamente, le idee vengono raggruppate visivamente in macro-categorie tematiche. L'esperienza suggerisce che emergeranno quasi certamente le seguenti aree:

    - **Onestà Accademica e Plagio:** La preoccupazione più immediata, legata al rischio che l'AI diventi una scorciatoia per evitare lo studio e la rielaborazione personale.

    - **Privacy e Sicurezza dei Dati:** La consapevolezza, più o meno strutturata, che l'interazione con queste piattaforme implica la cessione di dati personali e sensibili.

    - **Equità, Bias e Discriminazione:** La preoccupazione che l'AI possa amplificare le disuguaglianze esistenti o introdurre nuove forme di pregiudizio algoritmico.

    - **Sviluppo del Pensiero Critico:** Il timore che un affidamento eccessivo all'AI possa atrofizzare le capacità cognitive superiori, come la capacità di analisi, sintesi e valutazione.

    - **Creatività e Originalità:** Il dubbio che la facilità di generazione di contenuti possa omologare il pensiero e ridurre lo spazio per l'espressione creativa autentica e originale.

#### Fase 2: analisi guidata e costruzione delle competenze (durata: 40 minuti)

**Razionale:** Dopo aver fatto emergere le percezioni, è necessario fornire al gruppo gli strumenti concettuali per analizzare i problemi in modo più strutturato e informato. Questa fase trasforma le preoccupazioni in domande di ricerca e guida i docenti a trovare risposte basate su fonti normative ed etiche. Il lavoro in piccoli gruppi favorisce la partecipazione attiva e permette di approfondire tematiche specifiche in parallelo.

**Istruzioni operative per il facilitatore:**

1. **Suddivisione in gruppi di lavoro (5 min):** Il facilitatore divide l'uditorio in piccoli gruppi di 3-4 persone, possibilmente eterogenei per disciplina di insegnamento. A ciascun gruppo viene assegnata una delle macro-aree tematiche emerse nella fase precedente.

2. **Consegna e analisi dei materiali (35 min):** Il facilitatore fornisce a tutti i gruppi un set di risorse digitali (vedi Allegato B), che include sintesi della normativa, articoli su etica e didattica ed esempi di policy esistenti. Il compito di ogni gruppo è analizzare questi materiali attraverso la lente della propria tematica, utilizzando delle domande-guida per strutturare la riflessione e preparare una sintesi da condividere.

**Domande guida approfondite per i gruppi:**

- **Gruppo "Onestà Accademica":**

    - Come possiamo superare la dicotomia "uso buono / uso cattivo"? È possibile definire una tassonomia degli usi dell'AI (es. AI come tutor, AI come revisore, AI come fonte di idee, AI come autore)?

    - Quali sono le caratteristiche di un compito "a prova di AI"? Si richiede di elaborare almeno tre esempi concreti di compiti per la propria disciplina che integrino l'AI in modo virtuoso.

    - Come si cita correttamente l'AI? Il gruppo è invitato a elaborare una bozza di linea guida per la citazione, specificando quali informazioni includere (es. prompt utilizzato, data, strumento).

- **Gruppo "Privacy e Sicurezza":**

    - Analizzando le definizioni di "dati personali" del GDPR, si chiede di stilare un elenco dettagliato di informazioni che uno studente non dovrebbe mai inserire in un prompt (es. nomi completi, dati sulla salute, opinioni politiche, dettagli familiari, testi di temi personali).

    - Qual è la differenza tra un account "consumer" e un account "educational/enterprise" di un servizio di AI? Quali garanzie contrattuali (DPA - Data Processing Agreement) la scuola deve esigere da un fornitore?

    - Quali sono le responsabilità del docente nel vigilare sull'uso corretto degli strumenti in classe?

- **Gruppo "Equità e Bias":**

    - Si chiede di cercare e analizzare due esempi concreti di bias algoritmico (di genere, culturale, linguistico) in noti modelli di AI.

    - Come si può trasformare il rischio del bias in un'opportunità didattica? Il gruppo deve progettare un'attività di classe in cui gli studenti sono chiamati a "fare il debiasing" di un testo generato da AI, identificando e correggendo gli stereotipi.

    - Quali misure può adottare la scuola per mitigare il divario digitale e garantire che l'accesso ai benefici dell'AI sia equo per tutti gli studenti?

- **Gruppo "Pensiero Critico e Creatività":**

    - Cosa significa trattare l'AI come un "compagno cognitivo"? Il gruppo deve identificare almeno tre pratiche didattiche in cui l'AI è usata per stimolare domande, esplorare prospettive multiple o superare blocchi creativi.

    - Si chiede di stilare un elenco delle "competenze insostituibilmente umane" che la scuola deve prioritariamente potenziare nell'era dell'AI (es. intelligenza emotiva, pensiero etico, collaborazione complessa, problem solving non strutturato).

    - Come può la valutazione evolvere per dare più peso al processo di ricerca e rielaborazione piuttosto che al solo prodotto finale?

#### Fase 3: sintesi e co-costruzione del documento (durata: 40 minuti)

**Razionale:** Questa è la fase convergente del laboratorio, in cui il lavoro analitico dei gruppi viene messo a sistema per costruire un prodotto comune. La scrittura collaborativa in tempo reale è un potente strumento di mediazione e di sintesi, che trasforma le idee discusse in un testo formale e condiviso, aumentando il senso di appartenenza e di "ownership" del documento finale da parte dei partecipanti.

**Istruzioni operative per il facilitatore:**

1. **Restituzione e sistematizzazione (15 min):** A turno, un portavoce per ogni gruppo presenta alla plenaria i risultati principali della loro analisi. Il facilitatore ha un ruolo attivo: non si limita ad ascoltare, ma proietta un documento di testo vuoto (strutturato secondo il modello dell'Allegato A) e inizia a popolarlo in tempo reale con le proposte dei gruppi, sintetizzando, riformulando e chiedendo conferme.

2. **Scrittura collettiva guidata (25 min):** Con la struttura della bozza visibile a tutti, il facilitatore guida la stesura collettiva del "Patto di Corresponsabilità". Si procede sezione per sezione (Principi, Impegni degli Studenti, Impegni dei Docenti, etc.). Il facilitatore legge ad alta voce le proposte, invita a suggerire formulazioni più chiare o incisive e digita il testo in diretta. È fondamentale incoraggiare un linguaggio positivo e propositivo (privilegiando "Ci impegniamo a..." rispetto a "È vietato..."), che renda il patto uno strumento di empowerment piuttosto che un mero elenco di divieti.

#### Fase 4: Fase operativa e passi futuri (Durata: 20 minuti)

**Razionale:** Nessun documento ha valore se rimane confinato a un incontro di formazione. Quest'ultima fase è cruciale per garantire che il lavoro svolto abbia un seguito concreto e un impatto reale sulla vita dell'istituto. Definire chiaramente i prossimi passi trasforma l'energia del laboratorio in un processo di cambiamento organizzativo.

**Istruzioni operative per il facilitatore:**

1. **Revisione e consolidamento (10 min):** Il facilitatore legge ad alta voce l'intera bozza del "Patto", così come è stata redatta collettivamente. Viene chiesto un ultimo giro di feedback per affinare il testo e assicurarsi che rappresenti il consenso del gruppo.

2. **Pianificazione del follow-up (10 min):** La discussione si sposta sul piano operativo. Il facilitatore guida il gruppo a rispondere a domande chiave:

    - **Finalizzazione:** Chi si assume la responsabilità di revisionare e formattare la bozza? (es. un piccolo comitato di redazione, il referente per l'innovazione).

    - **Condivisione e Feedback:** Come verrà presentato questo documento agli studenti e alle famiglie? (es. durante assemblee di classe dedicate, incontri scuola-famiglia, tramite una comunicazione ufficiale con un modulo per raccogliere feedback).

    - **Validazione Istituzionale:** Qual è l'iter per rendere questo Patto un documento ufficiale della scuola? (es. presentazione al Collegio Docenti, approvazione in Consiglio d'Istituto).

    - **Monitoraggio:** Come verificheremo l'efficacia di questo Patto nel tempo? Si prevede un momento di revisione annuale?

3. Il facilitatore conclude l'incontro ringraziando i partecipanti per il contributo e riaffermando l'importanza del percorso intrapreso, che posiziona la comunità professionale come protagonista dell'innovazione.

#### Allegato A: esempio di "patto di corresponsabilità per l'uso etico dell'AI"

##### I.I.S.S. "Alessandro Greppi"

###### Premessa

L'Istituto di Istruzione Secondaria Superiore "Alessandro Greppi", in linea con la sua tradizione di eccellenza formativa e di attenzione all'innovazione, riconosce l'Intelligenza Artificiale (AI) come una potente risorsa per l'arricchimento della didattica e lo sviluppo delle competenze del XXI secolo. Consapevoli delle profonde implicazioni etiche, culturali e sociali di questa tecnologia, intendiamo promuoverne un'integrazione che sia consapevole, critica, responsabile e pienamente allineata ai principi della nostra Costituzione e alla normativa europea. Questo documento rappresenta il patto che la nostra intera comunità educante -- studenti, docenti, famiglie e istituzione -- stringe per governare insieme questa transizione, assicurando che ogni strumento tecnologico sia sempre al servizio della crescita intellettuale, della creatività e dello sviluppo integrale della persona.

###### I nostri principi fondamentali

1. **Antropocentrismo e centralità della persona:** Affermiamo il primato della persona umana. L'AI è e deve rimanere uno strumento. Nessuna decisione che impatti significativamente il percorso formativo o la valutazione di uno studente può essere delegata interamente a un algoritmo. La relazione educativa, il giudizio professionale del docente e l'interazione umana rimangono il cuore insostituibile del processo di apprendimento.

2. **Onestà intellettuale e valore dell'impegno:** Riconosciamo che l'apprendimento autentico è un processo che richiede impegno, fatica, riflessione e rielaborazione personale. L'AI può supportare questo processo, ma non deve mai diventare una scorciatoia per eluderlo. L'onestà accademica è un valore non negoziabile.

3. **Sviluppo del pensiero critico:** Il nostro obiettivo non è insegnare a "usare" l'AI, ma a "pensare con e oltre" l'AI. Ci impegniamo a sviluppare la capacità di interrogare, verificare, analizzare criticamente e contestualizzare ogni informazione prodotta da un sistema artificiale, riconoscendone limiti, errori e potenziali bias.

4. **Equità, inclusione e rifiuto del pregiudizio:** Vigileremo attivamente affinché l'uso dell'AI non crei né amplifichi disuguaglianze. Ci impegniamo a promuovere un accesso equo alle risorse, a educare al riconoscimento dei bias algoritmici e a utilizzare la tecnologia come strumento per l'inclusione e la personalizzazione, nel rispetto delle unicità di ciascuno.

5. **Responsabilità e sicurezza:** La tutela dei dati personali e la sicurezza digitale sono una responsabilità condivisa. Ci impegniamo a rispettare rigorosamente la normativa (GDPR, AI Act) e ad adottare comportamenti che proteggano la privacy individuale e la sicurezza dell'intera comunità scolastica.

**Come studentesse e studenti, ci impegniamo a:**

- Utilizzare l'AI come un "compagno cognitivo": uno strumento per esplorare idee, chiarire dubbi, rivedere bozze e superare ostacoli, non come un sostituto del nostro lavoro e del nostro pensiero.

- Dichiarare sempre in modo trasparente e onesto l'utilizzo dell'AI nei nostri lavori, seguendo le specifiche indicazioni fornite da ciascun docente per ogni attività.

- Non presentare mai come interamente nostro un testo, un'immagine, un codice o qualsiasi altro elaborato generato da un'AI, in quanto ciò costituisce una violazione del principio di onestà accademica.

- Essere custodi dei nostri dati personali e di quelli dei nostri compagni, evitando di inserire informazioni sensibili o identificative in piattaforme di AI pubbliche o non approvate dall'Istituto.

- Esercitare il nostro pensiero critico, verificando sempre l'accuratezza, la pertinenza e l'assenza di bias nelle informazioni fornite dall'AI, confrontandole con altre fonti autorevoli.

- Segnalare ai docenti eventuali output dell'AI che risultino palesemente errati, inappropriati, offensivi o discriminatori.

**Come docenti, ci impegniamo a:**

- Progettare percorsi didattici e valutativi che valorizzino le competenze umane superiori (pensiero critico, creatività, problem solving complesso, collaborazione) e che rendano l'uso fraudolento dell'AI pedagogicamente irrilevante.

- Fornire indicazioni chiare, esplicite e differenziate per ogni attività didattica su quando, come e perché l'uso dell'AI è consentito, incoraggiato o sconsigliato.

- Dedicarci a una formazione continua per comprendere l'evoluzione dell'AI e per sviluppare le competenze necessarie a guidare gli studenti verso un uso etico ed efficace di questi strumenti.

- Selezionare e utilizzare esclusivamente piattaforme e software di AI che siano conformi alla normativa sulla protezione dei dati e che siano stati approvati dall'Istituto, garantendo un ambiente di apprendimento sicuro.

- Mantenere la centralità del nostro giudizio professionale nel processo di valutazione, utilizzando gli strumenti di AI come supporto ma mai come sostituti della nostra responsabilità valutativa finale.

- Educare esplicitamente gli studenti sui rischi dell'AI, inclusi i bias algoritmici, le "allucinazioni" (informazioni false), la disinformazione e le implicazioni per la privacy.

**Come istituzione scolastica e famiglie, ci impegniamo a:**

- Promuovere un dialogo costante e costruttivo tra tutte le componenti della comunità scolastica per monitorare e aggiornare periodicamente il presente Patto.

- Garantire, come Istituto, l'accesso a un'infrastruttura tecnologica e a una selezione di strumenti software sicuri, equi e pedagogicamente validi.

- Sostenere, come Istituto, la formazione dei docenti e l'organizzazione di iniziative informative per studenti e famiglie.

- Collaborare, come Famiglie, con la scuola per promuovere un uso equilibrato e consapevole delle tecnologie digitali anche in ambito domestico, supportando i principi di onestà e impegno nello studio.

#### Allegato B: risorse e materiali di supporto per il laboratorio

- **Quadro normativo (link e sintesi):**

    - **AI Act (Regolamento UE 2024/1689):** [Testo ufficiale su EUR-Lex](https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689 "null"). Si raccomanda la lettura della sintesi commentata degli Articoli 5 (Pratiche Vietate), 6 (Sistemi ad Alto Rischio) e dell'Allegato III (focus su Istruzione).

    - **GDPR (Regolamento UE 2016/679):** [Testo ufficiale su EUR-Lex](https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679 "null"). Si raccomanda la lettura guidata degli Articoli 5 (Principi), 6 (Base Giuridica) e 35 (Valutazione d'Impatto) nel contesto scolastico.

- **Articoli di approfondimento su etica e didattica:**

    - **"Bias within AI: unpacking the risks and opportunities for education" (UNESCO):** [Leggi l'articolo](https://unesdoc.unesco.org/ark:/48223/pf0000386670). Un'analisi autorevole su come i bias di genere e culturali si manifestano nei modelli di AI.

    - **"A Generative AI Guide for Educators" (Vanderbilt University):** [Consulta la guida (PDF)](https://cdn.vanderbilt.edu/vu-sub/wp-content/uploads/sites/59/2023/09/09144130/Teaching-in-the-Age-of-AI-PRINT-VERSION.pdf). Un esempio di guida che illustra come formulare prompt per trasformare l'AI in uno strumento di riflessione.

    - **"Rethinking Assessment in the Age of AI" (Getting Smart):** [Leggi l'articolo](https://www.csu.edu.au/division/learning-teaching/assessments/assessment-and-artificial-intelligence/rethinking-assessments). Un saggio che esplora nuove forme di valutazione che valorizzano le competenze non automatizzabili.

- **Esempi pratici e strumenti:**

    - **Policy di atenei internazionali:**

        - [MIT - Academic Integrity & AI](https://library.mit.edu.au/c.php?g=968719&p=7042933)

        - [University of Sydney - Generative AI in learning](https://www.sydney.edu.au/students/academic-integrity/artificial-intelligence.html)

        - [ETH Zurich - AI and Plagiarism Policy](https://library.ethz.ch/en/researching-and-publishing/scientific-writing-at-eth-zurich/prevention-of-plagiarism.html)

    - **Guida alla citazione dell'AI:**

        - [APA Style: How to cite ChatGPT](https://apastyle.apa.org/blog/how-to-cite-chatgpt "null")

        - [MLA Style: How to Cite Generative AI](https://style.mla.org/citing-generative-ai/ "null")

    - **UNESCO - AI and Education:** [Visita il portale](https://www.unesco.org/en/digital-education/artificial-intelligence). Il portale di riferimento dell'UNESCO con risorse e raccomandazioni globali sull'integrazione dell'AI nei sistemi educativi.

## Conclusioni e prossimi passi

L'integrazione dell'Intelligenza Artificiale nel mondo della scuola non è più un'ipotesi futuribile, ma una realtà presente e in rapida evoluzione. Le sfide che pone sono complesse e non ammettono risposte semplicistiche. Come abbiamo visto in questo percorso, un approccio puramente entusiasta rischia di ignorare i pericoli, mentre un atteggiamento di chiusura e divieto è destinato a essere superato dalla realtà e a privare gli studenti di opportunità formative cruciali.

La via maestra, delineata dalla normativa europea e da modelli di policy illuminati come il "Documento di Indirizzo"[^2], è quella del **governo consapevole**. L'obiettivo non è vietare l'AI, ma governarla, plasmarla secondo i fini educativi della scuola e i valori di una società democratica. Questo richiede un impegno corale da parte di tutta la comunità scolastica.

I punti chiave emersi sono chiari:

1. **La conformità normativa non è un optional:** Il rispetto dell'AI Act[^1] e del GDPR[^3] è il fondamento per un'innovazione sicura e che tuteli i diritti di tutti.

2. **La prevenzione è meglio della repressione:** Di fronte a sfide come il plagio, la riprogettazione didattica è una strategia più efficace e pedagogicamente più ricca del mero controllo.

3. **La governance è essenziale:** Ogni scuola deve dotarsi di una AI Policy chiara, che definisca ruoli, responsabilità e procedure.

4. **La responsabilità è e deve rimanere umana:** Nessuna tecnologia può sostituire il giudizio critico, l'empatia e la responsabilità etica del docente.

L'invito finale è rivolto a tutti i docenti: diventare protagonisti attivi di questo processo. Ciò significa formarsi continuamente, sperimentare con prudenza e spirito critico, collaborare con i colleghi e, soprattutto, educare gli studenti a essere non solo consumatori passivi, ma cittadini digitali consapevoli, capaci di comprendere, utilizzare e interrogare criticamente la tecnologia più potente del nostro tempo. Promuovendo una cultura della responsabilità e dell'innovazione etica all'interno della propria comunità, possiamo assicurare che l'Intelligenza Artificiale diventi un potente alleato per una scuola più equa, inclusiva ed efficace.

## Riferimenti

[^1]: Parlamento Europeo e Consiglio, "Regolamento (UE) 2024/1689 del 13 giugno 2024 che stabilisce regole armonizzate sull'intelligenza artificiale (regolamento sull'intelligenza artificiale)".

[^2]: [Istituto di Istruzione Secondaria Superiore "Alessandro Greppi", "Documento di Indirizzo Strategico per l'Integrazione dell'Intelligenza Artificiale nell'Istituto", Versione 1.0, Ottobre 2025](../../ai-regulations/documento-di-indirizzo-integrazione-ai-in-istituto).

[^3]: Parlamento Europeo e Consiglio, "Regolamento (UE) 2016/679 del 27 aprile 2016 relativo alla protezione delle persone fisiche con riguardo al trattamento dei dati personali, nonché alla libera circolazione di tali dati".

[^4]: Ministero dell'Istruzione e del Merito, "Linee guida per l'introduzione dell'Intelligenza Artificiale nelle Istituzioni scolastiche", Versione 1.0, 2025.

[^5]: [La valutazione dell'Impatto sui diritti fondamentali (Fundamental Rights Impact Assessment, "FRIA")](https://www.piselliandpartners.com/news-di-settore/blockchain-intelligenza-artificiale/la-valutazione-dellimpatto-sui-diritti-fondamentali-fundamental-rights-impact-assessment-fria/)

[^6]: [Valutazione d impatto sulla protezione dei dati - DPIA](https://www.gpdp.it/web/guest/home/docweb/-/docweb-display/docweb/7185457)

[^7]: Council of Europe, ["Methodology for the risk and impact assessment of artificial intelligence systems (HUDERIA)"](https://rm.coe.int/cai-2024-16rev2-methodology-for-the-risk-and-impact-assessment-of-arti/1680b2a09f), 2024.

[^8]: Council of Europe, ["HUDERIA - Risk and Impact Assessment of AI Systems"](https://www.coe.int/en/web/artificial-intelligence/huderia-risk-and-impact-assessment-of-ai-systems)
