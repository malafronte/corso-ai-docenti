---
title: Uso responsabile, etica e sicurezza dell'IA a scuola
description: Intelligenza Artificiale a scuola - Guida per un uso responsabile, etico e sicuro
---

## Introduzione

L'avvento dell'Intelligenza Artificiale (IA) sta segnando una trasformazione epocale in ogni settore della società e il mondo dell'istruzione non fa eccezione. Da strumento di supporto per la personalizzazione didattica a risorsa per l'ottimizzazione dei processi amministrativi, le potenzialità dell'IA per la scuola sono tanto vaste quanto entusiasmanti. Tuttavia, come ogni grande innovazione tecnologica, essa porta con sé interrogativi complessi e sfide significative che non possono essere ignorate. Accanto alle straordinarie opportunità, emergono questioni cruciali in termini di etica, sicurezza dei dati, equità e responsabilità.

La scuola, in quanto agenzia educativa fondamentale per la formazione dei cittadini di domani, ha il dovere di affrontare questa transizione non in modo passivo o reattivo, ma con un approccio proattivo, critico e governato. Non si tratta semplicemente di "usare" l'IA, ma di integrarla in modo consapevole, allineandola con i principi pedagogici, i valori costituzionali e il quadro normativo che regola il sistema di istruzione.

Questo articolo si propone come una guida esaustiva per i docenti della scuola secondaria di secondo grado, con l'obiettivo di fornire un quadro completo per navigare le complessità dell'IA nella didattica. La nostra analisi si fonderà su due pilastri fondamentali. Da un lato, esamineremo il quadro normativo europeo, con particolare riferimento al Regolamento sull'Intelligenza Artificiale (noto come **AI Act**)[^1], che stabilisce le regole per un'IA affidabile e antropocentrica. Dall'altro, ci avvarremo di un modello pratico e concreto di policy scolastica, il **"Documento di Indirizzo Strategico per l'Integrazione dell'Intelligenza Artificiale"** dell'Istituto Greppi (d'ora in poi "Documento di Indirizzo")[^2], che traduce i principi normativi in azioni operative per la comunità scolastica.

Attraverso un percorso strutturato in capitoli, affronteremo la normativa di riferimento, le strategie didattiche per promuovere l'onestà accademica nell'era dell'IA generativa, il processo di costruzione di una policy d'istituto e le profonde implicazioni etiche legate ai bias algoritmici e alla responsabilità umana. L'obiettivo finale è quello di equipaggiare ogni docente, a prescindere dalla disciplina di insegnamento, con le conoscenze e gli strumenti necessari per diventare un attore protagonista di un'innovazione responsabile, sicura e realmente al servizio della crescita di ogni studente.

## Capitolo 1: Il Quadro Normativo di Riferimento per la Scuola

L'integrazione dell'Intelligenza Artificiale nel contesto scolastico non può prescindere da una solida comprensione del quadro giuridico che ne regola l'utilizzo. La scuola, in quanto pubblica amministrazione che tratta dati particolarmente sensibili di soggetti vulnerabili come i minori, è chiamata a un rigore normativo ancora maggiore. Le due colonne portanti di questo quadro sono il Regolamento Generale sulla Protezione dei Dati (GDPR)[^3] e, più specificamente per il nostro ambito, il nuovo Regolamento europeo sull'Intelligenza Artificiale (AI Act)[^1].

### 1.1 L'AI Act Europeo: La Bussola per la Didattica

L'AI Act[^1] rappresenta la prima legislazione orizzontale al mondo sull'IA e stabilisce un modello per la sua governance basato su un approccio stratificato in base al rischio (*risk-based approach*). Come evidenziato nel "Documento di Indirizzo"[^2], lo scopo del regolamento è "promuovere la diffusione di un'intelligenza artificiale (IA) antropocentrica e affidabile, garantendo nel contempo un livello elevato di protezione della salute, della sicurezza e dei diritti fondamentali". Per la scuola, questo si traduce in un obbligo non solo di cogliere le opportunità, ma anche di governare i rischi. L'AI Act[^1] classifica i sistemi di IA in diverse categorie, ognuna con obblighi specifici.

#### Pratiche di IA Vietate (Articolo 5)

L'articolo 5 dell'AI Act[^1] elenca una serie di pratiche considerate inaccettabili perché contrarie ai valori fondamentali dell'Unione Europea. Per il contesto scolastico, è essenziale comprendere e interdire categoricamente l'uso di sistemi che:

- **Utilizzano tecniche subliminali o manipolative:** È vietato l'uso di sistemi che distorcono il comportamento degli individui in modo da causare un danno fisico o psicologico significativo. Questo principio protegge l'autonomia di giudizio e la vulnerabilità psicologica degli studenti da tecnologie che potrebbero influenzarli senza che ne siano consapevoli.

- **Sfruttano le vulnerabilità di gruppi specifici:** La normativa vieta esplicitamente l'uso di IA che sfrutti le vulnerabilità legate a età, disabilità o situazione socio-economica per alterare il comportamento in modo dannoso. La popolazione studentesca, in particolare i minori, rientra a pieno titolo in questa categoria di protezione speciale.

- **Effettuano "punteggio sociale" (social scoring):** È proibito l'uso di sistemi di IA da parte di autorità pubbliche (come la scuola) per classificare l'affidabilità delle persone sulla base del loro comportamento sociale o delle loro caratteristiche personali, qualora ciò porti a un trattamento pregiudizievole o sproporzionato. Il principio di non classificazione aprioristica delle persone è un caposaldo etico da applicare rigorosamente in ambito educativo.

- **Inferiscono le emozioni in contesti educativi:** Di cruciale e diretta applicazione per la scuola è il divieto, sancito dall'art. 5 dell'AI Act[^1], di utilizzare sistemi di IA "per inferire le emozioni di una persona fisica nell'ambito degli istituti di istruzione", salvo per motivi medici o di sicurezza. Ciò significa che è illegale l'uso di software che pretendano di analizzare l'espressione facciale o il tono della voce di uno studente durante una lezione o una verifica per valutarne il livello di attenzione, la comprensione o la sincerità. L'eccezione per motivi di sicurezza deve essere interpretata in modo estremamente restrittivo e sempre sotto supervisione umana qualificata.

#### Sistemi di IA ad Alto Rischio (Articolo 6 e Allegato III)

Questa è la categoria di maggior impatto per le istituzioni scolastiche. Un sistema di IA è classificato come "ad alto rischio" quando il suo utilizzo può avere un impatto significativo sui diritti fondamentali e sulla sicurezza delle persone. L'Allegato III dell'AI Act[^1] identifica esplicitamente i sistemi utilizzati nel settore **"Istruzione e formazione professionale"** come potenzialmente ad alto rischio. Nello specifico, rientrano in questa categoria i sistemi destinati a:

- **Determinare l'accesso o l'ammissione a istituti di istruzione:** Ad esempio, un software che selezioni automaticamente le candidature per un corso a numero chiuso o che assegni gli studenti alle classi sulla base di determinati parametri.

- **Valutare i risultati dell'apprendimento:** Rientrano in questa definizione i sistemi di correzione automatizzata di compiti, test o esami che abbiano un impatto determinante sulla valutazione finale dello studente e, di conseguenza, sul suo percorso formativo. L'uso di un software per correggere un quiz a scelta multipla a scopo formativo può essere a basso rischio, ma se lo stesso software è usato per un esame finale, il sistema diventa ad alto rischio.

- **Monitorare e rilevare comportamenti vietati durante le prove:** I software di *proctoring* che utilizzano l'IA per monitorare gli studenti durante gli esami a distanza (analizzando suoni, movimenti o sguardi) sono un esempio lampante di sistemi ad alto rischio.

L'adozione di un sistema ad alto rischio impone alla scuola, in qualità di "utilizzatore" (*deployer*), una serie di obblighi stringenti. Come sottolinea il "Documento di Indirizzo"[^2], questi includono la necessità di garantire una **sorveglianza umana efficace** (art. 14 dell'AI Act[^1]), utilizzare i sistemi secondo le istruzioni del fornitore, monitorarne il funzionamento e, aspetto fondamentale, condurre una **Valutazione d'impatto sui diritti fondamentali (FRIA)** prima di mettere in uso il sistema (art. 27 dell'AI Act[^1]). La responsabilità della scuola non è solo tecnica, ma anche etica e giuridica.

#### Sistemi a Rischio Limitato (Articolo 50)

Questi sistemi sono soggetti a obblighi di trasparenza, come definito nell'articolo 50 dell'AI Act[^1]. Chi interagisce con essi deve essere sempre consapevole di avere a che fare con una macchina. Nel contesto scolastico, gli esempi più comuni sono:

- **Chatbot per l'orientamento o il supporto didattico:** Gli studenti devono essere chiaramente informati che stanno dialogando con un sistema di IA e non con un essere umano.

- **Sistemi che generano contenuti (deepfake):** Se un docente utilizza un sistema di IA per creare un video didattico con un avatar, un'immagine per una presentazione o un testo da analizzare, deve essere chiaramente indicato che il contenuto è stato generato o manipolato artificialmente.

### 1.2 I Principi del GDPR nell'Era dell'IA

Ogni volta che un sistema di IA tratta dati personali (e in ambito scolastico questo avviene quasi sempre), il suo utilizzo deve essere pienamente conforme al GDPR[^3]. Il "Documento di Indirizzo"[^2], nel suo paragrafo 1.2.2, fornisce un vademecum operativo essenziale per la scuola, che agisce come Titolare del Trattamento.

#### La Base Giuridica: il Compito di Interesse Pubblico

Il trattamento di dati personali è lecito solo se si fonda su una delle sei basi giuridiche previste dall'articolo 6 del GDPR[^3]. Per un'istituzione scolastica pubblica, la base giuridica preminente è l'**esecuzione di un compito di interesse pubblico** (art. 6, par. 1, lett. e del GDPR[^3]). L'interesse pubblico perseguito dalla scuola è la sua missione istituzionale: l'istruzione, l'educazione e la formazione degli studenti. Pertanto, qualsiasi trattamento di dati tramite IA deve essere strettamente **necessario e proporzionato** al raggiungimento di finalità educative, didattiche o amministrative.

È fondamentale, come evidenziato nel "Documento di Indirizzo"[^2], **evitare di fare affidamento sul consenso** come base giuridica per i trattamenti essenziali. A causa del chiaro squilibrio di potere tra la scuola e l'interessato (studente/famiglia), il consenso difficilmente potrebbe essere considerato "liberamente prestato". Può essere utilizzato solo per attività puramente facoltative e non essenziali (es. la partecipazione a un progetto extracurricolare che fa uso di IA).

#### L'obbligatorietà della Valutazione di Impatto (DPIA e FRIA)

Come indicato nelle Linee Guida del Ministero dell'Istruzione e del Merito[^4] e ribadito nel "Documento di Indirizzo"[^2], l'uso di sistemi di IA in ambito scolastico rende quasi sempre **obbligatoria una Valutazione di Impatto sulla Protezione dei Dati (DPIA)** ai sensi dell'art. 35 del GDPR[^3]. Si tratta infatti di un "uso di nuove tecnologie" applicato su "larga scala" a dati di "soggetti vulnerabili", tre condizioni che attivano l'obbligo di DPIA.

La DPIA non è un mero adempimento burocratico, ma un'analisi sistematica che la scuola deve compiere *prima* di adottare un sistema di IA per comprenderne, valutarne e mitigarne i rischi. La valutazione deve considerare:

1. **Descrizione del trattamento:** Quali dati vengono trattati? Per quali finalità? Chi vi ha accesso?

2. **Valutazione di necessità e proporzionalità:** L'uso dell'IA è davvero necessario? Esistono alternative meno intrusive per raggiungere lo stesso obiettivo?

3. **Analisi dei rischi per i diritti e le libertà:** Quali sono i potenziali rischi? Ad esempio:

    - **Discriminazione algoritmica (Bias):** Un software di valutazione potrebbe penalizzare studenti con background linguistici non standard.

    - **Violazione della privacy:** Un attacco informatico potrebbe esporre dati accademici e personali sensibili.

    - **Errore di valutazione:** Un sistema di correzione automatica potrebbe non comprendere una risposta corretta ma formulata in modo creativo.

    - **Effetto di sorveglianza (*chilling effect*):** La percezione di essere costantemente monitorati potrebbe inibire la creatività degli studenti.

4. **Individuazione delle misure di mitigazione:** Quali contromisure tecniche (es. pseudonimizzazione, crittografia) e organizzative (es. supervisione umana obbligatoria, formazione dei docenti, procedure di ricorso) verranno adottate?

Quando un sistema è classificato come "ad alto rischio" dall'AI Act[^1], questa DPIA deve essere integrata con gli elementi di una **FRIA (Fundamental Rights Impact Assessment)**, analizzando in modo ancora più approfondito l'impatto sui diritti fondamentali come la dignità umana, la non discriminazione e la libertà di espressione.

## Capitolo 2: Il Dilemma del Plagio e l'Onestà Accademica

L'ascesa dei modelli linguistici di grandi dimensioni (LLM) come GPT-4 ha introdotto una nuova e complessa sfida per il mondo dell'istruzione: la ridefinizione del concetto di plagio e di onestà accademica. Se uno studente può generare un tema, un saggio o la soluzione a un problema in pochi secondi, come possiamo valutare le sue reali competenze? La tentazione di un approccio puramente repressivo, basato sulla caccia al testo generato dall'IA, è forte, ma rischia di essere inefficace e pedagogicamente controproducente. Un approccio più maturo e sostenibile sposta il focus dalla repressione alla prevenzione, attraverso una riprogettazione consapevole delle attività didattiche.

### 2.1 Riconoscere l'Uso dell'IA: Strumenti e Limiti

Sono emersi numerosi strumenti, spesso chiamati "AI detector", che promettono di identificare se un testo è stato scritto da un umano o generato da un'intelligenza artificiale. Questi software analizzano caratteristiche del testo come la "perplessità" (la prevedibilità delle parole) e la "burstiness" (la variazione nella lunghezza delle frasi), che tendono a essere diverse tra la scrittura umana e quella artificiale.

Tuttavia, è fondamentale essere consapevoli dei loro limiti:

- **Affidabilità limitata:** Nessuno di questi strumenti è accurato al 100%. La loro efficacia varia a seconda del modello di IA utilizzato per generare il testo, della complessità dell'argomento e della lingua. Modelli più recenti e sofisticati sono sempre più difficili da individuare.

- **Rischio di falsi positivi:** Il limite più pericoloso è la possibilità che lo strumento segnali erroneamente come artificiale un testo scritto da un essere umano. Questo può accadere con studenti che hanno uno stile di scrittura molto strutturato o con persone non madrelingua che tendono a usare frasi più semplici e prevedibili. Basare una decisione disciplinare o una valutazione negativa unicamente sull'output di un AI detector è ingiusto e rischioso.

- **Evoluzione continua:** Gli sviluppatori di modelli di IA lavorano costantemente per rendere i loro output sempre più indistinguibili da quelli umani, in una sorta di "corsa agli armamenti" tecnologica che rende gli strumenti di rilevamento rapidamente obsoleti.

Pertanto, gli AI detector possono essere usati come un primo campanello d'allarme, un indizio che suggerisce un approfondimento, ma **mai come prova definitiva**. La valutazione finale deve basarsi sul dialogo con lo studente, su verifiche orali e sull'analisi complessiva del suo lavoro.

### 2.2 Progettare Compiti "a Prova di IA"

La strategia più efficace non è inseguire l'IA, ma renderne l'uso scorretto meno vantaggioso o irrilevante. Si tratta di progettare compiti e verifiche che valutino competenze di ordine superiore, quelle che (almeno per ora) l'IA non possiede: il pensiero critico, la creatività, l'esperienza personale, la capacità di sintesi originale e di argomentazione. Come suggerisce il "Documento di Indirizzo"[^2], si tratta di considerare l'IA come un **"compagno cognitivo" (*****cognitive partner*****)**, uno strumento da utilizzare e interrogare, non una scorciatoia da sfruttare.

Ecco alcuni esempi pratici di strategie didattiche:

- **Richiedere analisi critiche degli output dell'IA:** Invece di chiedere "Scrivi un saggio sulla Rivoluzione Francese", si può assegnare: "Usa un modello di IA per generare un saggio sulla Rivoluzione Francese. Poi, scrivi una relazione in cui analizzi l'output: quali sono i suoi punti di forza? Quali errori o imprecisioni contiene? Quali prospettive o interpretazioni storiografiche ignora? Quali bias (ad esempio, una visione eurocentrica) puoi identificare nel testo?". Questo tipo di compito non solo neutralizza il plagio, ma sviluppa competenze di *AI literacy* e pensiero critico.

- **Basarsi sull'esperienza personale e sul contesto locale:** Compiti che richiedono agli studenti di collegare i concetti studiati alla loro vita, alla loro comunità o a eventi recenti sono intrinsecamente "a prova di IA". Ad esempio: "Intervista un tuo parente che ha vissuto gli anni '70 e confronta il suo racconto con le fonti storiche che abbiamo studiato" oppure "Analizza l'impatto economico di quella nuova azienda sul nostro territorio".

- **Utilizzare fonti specifiche e recenti:** L'IA generativa ha una "conoscenza" che si ferma a una certa data e spesso non ha accesso a documenti specifici (come un articolo scientifico pubblicato la settimana scorsa o una dispensa fornita dal docente). Assegnare compiti che richiedono l'analisi di tali fonti rende l'IA meno utile.

- **Privilegiare la discussione e la presentazione orale:** La capacità di discutere, argomentare e rispondere a domande in tempo reale rimane una competenza prettamente umana. Le presentazioni orali, i dibattiti in classe (*debate*), le interrogazioni e le discussioni di gruppo sono strumenti di valutazione eccellenti.

- **Svolgere il lavoro in classe:** Una parte significativa del processo di scrittura o di risoluzione di problemi può essere svolta in classe, sotto la supervisione del docente. Questo non significa tornare a un modello puramente trasmissivo, ma creare momenti di "laboratorio" in cui gli studenti lavorano individualmente o in gruppo, potendo contare sul supporto del docente (e, perché no, anche di un uso guidato e trasparente dell'IA).

### 2.3 Le App più usate dagli Studenti: Conoscerle per Guidarle

Per guidare gli studenti verso un uso corretto, è essenziale che i docenti conoscano gli strumenti che essi utilizzano quotidianamente. Tra le applicazioni di IA generativa più diffuse troviamo:

- **ChatGPT (OpenAI):** Il più famoso modello linguistico, capace di generare testo, tradurre, scrivere codice e rispondere a domande su una vasta gamma di argomenti.

    - **Punti di forza:** Versatilità, facilità d'uso, capacità di generare testo coerente e ben strutturato.

    - **Rischi:** Tendenza a inventare informazioni ("allucinazioni"), conoscenza non aggiornata in tempo reale (nella versione gratuita), bias presenti nei dati di addestramento, problemi di privacy legati all'uso dei dati inseriti dagli utenti.

- **Perplexity AI:** Un motore di ricerca conversazionale che combina le capacità di un LLM con la ricerca web in tempo reale, fornendo risposte corredate di fonti e citazioni.

    - **Punti di forza:** Fornisce risposte aggiornate e verificabili, cita le fonti, riducendo il rischio di "allucinazioni".

    - **Rischi:** La qualità delle risposte dipende dalla qualità delle fonti trovate sul web; richiede comunque una verifica critica delle fonti citate.

- **Midjourney / DALL-E 3 / Stable Diffusion:** Piattaforme per la generazione di immagini a partire da una descrizione testuale (*prompt*).

    - **Punti di forza:** Enorme potenziale creativo per la creazione di materiale visivo originale per presentazioni, progetti e lavori artistici.

    - **Rischi:** Possibilità di creare immagini false o ingannevoli (*deepfake*), bias stereotipati (es. rappresentazioni di genere o etniche), questioni legate al diritto d'autore.

- **GitHub Copilot:** Uno strumento di IA che si integra negli ambienti di sviluppo e suggerisce righe di codice o intere funzioni ai programmatori.

    - **Punti di forza:** Accelera notevolmente il processo di scrittura del codice, aiuta a imparare nuove sintassi.

    - **Rischi:** Rischio di fare affidamento eccessivo sullo strumento senza comprendere la logica del codice generato, possibilità che il codice suggerito contenga errori o vulnerabilità di sicurezza.

Conoscere questi strumenti permette al docente non di proibirli, ma di educare gli studenti a un loro uso consapevole, critico e, soprattutto, onesto.

## Capitolo 3: Costruire una Policy d'Istituto sull'IA

L'integrazione dell'Intelligenza Artificiale nella vita scolastica non può essere lasciata all'iniziativa individuale o all'improvvisazione. Un approccio frammentato e non governato rischia di creare disuguaglianze, esporre l'istituto a rischi legali e di sicurezza, e vanificare le potenzialità educative della tecnologia. Per questo motivo, ogni scuola ha bisogno di una **AI Policy**, un documento strategico che definisca una visione, stabilisca regole chiare e assegni responsabilità precise.

### 3.1 Perché ogni Scuola ha Bisogno di una AI Policy

Utilizzando il "Documento di Indirizzo"[^2] come modello, possiamo comprendere l'importanza cruciale di una policy d'istituto. Un tale documento serve a:

- **Garantire la conformità normativa:** Stabilisce le procedure per assicurare che ogni uso dell'IA sia conforme all'AI Act[^1] e al GDPR[^3], proteggendo l'istituto, il personale e gli studenti da rischi legali.

- **Promuovere un'innovazione etica:** Definisce i principi etici (equità, trasparenza, centralità umana) che devono guidare l'adozione di qualsiasi strumento, assicurando che la tecnologia sia al servizio del progetto educativo e non viceversa.

- **Creare un quadro di riferimento comune:** Fornisce a dirigenti, docenti, personale, studenti e famiglie un insieme di regole e linee guida chiare e condivise, riducendo l'incertezza e promuovendo pratiche coerenti in tutto l'istituto.

- **Orientare le scelte strategiche:** Funge da bussola per le decisioni future in materia di investimenti, formazione e sviluppo didattico, assicurando che l'integrazione dell'IA sia "consapevole, etica e normativamente corretta".

- **Gestire i rischi:** Permette di identificare, valutare e mitigare in modo proattivo i rischi legati alla privacy, alla sicurezza informatica, ai bias algoritmici e all'onestà accademica.

Una AI Policy non è un manuale tecnico, ma un documento di governance che traduce una visione educativa in pratica quotidiana.

### 3.2 Gli Attori e le Responsabilità

Una policy efficace deve definire chiaramente "chi fa che cosa". Basandosi sulla struttura del Capitolo 2 del "Documento di Indirizzo"[^2], possiamo delineare i ruoli e le azioni concrete per le diverse figure scolastiche.

#### Governance (Dirigente Scolastico e Consiglio d'Istituto)

La responsabilità primaria della guida strategica ricade sugli organi di governo della scuola.

- **Azioni concrete:**

    - **Istituzione di un Gruppo di Lavoro per l'IA:** Un team multidisciplinare (presieduto dal Dirigente e composto da DPO, Animatore Digitale, docenti referenti, personale ATA, studenti e genitori) con il mandato di mappare i bisogni, valutare le proposte di adozione di nuovi strumenti e supervisionare l'attuazione della policy.

    - **Integrazione nei documenti strategici:** La visione sull'IA deve essere integrata nel Piano Triennale dell'Offerta Formativa (PTOF), definendo traguardi di competenza specifici (es. nel curricolo di Educazione Civica Digitale), un piano di formazione per il personale e criteri chiari per l'uso dell'IA nei processi valutativi.

    - **Definizione di un budget dedicato:** Stanziamento di fondi specifici per l'acquisizione di software, la formazione e l'adeguamento delle infrastrutture.

#### Conformità Normativa (Responsabile della Protezione dei Dati - DPO)

Il DPO è la figura cardine per garantire la conformità al GDPR[^3] e all'AI Act[^1].

- **Azioni concrete:**

    - **Creazione di un "Registro dei Trattamenti IA":** Una sezione specifica del Registro delle Attività di Trattamento (ex Art. 30 GDPR[^3]) che documenti per ogni sistema di IA la finalità, la base giuridica, i dati trattati e la classificazione del rischio.

    - **Gestione delle DPIA/FRIA:** Sviluppare una procedura standard e supportare la scuola nella conduzione delle Valutazioni di Impatto prima dell'adozione di ogni nuovo strumento.

    - **Revisione dei contratti con i fornitori:** Verificare che ogni fornitore di servizi di IA sia nominato Responsabile del Trattamento tramite un contratto conforme all'Art. 28 del GDPR[^3] e che offra adeguate garanzie sulla sicurezza e la localizzazione dei dati.

#### Implementazione (Animatore Digitale)

L'Animatore Digitale ha il ruolo di coordinatore pedagogico e tecnico dell'implementazione.

- **Azioni concrete:**

    - **Formazione dei docenti:** Progettare e coordinare un piano di formazione continua, differenziato per livelli di competenza, sui principi etici, normativi e sull'uso didattico degli strumenti. Un esempio concreto di modulo formativo potrebbe includere:

        > **Attività laboratoriale:** discussione guidata e stesura collaborativa di una bozza di "Patto di corresponsabilità" o di linee guida per l'uso etico dell'IA in classe, da condividere con studenti e famiglie.
        >
        > **Materiali forniti:** articoli su etica e IA, link alla normativa di riferimento, esempi di policy sull'IA adottate da altre scuole/università.

    - **Creazione di una "Software Library":** Curare un elenco ragionato e approvato di strumenti di IA sicuri ed efficaci. Per ogni strumento, la libreria deve indicare la finalità didattica, il livello di rischio (con link alla relativa DPIA) e una guida all'uso. Questo serve a orientare i docenti verso software già valutati, evitando l'uso incontrollato di piattaforme non verificate.

#### Uso Didattico (Docenti)

I docenti sono gli attori principali dell'integrazione dell'IA nel processo di apprendimento.

- **Azioni concrete:**

    - **Formazione continua:** Partecipare attivamente alle iniziative di formazione per acquisire le competenze necessarie.

    - **Uso responsabile:** Utilizzare prioritariamente gli strumenti della "Software Library" e non inserire mai dati personali di studenti in piattaforme pubbliche non approvate.

    - **Progettazione didattica critica:** Integrare l'IA come "compagno cognitivo" e non come sostituto del pensiero, progettando attività che richiedano di valutare e criticare i suoi output.

    - **Valutazione umana e trasparente:** Mantenere la centralità del proprio giudizio professionale. Gli strumenti di IA possono essere un supporto, ma la responsabilità della valutazione finale è e deve rimanere del docente.

### 3.3 "Cose da NON Fare": Una Guida Pratica

Una policy efficace deve essere anche prescrittiva. Basandosi sulla sezione 3.4 del "Documento di Indirizzo"[^2], ecco una checklist chiara e diretta delle azioni da evitare assolutamente:

- **NON usare l'IA per la valutazione finale e completamente automatizzata degli studenti.** Le decisioni che hanno un impatto significativo sul percorso di uno studente devono sempre prevedere una supervisione e una validazione umana.

- **NON inserire dati personali di studenti (nomi, temi, dati sensibili) in piattaforme di IA generative pubbliche e generiche (es. la versione gratuita di ChatGPT).** Si devono usare solo gli strumenti approvati e configurati dalla scuola che garantiscano la privacy.

- **NON adottare un nuovo strumento di IA senza aver prima consultato il DPO e aver completato la procedura di valutazione del rischio (DPIA).** L'approccio "fai da te" espone l'istituto a gravi rischi.

- **NON dare per scontato che l'output di un'IA sia corretto, completo o imparziale.** Il docente ha la responsabilità professionale di verificare ogni contenuto prima di usarlo a scopo didattico.

- **NON basare decisioni disciplinari (es. un'accusa di plagio) unicamente sull'output di un "AI detector".**

- **NON ignorare l'obbligo di trasparenza.** La natura artificiale di un chatbot o di un contenuto generato da IA deve essere sempre dichiarata agli studenti.

## Capitolo 4: Rischi, Bias e Implicazioni Etiche Profonde

Oltre alle questioni normative e di sicurezza, l'uso dell'IA nella didattica solleva profonde implicazioni etiche che toccano il cuore della missione educativa della scuola. Un approccio responsabile richiede di guardare oltre la superficie della tecnologia per interrogarsi sui suoi effetti più profondi sull'equità, la trasparenza e la natura stessa dell'apprendimento.

### 4.1 Oltre la Privacy: i Bias Algoritmici

Uno dei rischi etici più insidiosi dell'IA è il **bias algoritmico**. I sistemi di IA apprendono dai dati con cui vengono addestrati. Se questi dati riflettono pregiudizi, stereotipi e disuguaglianze presenti nella società, l'IA non solo li imparerà, ma potrà anche perpetuarli e amplificarli su larga scala. Questo è in netto contrasto con il principio di **equità**, menzionato come cardine nel "Documento di Indirizzo"[^2], secondo cui l'IA deve "promuovere l'equità, garantendo che tutti abbiano pari accesso alle opportunità e ai benefici".

Nel contesto educativo, i bias possono manifestarsi in modi diversi e dannosi:

- **Bias linguistico e culturale:** Un sistema di valutazione del testo addestrato prevalentemente su testi in inglese standard potrebbe penalizzare uno studente che usa una variante linguistica regionale o che scrive con una struttura sintattica influenzata dalla sua lingua madre. Allo stesso modo, un'IA che genera esempi o problemi potrebbe proporre scenari culturalmente stereotipati o irrilevanti per studenti con background diversi.

- **Bias socio-economico:** Un sistema di ammissione predittivo potrebbe, basandosi su dati storici, associare un codice postale di una zona a basso reddito a una minore probabilità di successo accademico, creando una profezia che si autoavvera e perpetuando la disuguaglianza.

- **Bias di genere e di rappresentazione:** Un'IA per la generazione di immagini, se non correttamente istruita, potrebbe associare determinate professioni (es. ingegnere, infermiere) a un genere specifico, rinforzando stereotipi dannosi.

Combattere i bias richiede una vigilanza costante. La scuola deve scegliere fornitori che dimostrino di lavorare attivamente per mitigare i bias nei loro modelli, ma soprattutto deve formare i docenti a riconoscere e a decostruire criticamente gli output dell'IA insieme agli studenti, trasformando un rischio in un'opportunità di educazione alla cittadinanza digitale.

### 4.2 L'Effetto "Scatola Nera" e la Responsabilità Umana

Molti dei modelli di IA più avanzati, in particolare le reti neurali profonde, funzionano come una "scatola nera" (*black box*). Siamo in grado di osservare i dati in ingresso e l'output in uscita, ma i processi interni che portano a una determinata decisione sono così complessi da essere difficilmente interpretabili persino per i loro stessi creatori.

Questo problema della non-trasparenza pone una questione fondamentale di responsabilità. Se un'IA commette un errore in una valutazione, di chi è la colpa? Del programmatore? Della scuola che ha adottato lo strumento? Del docente che lo ha utilizzato?

La risposta normativa ed etica, come sottolineato in più punti del "Documento di Indirizzo"[^2] e nell'AI Act[^1], è inequivocabile: la **centralità e la responsabilità finale devono sempre rimanere umane**. Nessuna decisione critica che riguardi la vita e il percorso formativo di uno studente può essere interamente delegata a una macchina. Il docente non è un semplice "operatore" di un sistema, ma il garante del processo educativo. L'IA può fornire dati, analisi, suggerimenti, ma il giudizio finale, la valutazione contestualizzata, la decisione pedagogica e la responsabilità che ne deriva sono e devono rimanere una prerogativa irrinunciabile dell'essere umano. Questo principio non è un ostacolo all'innovazione, ma la sua più importante garanzia etica.

## Guida alla Co-Progettazione di un Patto Etico per l'Uso dell'Intelligenza Artificiale a Scuola

### Premessa: Governare la Complessità, Costruire il Futuro

L'irruzione dell'Intelligenza Artificiale generativa nel panorama educativo rappresenta un punto di non ritorno, una trasformazione tecnologica e culturale di portata paragonabile all'avvento di Internet. Strumenti capaci di generare testi, immagini, codice e soluzioni a problemi complessi in pochi istanti sono ormai entrati nella pratica quotidiana degli studenti, ridefinendo i paradigmi tradizionali dell'apprendimento, della valutazione e dell'onestà accademica. Di fronte a questa realtà, le istituzioni scolastiche si trovano a un bivio: subire il cambiamento in modo passivo e reattivo, oscillando tra divieti inefficaci e un'adozione acritica, oppure scegliere di governare la complessità, assumendo un ruolo proattivo nella definizione di un nuovo equilibrio.

Questa guida si colloca risolutamente in questa seconda prospettiva. Il suo scopo è fornire un modello operativo per la co-progettazione di un **"Patto di Corresponsabilità per l'Uso Etico dell'IA"**, uno strumento strategico fondamentale per ogni istituto che desideri integrare l'innovazione tecnologica in modo consapevole, sicuro e allineato alla propria missione educativa. L'approccio proposto non è quello di fornire una soluzione preconfezionata, bensì di avviare un processo collaborativo che coinvolga l'intera comunità educante, a partire dal corpo docente.

La finalità ultima di questa attività laboratoriale è duplice. In primo luogo, si intende elevare il livello di consapevolezza collettiva, trasformando le percezioni individuali -- spesso un misto di entusiasmo, preoccupazione e incertezza -- in una comprensione strutturata delle implicazioni normative, etiche e didattiche dell'IA. In secondo luogo, l'obiettivo è eminentemente pratico: tradurre la riflessione in azione, dotando la scuola di un documento di riferimento chiaro, condiviso e operativo.

Un Patto di Corresponsabilità non è un mero regolamento, ma un manifesto culturale. È la dichiarazione pubblica di come una comunità sceglie di relazionarsi con una tecnologia potente, definendo i principi irrinunciabili, i confini da rispettare e gli impegni reciproci che legano studenti, docenti, famiglie e l'istituzione stessa. Attraverso il dialogo guidato e la scrittura collaborativa, i docenti diventano i primi architetti di questo nuovo patto formativo, ponendo le basi per una cultura dell'innovazione responsabile che sappia cogliere le immense opportunità dell'IA senza mai abdicare al primato del pensiero critico, della creatività e della centralità della persona umana.

### Descrizione dell'Attività Laboratoriale: un Percorso in Quattro Fasi

Il laboratorio è concepito come un percorso strutturato della durata di circa due ore, progettato per essere condotto con gruppi di docenti di scuola secondaria di secondo grado. L'approccio è maieutico e costruttivista: il ruolo del facilitatore è quello di guidare la discussione, fornire stimoli e strumenti, ma il contenuto e il prodotto finale emergono dal lavoro collettivo dei partecipanti.

#### Finalità Pedagogiche e Strumenti

L'attività si prefigge di raggiungere i seguenti obiettivi:

- **Analisi Critica:** Sviluppare una comprensione approfondita del quadro normativo (AI Act, GDPR) e dei concetti etici chiave (bias, trasparenza, equità) legati all'uso dell'IA in contesti educativi.

- **Progettazione Didattica:** Riflettere sulle modifiche necessarie alle pratiche di insegnamento e valutazione per promuovere l'onestà accademica e valorizzare le competenze umane nell'era dell'IA.

- **Costruzione di Comunità:** Rafforzare il dialogo professionale e la coesione del corpo docente attorno a una sfida comune, favorendo la nascita di un linguaggio e di un approccio condivisi.

- **Produzione Concreta:** Elaborare una bozza avanzata di "Patto di Corresponsabilità" che possa servire come base per il successivo coinvolgimento di studenti e famiglie e per l'integrazione nei documenti ufficiali dell'istituto (PTOF, Regolamento d'Istituto).

Gli strumenti necessari per la conduzione del laboratorio sono semplici e accessibili: uno spazio che favorisca la discussione, una lavagna (tradizionale o digitale) per la mappatura delle idee, un proiettore e un computer con accesso a un editor di testo collaborativo (es. Google Docs) per la stesura collettiva del documento.

#### Fase 1: Mappatura delle Percezioni e Brainstorming Guidato (Durata: 20 minuti)

**Razionale:** Ogni processo di cambiamento deve partire dall'ascolto e dalla comprensione del punto di vista dei suoi attori. Questa fase iniziale ha lo scopo di far emergere il "non detto": le speranze, le paure, le incertezze e le convinzioni dei docenti riguardo all'IA. Creare una mappa concettuale condivisa permette di stabilire un terreno comune, legittimare tutte le posizioni e focalizzare la discussione successiva sui temi realmente sentiti come prioritari dal gruppo.

**Istruzioni Operative per il Facilitatore:**

1. **Introduzione e Posizionamento (5 min):** Dopo aver accolto i partecipanti, il facilitatore introduce gli obiettivi del laboratorio, enfatizzando la natura collaborativa e il fine pratico dell'incontro. È cruciale posizionare l'attività non come un momento "top-down" di imposizione di regole, ma come un'opportunità "bottom-up" di co-costruzione di una policy che rispecchi l'identità e le esigenze dell'istituto.

2. **Lancio dello Stimolo (15 min):** Il facilitatore pone al gruppo una domanda aperta e potente, pensata per sollecitare una risposta sia razionale che emotiva. La domanda suggerita è: *"Pensando all'uso che i vostri studenti fanno dell'Intelligenza Artificiale oggi, qual è la vostra più grande preoccupazione e, al contempo, la vostra più grande speranza?"*

3. Il facilitatore modera il giro di interventi, trascrivendo sulla lavagna le parole chiave e i concetti che emergono. È importante non giudicare né filtrare le risposte, ma accoglierle tutte. Progressivamente, le idee vengono raggruppate visivamente in macro-categorie tematiche. L'esperienza suggerisce che emergeranno quasi certamente le seguenti aree:

    - **Onestà Accademica e Plagio:** La preoccupazione più immediata, legata al rischio che l'IA diventi una scorciatoia per evitare lo studio e la rielaborazione personale.

    - **Privacy e Sicurezza dei Dati:** La consapevolezza, più o meno strutturata, che l'interazione con queste piattaforme implica la cessione di dati personali e sensibili.

    - **Equità, Bias e Discriminazione:** La preoccupazione che l'IA possa amplificare le disuguaglianze esistenti o introdurre nuove forme di pregiudizio algoritmico.

    - **Sviluppo del Pensiero Critico:** Il timore che un affidamento eccessivo all'IA possa atrofizzare le capacità cognitive superiori, come la capacità di analisi, sintesi e valutazione.

    - **Creatività e Originalità:** Il dubbio che la facilità di generazione di contenuti possa omologare il pensiero e ridurre lo spazio per l'espressione creativa autentica e originale.

#### Fase 2: Analisi Guidata e Costruzione delle Competenze (Durata: 40 minuti)

**Razionale:** Dopo aver fatto emergere le percezioni, è necessario fornire al gruppo gli strumenti concettuali per analizzare i problemi in modo più strutturato e informato. Questa fase trasforma le preoccupazioni in domande di ricerca e guida i docenti a trovare risposte basate su fonti normative ed etiche. Il lavoro in piccoli gruppi favorisce la partecipazione attiva e permette di approfondire tematiche specifiche in parallelo.

**Istruzioni Operative per il Facilitatore:**

1. **Suddivisione in Gruppi di Lavoro (5 min):** Il facilitatore divide l'uditorio in piccoli gruppi di 3-4 persone, possibilmente eterogenei per disciplina di insegnamento. A ciascun gruppo viene assegnata una delle macro-aree tematiche emerse nella fase precedente.

2. **Consegna e Analisi dei Materiali (35 min):** Il facilitatore fornisce a tutti i gruppi un set di risorse digitali (vedi Allegato B), che include sintesi della normativa, articoli su etica e didattica ed esempi di policy esistenti. Il compito di ogni gruppo è analizzare questi materiali attraverso la lente della propria tematica, utilizzando delle domande-guida per strutturare la riflessione e preparare una sintesi da condividere.

**Domande Guida Approfondite per i Gruppi:**

- **Gruppo "Onestà Accademica":**

    - Come possiamo superare la dicotomia "uso buono / uso cattivo"? È possibile definire una tassonomia degli usi dell'IA (es. IA come tutor, IA come revisore, IA come fonte di idee, IA come autore)?

    - Quali sono le caratteristiche di un compito "a prova di IA"? Si richiede di elaborare almeno tre esempi concreti di compiti per la propria disciplina che integrino l'IA in modo virtuoso.

    - Come si cita correttamente l'IA? Il gruppo è invitato a elaborare una bozza di linea guida per la citazione, specificando quali informazioni includere (es. prompt utilizzato, data, strumento).

- **Gruppo "Privacy e Sicurezza":**

    - Analizzando le definizioni di "dati personali" del GDPR, si chiede di stilare un elenco dettagliato di informazioni che uno studente non dovrebbe mai inserire in un prompt (es. nomi completi, dati sulla salute, opinioni politiche, dettagli familiari, testi di temi personali).

    - Qual è la differenza tra un account "consumer" e un account "educational/enterprise" di un servizio di IA? Quali garanzie contrattuali (DPA - Data Processing Agreement) la scuola deve esigere da un fornitore?

    - Quali sono le responsabilità del docente nel vigilare sull'uso corretto degli strumenti in classe?

- **Gruppo "Equità e Bias":**

    - Si chiede di cercare e analizzare due esempi concreti di bias algoritmico (di genere, culturale, linguistico) in noti modelli di IA.

    - Come si può trasformare il rischio del bias in un'opportunità didattica? Il gruppo deve progettare un'attività di classe in cui gli studenti sono chiamati a "fare il debiasing" di un testo generato da IA, identificando e correggendo gli stereotipi.

    - Quali misure può adottare la scuola per mitigare il divario digitale e garantire che l'accesso ai benefici dell'IA sia equo per tutti gli studenti?

- **Gruppo "Pensiero Critico e Creatività":**

    - Cosa significa trattare l'IA come un "compagno cognitivo"? Il gruppo deve identificare almeno tre pratiche didattiche in cui l'IA è usata per stimolare domande, esplorare prospettive multiple o superare blocchi creativi.

    - Si chiede di stilare un elenco delle "competenze insostituibilmente umane" che la scuola deve prioritariamente potenziare nell'era dell'IA (es. intelligenza emotiva, pensiero etico, collaborazione complessa, problem solving non strutturato).

    - Come può la valutazione evolvere per dare più peso al processo di ricerca e rielaborazione piuttosto che al solo prodotto finale?

#### Fase 3: Sintesi e Co-Costruzione del Documento (Durata: 40 minuti)

**Razionale:** Questa è la fase convergente del laboratorio, in cui il lavoro analitico dei gruppi viene messo a sistema per costruire un prodotto comune. La scrittura collaborativa in tempo reale è un potente strumento di mediazione e di sintesi, che trasforma le idee discusse in un testo formale e condiviso, aumentando il senso di appartenenza e di "ownership" del documento finale da parte dei partecipanti.

**Istruzioni Operative per il Facilitatore:**

1. **Restituzione e Sistematizzazione (15 min):** A turno, un portavoce per ogni gruppo presenta alla plenaria i risultati principali della loro analisi. Il facilitatore ha un ruolo attivo: non si limita ad ascoltare, ma proietta un documento di testo vuoto (strutturato secondo il modello dell'Allegato A) e inizia a popolarlo in tempo reale con le proposte dei gruppi, sintetizzando, riformulando e chiedendo conferme.

2. **Scrittura Collettiva Guidata (25 min):** Con la struttura della bozza visibile a tutti, il facilitatore guida la stesura collettiva del "Patto di Corresponsabilità". Si procede sezione per sezione (Principi, Impegni degli Studenti, Impegni dei Docenti, etc.). Il facilitatore legge ad alta voce le proposte, invita a suggerire formulazioni più chiare o incisive e digita il testo in diretta. È fondamentale incoraggiare un linguaggio positivo e propositivo (privilegiando "Ci impegniamo a..." rispetto a "È vietato..."), che renda il patto uno strumento di empowerment piuttosto che un mero elenco di divieti.

#### Fase 4: Fase operativa e passi futuri (Durata: 20 minuti)

**Razionale:** Nessun documento ha valore se rimane confinato a un incontro di formazione. Quest'ultima fase è cruciale per garantire che il lavoro svolto abbia un seguito concreto e un impatto reale sulla vita dell'istituto. Definire chiaramente i prossimi passi trasforma l'energia del laboratorio in un processo di cambiamento organizzativo.

**Istruzioni Operative per il Facilitatore:**

1. **Revisione e Consolidamento (10 min):** Il facilitatore legge ad alta voce l'intera bozza del "Patto", così come è stata redatta collettivamente. Viene chiesto un ultimo giro di feedback per affinare il testo e assicurarsi che rappresenti il consenso del gruppo.

2. **Pianificazione del Follow-up (10 min):** La discussione si sposta sul piano operativo. Il facilitatore guida il gruppo a rispondere a domande chiave:

    - **Finalizzazione:** Chi si assume la responsabilità di revisionare e formattare la bozza? (es. un piccolo comitato di redazione, il referente per l'innovazione).

    - **Condivisione e Feedback:** Come verrà presentato questo documento agli studenti e alle famiglie? (es. durante assemblee di classe dedicate, incontri scuola-famiglia, tramite una comunicazione ufficiale con un modulo per raccogliere feedback).

    - **Validazione Istituzionale:** Qual è l'iter per rendere questo Patto un documento ufficiale della scuola? (es. presentazione al Collegio Docenti, approvazione in Consiglio d'Istituto).

    - **Monitoraggio:** Come verificheremo l'efficacia di questo Patto nel tempo? Si prevede un momento di revisione annuale?

3. Il facilitatore conclude l'incontro ringraziando i partecipanti per il contributo e riaffermando l'importanza del percorso intrapreso, che posiziona la comunità professionale come protagonista dell'innovazione.

#### Allegato A: Esempio di "Patto di Corresponsabilità per l'Uso Etico dell'IA"

##### I.I.S.S. "Alessandro Greppi"

###### Premessa

L'Istituto di Istruzione Secondaria Superiore "Alessandro Greppi", in linea con la sua tradizione di eccellenza formativa e di attenzione all'innovazione, riconosce l'Intelligenza Artificiale (IA) come una potente risorsa per l'arricchimento della didattica e lo sviluppo delle competenze del XXI secolo. Consapevoli delle profonde implicazioni etiche, culturali e sociali di questa tecnologia, intendiamo promuoverne un'integrazione che sia consapevole, critica, responsabile e pienamente allineata ai principi della nostra Costituzione e alla normativa europea. Questo documento rappresenta il patto che la nostra intera comunità educante -- studenti, docenti, famiglie e istituzione -- stringe per governare insieme questa transizione, assicurando che ogni strumento tecnologico sia sempre al servizio della crescita intellettuale, della creatività e dello sviluppo integrale della persona.

###### I Nostri Principi Fondamentali

1. **Antropocentrismo e Centralità della Persona:** Affermiamo il primato della persona umana. L'IA è e deve rimanere uno strumento. Nessuna decisione che impatti significativamente il percorso formativo o la valutazione di uno studente può essere delegata interamente a un algoritmo. La relazione educativa, il giudizio professionale del docente e l'interazione umana rimangono il cuore insostituibile del processo di apprendimento.

2. **Onestà Intellettuale e Valore dell'Impegno:** Riconosciamo che l'apprendimento autentico è un processo che richiede impegno, fatica, riflessione e rielaborazione personale. L'IA può supportare questo processo, ma non deve mai diventare una scorciatoia per eluderlo. L'onestà accademica è un valore non negoziabile.

3. **Sviluppo del Pensiero Critico:** Il nostro obiettivo non è insegnare a "usare" l'IA, ma a "pensare con e oltre" l'IA. Ci impegniamo a sviluppare la capacità di interrogare, verificare, analizzare criticamente e contestualizzare ogni informazione prodotta da un sistema artificiale, riconoscendone limiti, errori e potenziali bias.

4. **Equità, Inclusione e Rifiuto del Pregiudizio:** Vigileremo attivamente affinché l'uso dell'IA non crei né amplifichi disuguaglianze. Ci impegniamo a promuovere un accesso equo alle risorse, a educare al riconoscimento dei bias algoritmici e a utilizzare la tecnologia come strumento per l'inclusione e la personalizzazione, nel rispetto delle unicità di ciascuno.

5. **Responsabilità e Sicurezza:** La tutela dei dati personali e la sicurezza digitale sono una responsabilità condivisa. Ci impegniamo a rispettare rigorosamente la normativa (GDPR, AI Act) e ad adottare comportamenti che proteggano la privacy individuale e la sicurezza dell'intera comunità scolastica.

**Come Studentesse e Studenti, ci impegniamo a:**

- Utilizzare l'IA come un "compagno cognitivo": uno strumento per esplorare idee, chiarire dubbi, rivedere bozze e superare ostacoli, non come un sostituto del nostro lavoro e del nostro pensiero.

- Dichiarare sempre in modo trasparente e onesto l'utilizzo dell'IA nei nostri lavori, seguendo le specifiche indicazioni fornite da ciascun docente per ogni attività.

- Non presentare mai come interamente nostro un testo, un'immagine, un codice o qualsiasi altro elaborato generato da un'IA, in quanto ciò costituisce una violazione del principio di onestà accademica.

- Essere custodi dei nostri dati personali e di quelli dei nostri compagni, evitando di inserire informazioni sensibili o identificative in piattaforme di IA pubbliche o non approvate dall'Istituto.

- Esercitare il nostro pensiero critico, verificando sempre l'accuratezza, la pertinenza e l'assenza di bias nelle informazioni fornite dall'IA, confrontandole con altre fonti autorevoli.

- Segnalare ai docenti eventuali output dell'IA che risultino palesemente errati, inappropriati, offensivi o discriminatori.

**Come Docenti, ci impegniamo a:**

- Progettare percorsi didattici e valutativi che valorizzino le competenze umane superiori (pensiero critico, creatività, problem solving complesso, collaborazione) e che rendano l'uso fraudolento dell'IA pedagogicamente irrilevante.

- Fornire indicazioni chiare, esplicite e differenziate per ogni attività didattica su quando, come e perché l'uso dell'IA è consentito, incoraggiato o sconsigliato.

- Dedicarci a una formazione continua per comprendere l'evoluzione dell'IA e per sviluppare le competenze necessarie a guidare gli studenti verso un uso etico ed efficace di questi strumenti.

- Selezionare e utilizzare esclusivamente piattaforme e software di IA che siano conformi alla normativa sulla protezione dei dati e che siano stati approvati dall'Istituto, garantendo un ambiente di apprendimento sicuro.

- Mantenere la centralità del nostro giudizio professionale nel processo di valutazione, utilizzando gli strumenti di IA come supporto ma mai come sostituti della nostra responsabilità valutativa finale.

- Educare esplicitamente gli studenti sui rischi dell'IA, inclusi i bias algoritmici, le "allucinazioni" (informazioni false), la disinformazione e le implicazioni per la privacy.

**Come Istituzione Scolastica e Famiglie, ci impegniamo a:**

- Promuovere un dialogo costante e costruttivo tra tutte le componenti della comunità scolastica per monitorare e aggiornare periodicamente il presente Patto.

- Garantire, come Istituto, l'accesso a un'infrastruttura tecnologica e a una selezione di strumenti software sicuri, equi e pedagogicamente validi.

- Sostenere, come Istituto, la formazione dei docenti e l'organizzazione di iniziative informative per studenti e famiglie.

- Collaborare, come Famiglie, con la scuola per promuovere un uso equilibrato e consapevole delle tecnologie digitali anche in ambito domestico, supportando i principi di onestà e impegno nello studio.

#### Allegato B: Risorse e Materiali di Supporto per il Laboratorio

- **Quadro Normativo (Link e Sintesi):**

    - **AI Act (Regolamento UE 2024/1689):** [Testo ufficiale su EUR-Lex](https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689 "null"). Si raccomanda la lettura della sintesi commentata degli Articoli 5 (Pratiche Vietate), 6 (Sistemi ad Alto Rischio) e dell'Allegato III (focus su Istruzione).

    - **GDPR (Regolamento UE 2016/679):** [Testo ufficiale su EUR-Lex](https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679 "null"). Si raccomanda la lettura guidata degli Articoli 5 (Principi), 6 (Base Giuridica) e 35 (Valutazione d'Impatto) nel contesto scolastico.

- **Articoli di Approfondimento su Etica e Didattica:**

    - **"Bias within AI: unpacking the risks and opportunities for education" (UNESCO):** [Leggi l'articolo](https://unesdoc.unesco.org/ark:/48223/pf0000386670). Un'analisi autorevole su come i bias di genere e culturali si manifestano nei modelli di IA.

    - **"A Generative AI Guide for Educators" (Vanderbilt University):** [Consulta la guida (PDF)](https://cdn.vanderbilt.edu/vu-sub/wp-content/uploads/sites/59/2023/09/09144130/Teaching-in-the-Age-of-AI-PRINT-VERSION.pdf). Un esempio di guida che illustra come formulare prompt per trasformare l'IA in uno strumento di riflessione.

    - **"Rethinking Assessment in the Age of AI" (Getting Smart):** [Leggi l'articolo](https://www.csu.edu.au/division/learning-teaching/assessments/assessment-and-artificial-intelligence/rethinking-assessments). Un saggio che esplora nuove forme di valutazione che valorizzano le competenze non automatizzabili.

- **Esempi Pratici e Strumenti:**

    - **Policy di Atenei Internazionali:**

        - [MIT - Academic Integrity & AI](https://library.mit.edu.au/c.php?g=968719&p=7042933)

        - [University of Sydney - Generative AI in learning](https://www.sydney.edu.au/students/academic-integrity/artificial-intelligence.html)

        - [ETH Zurich - AI and Plagiarism Policy](https://library.ethz.ch/en/researching-and-publishing/scientific-writing-at-eth-zurich/prevention-of-plagiarism.html)

    - **Guida alla Citazione dell'IA:**

        - [APA Style: How to cite ChatGPT](https://apastyle.apa.org/blog/how-to-cite-chatgpt "null")

        - [MLA Style: How to Cite Generative AI](https://style.mla.org/citing-generative-ai/ "null")

    - **UNESCO - AI and Education:** [Visita il portale](https://www.unesco.org/en/digital-education/artificial-intelligence). Il portale di riferimento dell'UNESCO con risorse e raccomandazioni globali sull'integrazione dell'IA nei sistemi educativi.

## Conclusioni e Prossimi Passi

L'integrazione dell'Intelligenza Artificiale nel mondo della scuola non è più un'ipotesi futuribile, ma una realtà presente e in rapida evoluzione. Le sfide che pone sono complesse e non ammettono risposte semplicistiche. Come abbiamo visto in questo percorso, un approccio puramente entusiasta rischia di ignorare i pericoli, mentre un atteggiamento di chiusura e divieto è destinato a essere superato dalla realtà e a privare gli studenti di opportunità formative cruciali.

La via maestra, delineata dalla normativa europea e da modelli di policy illuminati come il "Documento di Indirizzo"[^2], è quella del **governo consapevole**. L'obiettivo non è vietare l'IA, ma governarla, plasmarla secondo i fini educativi della scuola e i valori di una società democratica. Questo richiede un impegno corale da parte di tutta la comunità scolastica.

I punti chiave emersi sono chiari:

1. **La conformità normativa non è un optional:** Il rispetto dell'AI Act[^1] e del GDPR[^3] è il fondamento per un'innovazione sicura e che tuteli i diritti di tutti.

2. **La prevenzione è meglio della repressione:** Di fronte a sfide come il plagio, la riprogettazione didattica è una strategia più efficace e pedagogicamente più ricca del mero controllo.

3. **La governance è essenziale:** Ogni scuola deve dotarsi di una AI Policy chiara, che definisca ruoli, responsabilità e procedure.

4. **La responsabilità è e deve rimanere umana:** Nessuna tecnologia può sostituire il giudizio critico, l'empatia e la responsabilità etica del docente.

L'invito finale è rivolto a tutti i docenti: diventare protagonisti attivi di questo processo. Ciò significa formarsi continuamente, sperimentare con prudenza e spirito critico, collaborare con i colleghi e, soprattutto, educare gli studenti a essere non solo consumatori passivi, ma cittadini digitali consapevoli, capaci di comprendere, utilizzare e interrogare criticamente la tecnologia più potente del nostro tempo. Promuovendo una cultura della responsabilità e dell'innovazione etica all'interno della propria comunità, possiamo assicurare che l'Intelligenza Artificiale diventi un potente alleato per una scuola più equa, inclusiva ed efficace.

## Riferimenti

[^1]: Parlamento Europeo e Consiglio, "Regolamento (UE) 2024/1689 del 13 giugno 2024 che stabilisce regole armonizzate sull'intelligenza artificiale (regolamento sull'intelligenza artificiale)".

[^2]: [Istituto di Istruzione Secondaria Superiore "Alessandro Greppi", "Documento di Indirizzo Strategico per l'Integrazione dell'Intelligenza Artificiale nell'Istituto", Versione 1.0, Ottobre 2025](../../ai-regulations/documento-di-indirizzo-integrazione-ai-in-istituto).

[^3]: Parlamento Europeo e Consiglio, "Regolamento (UE) 2016/679 del 27 aprile 2016 relativo alla protezione delle persone fisiche con riguardo al trattamento dei dati personali, nonché alla libera circolazione di tali dati".

[^4]: Ministero dell'Istruzione e del Merito, "Linee guida per l'introduzione dell'Intelligenza Artificiale nelle Istituzioni scolastiche", Versione 1.0, 2025.
