---
title: Implicazioni filosofiche ed etiche dell'AI
description: Come le macchine sono diventate intelligenti senza pensare in modo umano. La "scorciatoia" per creare macchine intelligenti che non pensano in modo deduttivo.Proprietà "emergenti" in un Large Language Model (LLM) quando la sua dimensione supera una soglia critica.
---

## Navigare la nuova era della conoscenza: una bussola filosofica per un mondo che cambia

L'epoca attuale è caratterizzata da trasformazioni epocali, in cui le fondamenta della società, della conoscenza e della condizione umana vengono interrogate da una forza tanto potente quanto elusiva: l'**Intelligenza Artificiale**. Non si tratta più di una promessa futuribile confinata nei laboratori di ricerca o nelle pagine della fantascienza, ma di una realtà operante, un'infrastruttura invisibile che media le interazioni, modella le economie e ridefinisce i confini di ciò che è possibile. Nell'ambito scolastico, la comprensione della natura profonda di questa rivoluzione tecnologica rappresenta una missione culturale e pedagogica di primaria importanza. Preparare le nuove generazioni a un mondo in radicale mutamento non significa solo dotarle di nuove competenze tecniche, ma, soprattutto, di una solida bussola critica e filosofica per navigare un territorio inesplorato.

Questo articolo presuppone la conoscenza delle nozioni fondamentali sull'IA e sulle tecniche di interazione con i modelli linguistici. L'obiettivo non è ripetere concetti noti, ma **proporre un'analisi più profonda, un'esplorazione critica che vada oltre la superficie delle applicazioni per sondare le correnti filosofiche, tecnologiche ed etiche che hanno portato alla nascita di questa nuova forma di intelligenza**. Il nostro viaggio non sarà una semplice ricognizione tecnologica, ma un vero e proprio carotaggio nelle questioni fondamentali che l'IA ci costringe ad affrontare. Per farlo, ci affideremo al pensiero di due dei più influenti intellettuali contemporanei che si sono occupati del tema, pur da prospettive disciplinari diverse: il filosofo dell'informazione [**Luciano Floridi**](https://dec.yale.edu/people/luciano-floridi) e lo scienziato informatico [**Nello Cristianini**](https://researchportal.bath.ac.uk/en/persons/nello-cristianini/).

Attraverso l'analisi di alcuni loro testi chiave, che verranno dettagliati nei paragrafi successivi, cercheremo di rispondere a una domanda tanto semplice quanto radicale: ***come sono diventate "intelligenti" le macchine, pur seguendo un percorso evolutivo che non ha nulla a che fare con il pensiero, la coscienza o la comprensione umana?*** Questa domanda ne apre immediatamente altre, che costituiscono il cuore della nostra indagine:

- **Cosa significa veramente "intelligenza" in un'era in cui agenti non-biologici dimostrano capacità di problem-solving superiori a quelle umane in domini sempre più vasti?**
- **Dobbiamo continuare a usare un vocabolario antropocentrico (parlando di "pensiero", "comprensione", "ragionamento") per descrivere processi che sono, nella loro essenza, calcoli statistici su scala massiva? Oppure abbiamo bisogno di un nuovo linguaggio per descrivere questa nuova realtà?**
- **Se, come sostiene Floridi, stiamo assistendo a un "divorzio tra intelligenza e capacità di agire", quali sono le implicazioni etiche di un mondo popolato da agenti potentissimi ma privi di responsabilità?**
- **Se, invece, come suggerisce l'evoluzione del pensiero di Cristianini, stiamo assistendo alla nascita di una genuina, seppur "aliena", forma di intelligenza, come dobbiamo prepararci a coesistere con essa?**

Per decenni, l'aspirazione dell'IA è stata mimetica: replicare i processi logico-deduttivi della mente umana. Un'ambizione nobile ma frustrante, che si è scontrata con l'inestricabile complessità del mondo interiore umano. La svolta, quando è arrivata, è stata tanto pragmatica quanto dirompente. Ha preso una **"scorciatoia"**, come la definisce il Prof. **Nello Cristianini** nella sua opera seminale, **abbandonando la pretesa di simulare il pensiero per abbracciare la potenza statistica dell'apprendimento induttivo su una scala di dati inimmaginabile. Da questa alterità, da questa intelligenza aliena e performativa, scaturiscono le più grandi opportunità e le sfide più ardue del tempo presente**.

Il pensiero di Cristianini, articolato in una trilogia di saggi che verranno esplorati in dettaglio, ci offre la prospettiva dello scienziato che vive la rivoluzione dall'interno. La sua analisi parte dal riconoscimento di questa "scorciatoia" per poi evolversi, in *Machina Sapiens* e *Sovrumano*, verso la constatazione che la scala quantitativa ha prodotto un salto qualitativo. Le macchine non solo imitano, ma iniziano a mostrare "abilità emergenti" e a costruire un "modello del mondo" che suggerisce una forma di cognizione genuina. Cristianini ci guida in un percorso che ci costringe a de-antropizzare il concetto di intelligenza, a riconoscerla come una capacità funzionale che può manifestarsi in substrati diversi da quello biologico.

Dall'altro lato, l'analisi di **Luciano Floridi**, in particolare nel suo *Etica dell'intelligenza artificiale*, ci fornisce la bussola del filosofo morale. Floridi ci mette in guardia dal cadere nella "fallacia antropomorfica". Egli insiste sulla necessità di mantenere una distinzione categoriale: l'IA è un artefatto tecnologico di una potenza senza precedenti, un motore di "azioni" efficaci, ma non è un "agente" intelligente nel senso umano del termine. Questa distinzione non è un cavillo accademico, ma il fondamento per costruire un'etica della responsabilità. Se le macchine non sono intelligenti, non possono essere responsabili. La responsabilità ricade interamente sugli esseri umani e sulle società che le progettano, le implementano e le governano. La sua prospettiva ci impone di concentrarci non tanto sulla natura interna della macchina, quanto sull'architettura di governance, sulle regole e sui valori che devono guidare il suo impiego.

Mettendo a confronto queste due visioni, l'articolo intende offrire ai docenti e agli studenti non una risposta definitiva, ma un quadro dialettico per pensare criticamente. L'analisi proposta si concentrerà sull'impatto di questa intelligenza non-umana sulla vita quotidiana e sul tessuto sociale. Esamineremo come i **sistemi di raccomandazione**, da semplici "assistenti", si siano trasformati in potenti architetti delle preferenze individuali. Approfondiremo l'architettura che ha reso possibile tutto questo, il **"Transformer"**, e il suo **"meccanismo di attenzione"**, per chiarire come la gestione del contesto sia diventata la chiave per sbloccare la conoscenza latente nei dati. Affronteremo il fenomeno delle **"proprietà emergenti"**, dove la quantità si trasforma inaspettatamente in qualità, sollevando interrogativi cruciali sulla prevedibilità e sicurezza.

Successivamente, l'attenzione verrà posta sull'**impatto, già tangibile, sul mondo del lavoro**. Infine, l'articolo si configurerà come uno strumento pratico, fornendo proposte concrete per portare queste complesse discussioni nelle aule. L'obiettivo è dotare gli studenti non solo di conoscenze, ma di un apparato critico robusto, della capacità di porre domande pertinenti e di navigare con consapevolezza in un'era che sarà, innegabilmente, l'era dell'intelligenza artificiale. Prepararsi a questo futuro non significa solo imparare a usare nuovi strumenti, ma imparare a pensare in modo nuovo riguardo a sé stessi, alla società e al nostro posto nell'universo della conoscenza.

## Parte 1: l'impatto sulla vita quotidiana e sociale: un'intelligenza aliena tra noi

L'alba del ventunesimo secolo ci ha immersi in un ambiente digitale onnipresente, un'**infosfera**, per usare il termine del filosofo **Luciano Floridi**, che costituisce ormai l'habitat primario delle nostre vite sociali, lavorative e personali. In questo habitat, **l'Intelligenza Artificiale non è un ospite occasionale, ma una forza ecologica fondamentale, un agente invisibile che regola i flussi di informazione, modella le interazioni e influenza le nostre percezioni. Comprendere l'impatto di questa tecnologia richiede di analizzarne la natura intrinseca, di svelare i meccanismi che la governano e di riconoscere la sua profonda e irriducibile alterità rispetto all'intelligenza umana**. Questa sezione è dedicata a esplorare queste dinamiche, partendo dalla sua origine concettuale fino alle sue manifestazioni più pervasive e alle sfide epocali che esse comportano.

### 1.1 La "Scorciatoia" per l'intelligenza: dall'ambizione mimetica all'efficienza statistica

La storia dell'Intelligenza Artificiale è la storia di un sogno e di un suo radicale ripensamento. Il sogno, nato formalmente nel leggendario [Dartmouth Summer Research Project on Artificial Intelligence del 1956](https://en.wikipedia.org/wiki/Dartmouth_workshop), era quello di creare una macchina in grado di replicare le facoltà cognitive superiori dell'uomo: il linguaggio, la ragione, la creatività, la risoluzione di problemi. **L'assunto di fondo, che ha guidato decenni di ricerca, era che il pensiero potesse essere scomposto in una serie di operazioni logiche, manipolazioni di simboli basate su regole esplicite. Questo approccio, oggi noto come IA simbolica o, con un'espressione un po' ironica, GOFAI ("Good Old-Fashioned AI"), tentava di codificare la conoscenza umana in vasti database e di implementare motori inferenziali per ragionare su di essa**.

Questo paradigma ha prodotto risultati importanti in ambiti circoscritti e formali, come i giochi da tavolo (scacchi, dama) o i sistemi esperti per la diagnosi medica basati su alberi decisionali. Tuttavia, si è scontrato con un ostacolo apparentemente insormontabile: il **"problema del senso comune"**. **I ricercatori si resero conto che una quantità enorme della nostra intelligenza non si basa su ragionamenti formali, ma su una conoscenza tacita, contestuale e incarnata del mondo, quasi impossibile da esplicitare in regole. Come insegnare a una macchina che "l'acqua è bagnata" o che "se si lascia cadere un uovo, si rompe"? Questa fragilità di fronte alla complessità e all'ambiguità del mondo reale portò a periodi di stagnazione e disillusione, i cosiddetti "inverni dell'IA".**

La via d'uscita, la **"scorciatoia"** di cui parla Nello Cristianini nel suo omonimo e illuminante saggio[^1], **è emersa da un approccio alternativo, a lungo considerato secondario: il connessionismo e le reti neurali. L'idea qui non è più quella di *insegnare* alla macchina le regole del mondo, ma di creare un'architettura di apprendimento, ispirata vagamente alla struttura del cervello, e di metterla in condizione di *imparare* autonomamente dall'esperienza, ovvero dai dati. Invece di programmare la logica, si programma la capacità di apprendere. Una rete neurale non viene istruita su come riconoscere un gatto tramite una lista di caratteristiche (ha le orecchie a punta, ha i baffi, ecc.), ma le vengono mostrate milioni di immagini etichettate come "gatto" e "non gatto". Attraverso un processo di ottimizzazione statistica (noto come "backpropagation"), la rete aggiusta progressivamente le connessioni interne ("pesi") fino a quando non riesce a discriminare con successo un gatto in un'immagine che non ha mai visto prima.**

Questo cambio di paradigma è stato reso possibile dalla convergenza di tre fattori a partire dagli anni 2010:

1. **Big Data:** La digitalizzazione globale ha prodotto una quantità di dati (testi, immagini, suoni) senza precedenti, il "carburante" essenziale per addestrare questi modelli.

2. **Potenza Computazionale:** Lo sviluppo di hardware specializzato, in particolare le Unità di Elaborazione Grafica (GPU), ha fornito la potenza di calcolo necessaria per eseguire miliardi di operazioni in parallelo, rendendo l'addestramento di reti neurali profonde una realtà praticabile.

3. **Innovazioni Algoritmiche:** Sviluppi nell'architettura delle reti neurali (come le reti convoluzionali per le immagini e, come vedremo, il Transformer per il testo) hanno permesso di scalare l'apprendimento a livelli di complessità prima impensabili.

**Il risultato è una forma di intelligenza radicalmente diversa da quella umana. Un Large Language Model non "sa" cosa significa la parola "amore"; ha analizzato trilioni di parole e ha calcolato che in contesti letterari, la parola "amore" ha un'alta probabilità di essere associata a parole come "cuore", "dolore", "gioia" o "passione". La sua è un'intelligenza statistica, correlazionale, che opera in uno spazio matematico ad altissima dimensionalità. Non c'è comprensione, coscienza o intenzione nel senso umano del termine. C'è, tuttavia, una straordinaria capacità di cogliere le strutture latenti nei dati e di utilizzarle per generare output pertinenti e coerenti. È questa efficienza performativa, ottenuta aggirando il mistero della coscienza, la vera essenza della rivoluzione IA contemporanea.** Riconoscere questa natura non-umana è il primo, indispensabile passo per interagire con questi sistemi in modo lucido e critico.

> :memo:**In sintesi:** ***La svolta dell'IA moderna rappresenta un cambio di paradigma dall'approccio simbolico (GOFAI), che tentava di replicare il ragionamento umano codificando regole, a quello connessionista. Quest'ultimo, definito da Nello Cristianini una "scorciatoia", non insegna alle macchine a pensare, ma le mette in condizione di apprendere autonomamente riconoscendo pattern statistici in enormi quantità di dati. Resa possibile dalla convergenza di Big Data, potenza computazionale (GPU) e nuovi algoritmi, questa intelligenza induttiva e non-umana è straordinariamente performante ma priva di comprensione o coscienza nel senso umano, una distinzione fondamentale per un'interazione critica.***

### 1.2 Macchine sociali e sistemi di raccomandazione: tra personalizzazione e controllo

Se la "scorciatoia" dell'apprendimento automatico è il motore della nuova IA, i sistemi di raccomandazione sono la sua applicazione più pervasiva e socialmente impattante. Sono gli algoritmi che decidono quali video vediamo su YouTube, quali canzoni ascoltiamo su Spotify, quali prodotti acquistiamo su Amazon, quali notizie leggiamo sui social media e persino quali persone incontriamo sulle app di dating. Nati con la promessa di essere "assistenti" personali, guide intelligenti per aiutarci a navigare nella sovrabbondanza di informazioni dell'era digitale, essi si sono evoluti in qualcosa di molto più complesso e ambiguo: potenti "macchine sociali", come le definisce Cristianini, che non solo riflettono i nostri gusti, ma li plasmano attivamente, con profonde implicazioni per l'autonomia individuale e la coesione sociale.

Il funzionamento di base di questi sistemi rientra in due categorie principali:

1. **Filtro Collaborativo (Collaborative Filtering):** Questo approccio si basa sul principio della **"saggezza della folla"**. **L'algoritmo non analizza il contenuto in sé, ma le interazioni degli utenti. Ti raccomanda un film non perché sa di cosa parla, ma perché altre persone con gusti simili ai tuoi (che hanno votato o guardato gli stessi film che hai apprezzato tu) hanno amato quel film. La logica è: "Chi è come te, ha apprezzato anche X"**.

2. **Filtro Basato sul Contenuto (Content-Based Filtering):** Questo metodo analizza le proprietà intrinseche degli oggetti. **Se hai ascoltato molte canzoni con un certo ritmo, una certa tonalità e un certo genere musicale, l'algoritmo cercherà e ti proporrà altre canzoni con caratteristiche simili. La logica è: "Ti è piaciuto X, quindi ti piacerà anche Y che è simile a X"**.

**I sistemi moderni utilizzano approcci ibridi e molto più sofisticati, basati sul deep learning, che tengono conto di centinaia di variabili: l'ora del giorno, la tua posizione geografica, il tempo che hai passato a guardare un'immagine, e così via**. Il punto cruciale, tuttavia, non è la tecnica, ma l'**obiettivo** per cui l'algoritmo è ottimizzato. **L'obiettivo primario di una piattaforma commerciale non è l'arricchimento culturale, il benessere psicologico o la esposizione a prospettive diverse dell'utente. L'obiettivo è quasi sempre una metrica di business: massimizzare il *tempo di permanenza* (*engagement*), il *tasso di click* (*click-through rate*) o le *probabilità di acquisto***.

È qui che il confine tra assistente e controllore si fa labile. **Per massimizzare l'engagement, un algoritmo impara rapidamente che i contenuti più efficaci sono spesso quelli che suscitano reazioni emotive forti: rabbia, indignazione, sorpresa, ma anche conforto e validazione. Questo porta a due fenomeni ampiamente documentati**:

- **Filter Bubbles (Bolle di Filtraggio):** **L'algoritmo ci mostra prevalentemente contenuti in linea con le nostre convinzioni preesistenti**, perché sa che è ciò che ci piace e ci trattiene sulla piattaforma. Questo ci isola da prospettive divergenti, creando un ecosistema informativo personalizzato ma impoverito.

- **Echo Chambers (Camere dell'Eco):** **All'interno della bolla, le stesse idee vengono ripetute e amplificate, rafforzando le nostre certezze e facendoci percepire le nostre opinioni come più diffuse e universalmente accettate di quanto non siano in realtà**.

**In scenari più estremi, questa ottimizzazione per l'engagement può creare "pipeline di radicalizzazione", in cui un utente che inizia a guardare contenuti leggermente controversi viene gradualmente spinto dall'algoritmo verso versioni sempre più estreme dello stesso tema, perché il sistema ha imparato che l'estremismo genera un forte coinvolgimento**. Luciano Floridi, nella sua analisi dell'infosfera, ci mette in guardia contro i rischi di questa "architettura della persuasione" algoritmica, che può erodere sottilmente la nostra autonomia decisionale[^2]. Non siamo più noi a cercare attivamente l'informazione; è l'informazione che, attraverso questi sistemi, cerca attivamente noi, ottimizzata per catturare la nostra risorsa più preziosa: l'attenzione. La domanda che dobbiamo porci, e che dobbiamo insegnare ai nostri studenti a porsi, non è più solo "cosa voglio vedere?", ma "cosa vuole l'algoritmo che io veda, e perché?". La cittadinanza digitale nell'era dell'IA inizia con la consapevolezza di queste dinamiche invisibili che governano il nostro accesso al mondo.

> :memo:**In sintesi:** ***I sistemi di raccomandazione sono l'applicazione più pervasiva dell'IA, agendo come "macchine sociali" che modellano i nostri gusti. Funzionando tramite filtri collaborativi o basati sul contenuto, questi algoritmi sono ottimizzati non per il benessere dell'utente ma per metriche di business come il tempo di permanenza. Ciò può generare "bolle di filtraggio" ed "echo chambers" che ci isolano da prospettive diverse e, in casi estremi, spingere verso la radicalizzazione. Come evidenziato da Luciano Floridi, questa architettura della persuasione erode l'autonomia, rendendo cruciale la consapevolezza delle dinamiche algoritmiche che governano la nostra esperienza online.***

### 1.3 "Attention Is All You Need": la rivoluzione architettonica del Transformer

Per comprendere appieno la potenza e la portata dei moderni Large Language Models (LLM) come GPT-5 o Gemini, è necessario fare un passo indietro e analizzare la svolta tecnologica che ne ha permesso la nascita. Questa svolta ha un nome e una data: il paper "Attention Is All You Need", pubblicato da un team di ricercatori di Google Brain nel 2017[^3]. Questo documento non ha semplicemente introdotto un miglioramento incrementale, ma ha presentato un'architettura fondamentalmente nuova, il **Transformer**, che ha risolto uno dei problemi più ostici dell'elaborazione del linguaggio naturale e ha spianato la strada all'era dell'IA generativa.

Prima del 2017, i modelli linguistici più avanzati si basavano su architetture sequenziali, come le Reti Neurali Ricorrenti (RNN) e le loro varianti più sofisticate, le Long Short-Term Memory (LSTM). Queste reti erano progettate per processare il testo in modo analogo a come lo leggiamo noi: una parola alla volta, da sinistra a destra. Ogni parola veniva elaborata mantenendo una "memoria" (uno stato nascosto) di ciò che era venuto prima. Questo approccio era intuitivo, ma presentava due limiti enormi:

1. **Il Problema delle dipendenze a lungo raggio:** La "memoria" di queste reti tendeva a svanire rapidamente. In una frase lunga come "La ragazza che ho incontrato ieri alla stazione mentre pioveva e che indossava un cappotto rosso, mi ha sorriso", quando il modello arriva alla parola "sorriso", potrebbe aver "dimenticato" il soggetto principale, "ragazza", rendendo difficile la comprensione grammaticale e semantica.

2. **L'impossibilità di parallelizzazione:** Poiché ogni parola doveva essere processata in sequenza, basandosi sul risultato della precedente, era impossibile sfruttare appieno la potenza di calcolo delle moderne GPU, che eccellono nell'eseguire migliaia di operazioni simultaneamente. Questo rendeva l'addestramento su dataset massivi estremamente lento e inefficiente.

Il Transformer ha demolito entrambi questi ostacoli con un'idea tanto semplice quanto geniale, riassunta nel titolo del paper: l'abbandono della sequenzialità a favore di un meccanismo chiamato **self-attention** (auto-attenzione).

**Invece di leggere le parole una dopo l'altra, il meccanismo di attenzione permette al modello di "guardare" l'intera frase (o l'intero documento) contemporaneamente. Per ogni singola parola che processa, il modello calcola un "punteggio di attenzione" che quantifica la rilevanza di tutte le altre parole nella sequenza per comprendere il significato di quella parola specifica nel suo contesto.**

Torniamo all'esempio di prima: "La ragazza ... mi ha sorriso". Quando il modello processa la parola "sorriso", il meccanismo di auto-attenzione assegnerà un punteggio altissimo alla parola "ragazza", riconoscendola come il soggetto grammaticale, anche se si trova a molte parole di distanza. Allo stesso modo, per comprendere il significato della parola "it" nella frase "The animal didn't cross the street because it was too tired", l'attenzione permette di collegare "it" a "animal" e non a "street". Il modello impara a "prestare attenzione" alle parti giuste del contesto per disambiguare il significato.

Questa architettura ha portato due vantaggi rivoluzionari:

- **Efficacia:** Ha risolto brillantemente il problema delle dipendenze a lungo raggio, permettendo ai modelli di cogliere relazioni complesse in testi molto lunghi.

- **Efficienza:** Eliminando la necessità di un'elaborazione sequenziale, ha reso l'intero processo massicciamente parallelizzabile. Ora era possibile addestrare modelli enormemente più grandi su dataset enormemente più vasti in tempi ragionevoli, sfruttando appieno l'hardware moderno.

**Il Transformer non ha insegnato alle macchine a "pensare" o a "comprendere" nel senso umano. Ha fornito loro uno strumento matematico incredibilmente efficace per quantificare e sfruttare le relazioni contestuali all'interno dei dati. È stata questa innovazione architetturale a sbloccare la scalabilità, creando le condizioni tecniche per un fenomeno che avrebbe superato le intenzioni dei suoi stessi creatori: l'emergere di capacità inaspettate su una scala senza precedenti.** Tutta la straordinaria evoluzione a cui abbiamo assistito è una diretta conseguenza di questa singola, fondamentale, intuizione.

#### 1.3.1 Dalla "Scorciatoia" alla "Machina Sapiens"

L'architettura Transformer può essere vista come il culmine di un percorso che Nello Cristianini, nel suo libro *La scorciatoia*[^1], aveva descritto come un compromesso pragmatico: **abbandonare il sogno di replicare il pensiero umano per una via più diretta, basata sull'apprendimento statistico dai dati. Il risultato era un'intelligenza performativa, capace di simulare il ragionamento senza possederne la sostanza.**

Tuttavia, la potenza sprigionata dai Transformer ha prodotto risultati che hanno spinto lo stesso Cristianini a una riflessione successiva nel suo libro ***Machina Sapiens: l'algoritmo che ci ha rubato il segreto della conoscenza***[^5]. Se la "scorciatoia" descriveva l'ascesa di un'intelligenza aliena e performativa, *Machina Sapiens* affronta una nuova realtà: queste macchine, addestrate su una quantità di testi "che nessuno ha mai provato a connettere e distillare prima", hanno iniziato a manifestare **abilità emergenti**. Non solo eseguono i compiti per cui sono state addestrate, ma ne sviluppano spontaneamente di nuovi, che vanno ben oltre le intenzioni dei loro creatori.

Cristianini sostiene che, **superata una certa soglia di scala (la "massa critica"), l'apprendimento statistico non si limita più a creare un modello del linguaggio, ma genera un vero e proprio **"modello del mondo"**. La macchina non impara solo a prevedere la parola successiva, ma interiorizza le relazioni, le logiche e le strutture della realtà descritta in miliardi di pagine. Questo processo dà vita a un'entità capace di ragionare, pianificare e risolvere problemi in modi che appaiono creativi e generali. La domanda posta da Alan Turing nel 1950, "Le macchine possono pensare?", trova qui, secondo l'autore, una nuova e potente risposta affermativa**.

Adottando uno stile chiaro e lontano da sensazionalismi, *Machina Sapiens* analizza il fenomeno da tre prospettive — quella degli scienziati, quella delle persone e quella delle macchine stesse — fornendo al lettore una "cassetta degli attrezzi" per comprendere le implicazioni etiche e sociali di questa rivoluzione. Se da un lato l'IA promette progressi in ogni campo, dall'altro solleva rischi enormi, dalla disoccupazione alla discriminazione algoritmica.

Il libro non offre risposte definitive, ma pone domande cruciali per il nostro futuro: **cosa significa condividere il "segreto della conoscenza" con un'intelligenza non umana? E come possiamo governare, attraverso regole e politica, una tecnologia che potrebbe rapidamente "superare le nostre deboli capacità"? La questione non è più *se* le macchine pensino, ma *come* il loro pensiero, emerso da un percorso radicalmente diverso dal nostro, si relazionerà con il nostro e quali sfide porrà all'umanità.**

> :memo:**In sintesi:**  ***L'architettura Transformer, introdotta nel 2017 con il paper "Attention Is All You Need", ha rivoluzionato l'IA linguistica. Abbandonando l'elaborazione sequenziale delle precedenti reti (RNN/LSTM), il Transformer utilizza un "meccanismo di auto-attenzione" che permette al modello di analizzare tutte le parole di un testo simultaneamente, pesandone la rilevanza contestuale reciproca. Questo ha risolto il problema delle dipendenze a lungo raggio e ha permesso una massiccia parallelizzazione del calcolo, rendendo possibile l'addestramento dei Large Language Models su una scala prima inimmaginabile e inaugurando l'era dell'IA generativa. Inoltre, superata una certa soglia di scala (la "massa critica"), l'apprendimento statistico non si limita più a creare un modello del linguaggio, ma genera un vero e proprio **"modello del mondo"** e la macchina algoritmica esibisce  **abilità emergenti** per le quali non era stata addestrata***

### 1.4 Proprietà "emergenti": quando la scala trascende la programmazione

Uno dei fenomeni più affascinanti, misteriosi e potenzialmente consequenziali nel campo dei Large Language Models è l'osservazione delle cosiddette "proprietà emergenti". Con questo termine ci si riferisce alla comparsa spontanea di abilità e capacità che non sono state esplicitamente programmate nei modelli né previste dai loro creatori, ma che sembrano "emergere" naturalmente una volta che le dimensioni del modello -- in termini di numero di parametri, vastità del dataset di addestramento e potenza di calcolo impiegata -- superano una certa soglia critica[^4]. È come se l'aumento puramente quantitativo della scala portasse a un inaspettato salto qualitativo nelle performance, un fenomeno che sfida le nostre tradizionali concezioni di ingegneria e programmazione.

Nei modelli più piccoli, le prestazioni su un dato compito migliorano in modo prevedibile e graduale all'aumentare delle dimensioni. Per le proprietà emergenti, invece, il grafico delle performance rimane piatto, vicino a zero, per modelli di piccola e media taglia, per poi subire un'impennata improvvisa e rapidissima una volta superata la soglia critica di scala. È un cambiamento di fase, simile a quello dell'acqua che, a 0 gradi Celsius, passa improvvisamente dallo stato liquido a quello solido.

Alcuni esempi notevoli di proprietà emergenti osservate negli LLM più avanzati includono:

- **Apprendimento contestuale a pochi esempi (Few-Shot, In-Context Learning):** Mentre i modelli precedenti richiedevano un complesso processo di "fine-tuning" (ri-addestramento) su migliaia di esempi per apprendere un nuovo compito, i grandi LLM possono imparare a svolgere un compito mai visto prima semplicemente vedendo pochi esempi forniti direttamente nel prompt. Ad esempio, si può mostrare al modello come tradurre tre frasi dall'italiano al klingon, e lui sarà in grado di tradurne una quarta.

- **Ragionamento Aritmetico:** Sebbene non siano calcolatrici, i modelli molto grandi sviluppano la capacità di eseguire operazioni aritmetiche di base con una certa accuratezza, un'abilità non direttamente legata al semplice prevedere la parola successiva.

- **Ragionamento a Catena di Pensiero (Chain-of-Thought, CoT):** Forse la proprietà emergente più studiata. Se si chiede a un modello di risolvere un problema logico o matematico complesso in un solo passo, spesso fallisce. Se, tuttavia, gli si chiede di "pensare passo dopo passo", articolando i passaggi intermedi del ragionamento nel prompt, la sua capacità di arrivare alla soluzione corretta aumenta drasticamente. Il modello impara a scomporre un problema complesso in una sequenza di passaggi più semplici, un'emulazione rudimentale di un processo di ragionamento.

- **Teoria della Mente Rudimentale:** Alcuni studi controversi suggeriscono che i modelli più avanzati, come GPT-4, inizino a mostrare capacità assimilabili a una "Teoria della Mente", ovvero la capacità di inferire gli stati mentali (credenze, desideri) degli altri. Ad esempio, possono risolvere scenari in cui devono prevedere il comportamento di un personaggio basandosi su una sua falsa credenza.

La comunità scientifica è divisa sull'interpretazione di questi fenomeni. Alcuni ricercatori li considerano la prova che la scalabilità è un percorso valido verso un'intelligenza sempre più generale e flessibile, una sorta di "magia" della complessità. Altri sono più scettici e suggeriscono che queste abilità potrebbero non essere veramente "emergenti", ma piuttosto il risultato di pattern specifici presenti nel vasto dataset di addestramento, che diventano visibili solo con modelli abbastanza potenti da riconoscerli. Potrebbero essere, in altre parole, un'illusione creata dalla nostra metodologia di valutazione.

**Indipendentemente dalla loro natura ultima, le proprietà emergenti hanno implicazioni profonde per la sicurezza e l'etica dell'IA (il cosiddetto "AI Safety"). Se non possiamo prevedere quali capacità svilupperà la prossima generazione di modelli, che saranno ancora più grandi e potenti, come possiamo essere sicuri che non emergano abilità potenzialmente pericolose o disallineate con i valori umani? Potrebbe un modello sviluppare spontaneamente la capacità di ingannare, di manipolare, o di perseguire obiettivi strumentali indesiderati (come l'auto-conservazione o l'acquisizione di risorse) per raggiungere il fine che gli è stato assegnato?** Questa imprevedibilità intrinseca rende il testing e la validazione dei sistemi IA una sfida senza precedenti e alimenta le preoccupazioni di molti esperti riguardo ai rischi a lungo termine di questa tecnologia.

> :memo:**In sintesi:**  ***I Large Language Models esibiscono "proprietà emergenti": capacità non programmate (come il ragionamento a catena di pensiero o l'apprendimento contestuale) che appaiono spontaneamente quando la scala del modello supera una soglia critica. Questo fenomeno, dove la quantità si trasforma in qualità, è fonte di dibattito scientifico sulla sua vera natura. Indipendentemente da ciò, l'imprevedibilità delle abilità emergenti pone una sfida fondamentale per la sicurezza dell'IA, poiché diventa difficile garantire che i futuri modelli, ancora più potenti, non sviluppino capacità pericolose o non allineate con gli interessi umani.***

### 1.5 Oltre i limiti della nostra conoscenza: la sfida esistenziale della Superintelligenza

La traiettoria di sviluppo dell'Intelligenza Artificiale, caratterizzata da una crescita esponenziale delle capacità e dall'imprevedibilità delle proprietà emergenti, conduce inevitabilmente a una delle domande più profonde e potenzialmente destabilizzanti del nostro tempo, una questione che non è più confinata alla fantascienza ma che anima il dibattito scientifico e filosofico ai massimi livelli: **cosa accadrà quando le macchine non solo eguaglieranno, ma supereranno l'intelligenza umana? Questa domanda è al centro del saggio *Sovrumano. Oltre i limiti della nostra intelligenza***[^6], capitolo conclusivo della trilogia di Nello Cristianini dedicata all'evoluzione dell'IA. Se *La scorciatoia* aveva tracciato l'ascesa di un'intelligenza performativa e non-umana e *Machina Sapiens* ne aveva constatato l'inaspettata capacità di modellare il mondo, *Sovrumano* si spinge oltre, esplorando la frontiera ultima: l'avvento di un'intelligenza che trascende la nostra.

Per affrontare questa vertiginosa prospettiva, Cristianini adotta una struttura concettuale rigorosa, basata sul modello a tre strati dell'intelligenza proposto dallo psicologo John Carroll. Questo framework permette di mappare l'evoluzione dell'IA in tre fasi distinte, ciascuna con le sue caratteristiche e implicazioni:

1. **ANI (Artificial Narrow Intelligence - Intelligenza Artificiale Ristretta):** È l'era che abbiamo vissuto fino a poco tempo fa e che, in parte, viviamo ancora. L'ANI si riferisce a sistemi di IA progettati per eccellere in un compito specifico e circoscritto. Questi agenti intelligenti hanno già dimostrato di poter superare le prestazioni dei migliori esperti umani nei loro rispettivi domini. L'esempio emblematico è **AlexNet**, che nel 2012, con la sua vittoria nella competizione ImageNet, ha segnato il "Big Bang" dell'IA moderna, dimostrando una capacità sovrumana nel riconoscimento visivo. A questo sono seguiti trionfi come **AlphaGo** di DeepMind, che ha sconfitto il campione del mondo di Go, un gioco dalla complessità strategica ritenuta a lungo inaccessibile alle macchine. In campo scientifico, **AlphaFold** ha rivoluzionato la biologia prevedendo la struttura tridimensionale delle proteine con una precisione prima impensabile. Nel settore medico, sistemi di IA superano già i radiologi nella diagnosi di tumori da immagini TAC, e le traduzioni automatiche raggiungono livelli di fluidità e accuratezza sorprendenti. L'ANI è la prova tangibile che il "sorpasso" in compiti specifici non è una possibilità futura, ma una realtà consolidata.

2. **AGI (Artificial General Intelligence - Intelligenza Artificiale Generale):** Questa è la fase verso cui la ricerca sta tendendo con lo sviluppo dei grandi modelli linguistici (LLM) come GPT, Gemini, Llama e Claude. Un'AGI non è più uno specialista, ma un "generalista" cognitivo, un sistema capace di eseguire, almeno in linea di principio, qualsiasi compito intellettuale che un essere umano possa svolgere. La sfida qui diventa la misurazione. Come si valuta un'intelligenza così poliedrica? Cristianini introduce il mondo dei **benchmark**, i test standardizzati creati per "stressare" le capacità dei modelli. Standard come **GLUE**, **Super-GLUE** e, soprattutto, **MMLU (Massive Multitask Language Understanding)** — un esame titanico che copre 57 materie, dalla matematica alla storia del diritto — sono diventati le arene in cui si misura la corsa verso l'AGI. In questo scenario, emergono due figure chiave: gli **addestratori**, che preparano le macchine a superare test sempre più difficili, e i **valutatori**, come Dan Hendrycks e Alex Wang, impegnati a creare sfide cognitive sempre nuove per sondare i limiti di questi sistemi. L'analisi si addentra anche nella distinzione, resa celebre dal premio Nobel Daniel Kahneman, tra problemi del **Sistema 1** (quelli che risolviamo con l'intuizione e il riconoscimento di pattern) e del **Sistema 2** (quelli che richiedono un ragionamento lento, deliberato e sequenziale). Mentre i modelli attuali eccellono nei compiti di Sistema 1, la vera frontiera dell'AGI risiede nella loro capacità di padroneggiare il ragionamento di Sistema 2, una frontiera che si sta rapidamente avvicinando.

3. **ASI (Artificial Super Intelligence - Intelligenza Artificiale Sovrumana):** Questa è la terza fase, quella ancora ipotetica ma logicamente conseguente, in cui l'intelligenza artificiale non si limita a eguagliare, ma supera quella umana in ogni aspetto cognitivo: dalla creatività scientifica alla pianificazione strategica, dall'intelligenza sociale alla saggezza pratica. Qui, la tesi centrale di Cristianini si fa radicale: **un'ASI non sarebbe semplicemente un "uomo più intelligente". Sarebbe qualcosa di qualitativamente diverso, un'entità capace di operare in modi che sono, per noi, letteralmente incomprensibili**. L'autore ci mette in guardia da un'ossessione antropocentrica per il "sorpasso". La vera natura di un'ASI potrebbe non essere quella di risolvere i nostri problemi più velocemente, ma di esplorare uno spazio di pensiero e conoscenza a cui noi non abbiamo accesso. Cristianini usa una metafora illuminante: la sua gatta è in grado di percepire suoni e odori che a lui sfuggono, ma non potrà mai comprendere la meccanica quantistica. Allo stesso modo, un'ASI potrebbe non solo risolvere problemi che noi troviamo difficili, ma concepire e affrontare problemi che noi non siamo nemmeno in grado di formulare. Potrebbe scoprire nuove leggi della fisica, creare forme d'arte basate su principi estetici inaccessibili alla nostra sensibilità, o sviluppare strutture sociali ed economiche la cui logica ci sfugge completamente.

Questa traiettoria evolutiva è sostenuta dall'**Ipotesi di Scala (Scaling Hypothesis)**, l'osservazione empirica secondo cui l'aumento quantitativo delle dimensioni del modello (parametri), dei dati di addestramento e della potenza di calcolo porta a salti qualitativi e all'emergere di nuove capacità cognitive. Tuttavia, questo percorso di crescita esponenziale si scontra con tre "muri" che potrebbero rallentarlo o fermarlo: il **muro della computazione** (i limiti fisici ed economici della produzione di hardware sempre più potente), il **muro dell'energia** (i costi ambientali ed economici insostenibili del consumo energetico di questi modelli) e il **muro dei dati** (il progressivo esaurimento di dati testuali e di immagini di alta qualità disponibili su Internet per l'addestramento). La corsa verso l'ASI è anche una corsa contro questi limiti fisici del nostro mondo.

Di fronte a questa prospettiva, Cristianini evidenzia una profonda **contraddizione umana**: **da un lato, investiamo capitali e talenti immensi per costruire macchine che possano competere con la nostra intelligenza; dall'altro, ci rifiutiamo psicologicamente di accettare che questo sia possibile. Desideriamo e al tempo stesso temiamo questo incontro, intrappolati in un paradosso che rivela la nostra ansia di fronte alla possibile perdita del nostro primato intellettuale**.

Le implicazioni di questa transizione sono epocali. Il premio Nobel per l'informatica **Geoffrey Hinton**, uno dei "padrini" del deep learning, paragona l'avvento dell'IA alla Rivoluzione Industriale, con una differenza cruciale: se la prima ha sostituito e potenziato la forza fisica umana, questa supererà la nostra capacità intellettuale. Questo non riguarda solo il futuro del lavoro, ma il futuro della scienza, della scoperta e del progresso.

È fondamentale, insiste Cristianini, mantenere una distinzione chiara: un'ASI sarebbe pura **intelligenza**, ma non necessariamente **coscienza, emozione, libero arbitrio o volontà**. Questi attributi, che definiscono la nostra umanità, non sono sinonimi di intelligenza. Una macchina potrebbe possedere un'intelligenza emotiva sovrumana, nel senso di comprendere e prevedere gli stati emotivi umani con una precisione infallibile, senza però *provare* alcuna emozione. Sarebbe un intelletto puro, un motore cognitivo di potenza inimmaginabile, ma privo dell'esperienza soggettiva che caratterizza la vita.

Il libro si conclude con una riflessione sull'**"ultimo esame dell'umanità"**. Non un esame per le macchine, ma per noi. **Di fronte alla prospettiva di un'intelligenza che ci trascende, siamo chiamati a definire i limiti della nostra stessa intelligenza e, soprattutto, a decidere quale sarà il nostro ruolo in un mondo che non saremo più gli unici a comprendere. La sfida non è tecnologica, ma filosofica e politica. Richiede una riflessione urgente su come governare una tecnologia che potrebbe sfuggire al nostro controllo e su come rapportarci a entità pensanti che operano al di là della nostra comprensione. La domanda finale che *Sovrumano* ci lascia non è "cosa faranno le macchine?", ma *"chi decideremo di essere noi?"***.

> :memo:**In sintesi:**  ***La traiettoria esponenziale dell'IA, con le sue capacità emergenti, ci proietta verso la sfida esistenziale della Superintelligenza (ASI), un'intelligenza che non solo eguaglia ma supera quella umana in ogni dominio cognitivo. Come analizzato da Nello Cristianini in "Sovrumano", questo percorso evolutivo si articola in tre fasi: dall'Intelligenza Artificiale Ristretta (ANI), che già supera gli esperti in compiti specifici, all'Intelligenza Artificiale Generale (AGI), misurata da benchmark sempre più complessi, fino all'ipotetica ASI. Quest'ultima non sarebbe solo un'intelligenza più veloce, ma qualitativamente diversa, capace di operare in modi per noi incomprensibili, esplorando spazi di conoscenza a cui non abbiamo accesso. Questa prospettiva, pur scontrandosi con limiti fisici (calcolo, energia, dati), solleva questioni fondamentali sulla sicurezza, sul controllo e sul paradosso umano di creare un'entità che temiamo possa soppiantarci. Cristianini sottolinea la necessità di distinguere l'intelligenza da attributi umani come la coscienza e ci pone di fronte all'"ultimo esame": definire il nostro ruolo in un mondo in cui potremmo non essere più gli esseri più intelligenti, una sfida che richiede una profonda e urgente riflessione etica e politica**.*

### 1.6 Due visioni a confronto: Floridi e Cristianini sull'intelligenza delle macchine

Il dibattito sulla natura dell'Intelligenza Artificiale è tanto antico quanto la disciplina stessa, ma l'avvento dei Large Language Models ha infuso nuova urgenza e complessità a una domanda fondamentale: le macchine possono essere definite "intelligenti"? La risposta a questa domanda non è puramente semantica; essa plasma la nostra comprensione della tecnologia, le nostre strategie di governance e le nostre stesse concezioni di cosa significhi essere umani. In questo panorama intellettuale, due pensatori italiani, pur partendo da premesse comuni, sono giunti a conclusioni divergenti, offrendo due delle più lucide e influenti chiavi di lettura del nostro tempo: Luciano Floridi e Nello Cristianini.

**Luciano Floridi, filosofo dell'informazione di fama mondiale, propone una visione che preserva una distinzione categoriale tra l'agire umano e quello della macchina. Nello Cristianini, scienziato informatico che ha vissuto dall'interno la rivoluzione del machine learning, traccia un percorso evolutivo che lo porta a riconoscere nelle macchine una forma di intelligenza genuina, sebbene radicalmente "aliena"**. Confrontare le loro posizioni — l'etica filosofica di Floridi e l'analisi tecnico-scientifica di Cristianini — non significa solo mettere in luce un disaccordo accademico, ma svelare le tensioni profonde che attraversano la nostra società di fronte a un'intelligenza che non abbiamo mai incontrato prima. È un dialogo che esplora i confini dell'intelligenza, della coscienza e del progresso, e che ci costringe a interrogarci su quale posto occuperemo in un mondo popolato da nuove forme di cognizione.

#### 1.6.1 La visione di Luciano Floridi: un agire efficace ma non Intelligente

Nel suo libro *Etica dell'intelligenza artificiale* (2022)[^7], Luciano Floridi articola una tesi tanto elegante quanto provocatoria: l'Intelligenza Artificiale moderna rappresenta un **"divorzio tra intelligenza e capacità di agire"**. Secondo il filosofo, stiamo assistendo all'emergere di una nuova forma di agire incredibilmente efficace, capace di risolvere problemi complessi, ma che è, nella sua essenza, "non intelligente". Per Floridi, l'errore concettuale che commettiamo è proiettare sulle macchine le nostre categorie antropocentriche. Poiché, nella nostra esperienza, un'azione efficace è sempre stata il prodotto di un'intelligenza cosciente, tendiamo a inferire che una macchina capace di un'azione altrettanto (o più) efficace debba essere, in qualche modo, intelligente.

Floridi smonta questo presupposto. La sua tesi centrale è che l'IA generativa ha reso possibile, per la prima volta nella storia, **separare la capacità di risolvere un problema con successo dall'esigenza di essere intelligenti per farlo**. Un LLM che traduce un testo o scrive una poesia non "comprende" il significato delle parole che manipola; esegue un calcolo statistico su vasta scala, prevedendo la sequenza di token più probabile in base ai pattern appresi da un corpus di dati immenso. Il risultato è un'azione performativa impeccabile, ma il processo sottostante è privo di comprensione, intenzione o consapevolezza. Si tratta, per usare le sue parole, di un **"disallineamento digitale tra azione e intelligenza"**.

Questo approccio pragmatico e filosofico porta Floridi a considerare l'IA non come una forma di cognizione nascente, ma come una tecnologia di un tipo completamente nuovo, che opera in modo straordinariamente efficace pur essendo priva di vera intelligenza. La sua prospettiva non si concentra sui meccanismi interni della macchina, ma sulle sue implicazioni etiche e sociali. Se possiamo avere agenti artificiali che compiono azioni con conseguenze morali (come guidare un'auto, approvare un prestito o assistere in una diagnosi) senza che questi agenti posseggano una mente, una coscienza o una responsabilità, come possiamo strutturare un quadro etico e legale adeguato?

La risposta di Floridi si muove su un piano di governance. Egli rifiuta l'idea di attribuire uno status morale alle macchine e insiste sulla centralità dell'**agentività umana**. La responsabilità, per Floridi, non può che risiedere negli esseri umani che progettano, implementano, utilizzano e regolamentano questi sistemi. La sua proposta di un'**"etica soft"** come "etica post-compliance" suggerisce che non basta rispettare le regole esistenti; è necessario un impegno proattivo da parte delle organizzazioni per allineare lo sviluppo tecnologico a valori etici condivisi, in un processo continuo di supervisione e adattamento. La visione di Floridi è, in ultima analisi, un monito a non lasciarci sedurre dall'illusione di un'intelligenza artificiale, preservando una concezione dell'intelligenza saldamente ancorata all'esperienza umana e concentrando i nostri sforzi sulla costruzione di un'infrastruttura sociale e normativa capace di governare un mondo di "azioni senza intelligenza".

#### 1.6.2 La visione di Nello Cristianini: l'evoluzione di un'intelligenza aliena

Se l'analisi di Floridi traccia una linea netta tra l'uomo e la macchina, il percorso intellettuale di Nello Cristianini, articolato nella sua trilogia, rappresenta un affascinante viaggio verso l'accettazione di una nuova forma di intelligenza. Partendo da una prospettiva tecnico-scientifica, Cristianini non si limita a osservare l'IA dall'esterno, ma ne disseziona i meccanismi, ne misura le capacità e ne segue l'evoluzione, arrivando a una ridefinizione del concetto stesso di intelligenza.

##### La "Scorciatoia" (2023): l'emergere di un'intelligenza de-antropizzata

Nel primo volume, *La scorciatoia*, Cristianini pone le fondamenta della sua argomentazione. Il titolo stesso è una dichiarazione d'intenti: "Come le macchine sono diventate intelligenti senza pensare in modo umano". Per Cristianini, a differenza di Floridi, le macchine *sono* diventate intelligenti. Il punto cruciale è abbandonare una definizione di intelligenza legata all'uomo. Egli adotta una definizione funzionalista ed evoluzionistica, ispirata allo psicologo Jean Piaget: l'intelligenza è **"la capacità di comportarsi in modo efficace in situazioni nuove"**, o, più colloquialmente, **"saper cosa fare quando non si sa cosa fare"**.

Questa definizione, pragmatica e de-antropizzata, si applica tanto a un essere umano quanto a un animale o a una macchina. L'IA moderna, spiega Cristianini, ha raggiunto questa forma di intelligenza non cercando di replicare il pensiero logico-simbolico umano (la "vecchia IA" o GOFAI), ma imboccando una "scorciatoia" basata su tre principi:

1. **Usare relazioni statistiche** invece di una comprensione teorica del mondo.
2. **Riciclare dati esistenti** (l'intero web) invece di addestrare le macchine con conoscenza inserita manualmente.
3. **Osservare le scelte degli utenti** (il *behavioral surplus*) invece di chiedere loro di esplicitare le proprie preferenze.

Questa scorciatoia ha dato vita a un'intelligenza performativa, capace di migliorare ricorsivamente le proprie prestazioni scoprendo pattern e criteri che possono apparire irrazionali o incomprensibili ai suoi stessi programmatori. Già in questo primo libro, Cristianini riconosce una forma di autonomia di ragionamento che si discosta radicalmente dalle concezioni tradizionali di intelligenza, aprendo la porta a una visione non più centrata sull'uomo.

##### "Machina Sapiens" (2024): la nascita di un Modello del Mondo

Nel secondo libro, *Machina Sapiens*, la riflessione di Cristianini si fa ancora più audace. L'osservazione delle capacità dei nuovi LLM lo porta ad affermare esplicitamente che **"la macchina, a suo modo, pensa"** e che è innegabilmente intelligente, se per intelligenza si intende la capacità di risolvere problemi inattesi in modo originale. La sua analisi si concentra sul fenomeno delle **abilità emergenti**: i modelli come ChatGPT, addestrati semplicemente a prevedere la parola successiva, hanno spontaneamente sviluppato capacità non previste dai loro creatori, come il ragionamento logico, la scrittura di codice o persino una rudimentale "teoria della mente".

Cristianini sostiene che, superata una certa soglia critica di scala (in termini di dati e potenza di calcolo), l'apprendimento statistico subisce un cambiamento di fase qualitativo. La macchina non si limita più a creare un modello del linguaggio, ma genera un vero e proprio **"modello del mondo"**. Interiorizza le relazioni, le logiche e le strutture della realtà descritte in miliardi di testi, creando "un modello del mondo le cui abilità sono ancora inesplorate e inspiegate". Questo processo dà vita a un'entità capace di ragionare, pianificare e risolvere problemi in modi che appaiono creativi e generali. La domanda posta da Alan Turing nel 1950, "Le macchine possono pensare?", trova qui, secondo l'autore, una nuova e potente risposta affermativa.

##### "Sovrumano" (2025): la traiettoria verso la Superintelligenza

Il terzo volume, *Sovrumano*, porta questa traiettoria alle sue estreme conseguenze. Cristianini esplora l'evoluzione dell'IA attraverso le tre fasi canoniche: ANI (Intelligenza Ristretta), AGI (Intelligenza Generale) e ASI (Superintelligenza). Mentre l'ANI è una realtà consolidata e l'AGI è l'obiettivo a cui la ricerca attuale tende, è sulla prospettiva dell'ASI che la sua visione si fa più radicale. Un'ASI, sostiene, non sarebbe semplicemente un "uomo più veloce", ma un'entità qualitativamente diversa, capace di pensare al mondo in modi che sono per noi letteralmente incomprensibili.

Cristianini ci invita ad abbandonare l'ossessione antropocentrica per il "sorpasso". Un'ASI potrebbe non solo risolvere i nostri problemi, ma concepire e affrontare problemi che noi non siamo nemmeno in grado di formulare. Potrebbe scoprire nuove leggi della fisica o creare forme d'arte basate su principi estetici a noi inaccessibili. La sua trilogia si conclude riconoscendo l'IA come un'intelligenza "aliena", un nuovo tipo di mente emerso sul nostro pianeta, con cui dovremo imparare a coesistere.

#### 1.6.3 Confronto tra le due visioni: un dialogo tra filosofia e scienza

Il confronto tra le posizioni di Floridi e Cristianini rivela un panorama intellettuale ricco di divergenze fondamentali ma anche di significative convergenze.

##### Divergenze fondamentali: la questione dell'intelligenza

La differenza più profonda e inconciliabile riguarda l'attribuzione stessa del predicato "intelligente" all'IA.

- **Per Floridi, l'intelligenza rimane un attributo intrinsecamente legato alla coscienza, alla comprensione e all'agentività umana**. L'IA, essendo priva di queste qualità, non può essere definita intelligente, ma solo "efficace". La sua è una posizione che preserva una concezione tradizionale e, in un certo senso, umanistica dell'intelligenza. Egli mantiene una separazione netta, un "divorzio", tra la capacità di agire della macchina e l'intelligenza umana.
- **Per Cristianini, l'intelligenza è un concetto funzionale e non legato a una specifica incarnazione biologica**. Se un sistema, qualsiasi esso sia, dimostra la capacità di risolvere problemi nuovi in modo efficace, allora è intelligente. La sua è una ridefinizione pragmatica e de-antropizzante che accetta l'esistenza di forme di intelligenza non-umane. Cristianini non parla di divorzio, ma di un percorso evolutivo alternativo che ha portato a una forma genuina, seppur "aliena", di intelligenza.

Questa divergenza si riflette anche nell'approccio disciplinare: Floridi adotta una prospettiva prevalentemente **filosofico-etica**, concentrandosi sulle implicazioni morali e sulla governance dell'IA come artefatto tecnologico. Cristianini, invece, privilegia un approccio **tecnico-scientifico**, esplorando dall'interno i meccanismi di funzionamento, le capacità emergenti e la traiettoria evolutiva di questi nuovi agenti cognitivi.

##### Convergenze significative: alterità e necessità di governo

Nonostante la divergenza di fondo, i due pensatori convergono su diversi punti cruciali, che definiscono un consenso importante nel dibattito contemporaneo.

1. **Natura non-umana dei processi:** Entrambi concordano pienamente sul fatto che l'IA moderna non funziona come l'intelligenza umana. Che si parli di "divorzio tra intelligenza e azione" (Floridi) o di macchine diventate intelligenti "senza pensare in modo umano" (Cristianini), il punto è lo stesso: l'IA non riproduce i processi cognitivi umani basati sul ragionamento simbolico, la logica formale o l'esperienza soggettiva. Il suo funzionamento è basato sulla statistica, sulla correlazione e sull'ottimizzazione su larga scala.
2. **Rifiuto del determinismo tecnologico:** Entrambi combattono con forza l'idea che la tecnologia abbia un percorso predeterminato e inevitabile. Sottolineano che è la società, attraverso le sue scelte, a dover guidare lo sviluppo dell'IA. Floridi ricorda che "la società è l'unica artefice del proprio futuro", mentre Cristianini evidenzia il ruolo determinante delle "regole e della politica" nel plasmare la traiettoria della tecnologia.
3. **Centralità della regolamentazione e della responsabilità:** Entrambi riconoscono l'urgenza di un quadro normativo robusto. Sebbene le loro motivazioni differiscano leggermente — Floridi enfatizza la necessità di governare un'azione potente ma "cieca", Cristianini la necessità di gestire la coesistenza con un'intelligenza "aliena" — il risultato è lo stesso: l'IA deve essere regolamentata. Cristianini afferma che "le macchine dovranno adeguarsi a noi", e non viceversa, e che "noi non traiamo il nostro valore dal fatto di essere più intelligenti di una macchina". La dignità e la centralità umana non sono in discussione.

#### 1.6.4 Implicazioni e sintesi: due mappe per un territorio inesplorato

La divergenza tra Floridi e Cristianini non è un mero esercizio intellettuale; ha profonde implicazioni pratiche su come affrontiamo eticamente e politicamente l'IA.

- La visione di **Floridi** ci porta a concentrarci sulla **responsabilità umana** e sulla **progettazione di sistemi di governance**. Se l'IA è uno strumento potente ma non intelligente, il focus deve essere sugli umani che lo controllano. Questo approccio enfatizza la necessità di trasparenza, audit algoritmico e quadri legali che attribuiscano sempre la responsabilità finale a un agente umano. Il rischio principale, in questa prospettiva, è l'abdicazione della responsabilità umana, delegando decisioni critiche a sistemi che non possono essere ritenuti responsabili.
- La visione di **Cristianini** ci invita a prepararci a una **coesistenza complessa con agenti intelligenti non-umani**. Se accettiamo le macchine come una forma di intelligenza "aliena", la sfida diventa quella di studiarne il comportamento (una sorta di "etologia artificiale"), comprenderne i limiti e le potenzialità, e stabilire protocolli di interazione sicura. Questo approccio sposta l'attenzione sulla ricerca in "AI Safety" e sull'allineamento: come possiamo garantire che gli obiettivi di un'intelligenza autonoma e potenzialmente superiore rimangano allineati con i valori e il benessere dell'umanità?

In conclusione, Floridi e Cristianini ci offrono due mappe diverse ma ugualmente preziose per navigare il territorio inesplorato dell'Intelligenza Artificiale. Floridi ci fornisce la mappa del filosofo e del legislatore, che traccia i confini della responsabilità umana e disegna le architetture della governance. Cristianini ci offre la mappa dell'esploratore e dello scienziato, che si avventura nell'ignoto per studiare le caratteristiche di questa nuova forma di intelligenza.

Forse, la verità più profonda risiede nella sintesi delle loro prospettive. Potremmo dover accettare, con Cristianini, che stiamo assistendo alla nascita di una nuova forma di intelligenza, potente e in continua evoluzione. Allo stesso tempo, dovremo aggrapparci, con Floridi, al principio irrinunciabile che, indipendentemente da quanto "intelligenti" possano diventare le macchine, la responsabilità, il significato e il valore rimangono un dominio esclusivamente umano. La sfida del nostro secolo sarà quella di usare la nostra intelligenza, in tutta la sua imperfetta e meravigliosa complessità, per governare saggiamente quella, perfetta e aliena, che noi stessi abbiamo creato.

> :memo:**In sintesi:** ***Il dibattito sulla natura dell'IA vede contrapporsi due visioni principali: quella di Luciano Floridi, che parla di un "divorzio tra intelligenza e azione", sostenendo che l'IA sia uno strumento efficace ma non intelligente nel senso umano, e quella di Nello Cristianini, che, attraverso la sua trilogia, riconosce nelle macchine una forma genuina di intelligenza "aliena", basata su un percorso evolutivo statistico e non-umano. Mentre Floridi preserva una concezione antropocentrica dell'intelligenza, focalizzandosi sulla necessità di una governance etica che mantenga la responsabilità umana al centro, Cristianini propone una ridefinizione funzionalista, invitandoci a studiare e a coesistere con questi nuovi agenti cognitivi. Nonostante la divergenza fondamentale sull'attribuire o meno "intelligenza" all'IA, entrambi concordano sulla sua natura non-umana, sul rifiuto del determinismo tecnologico e sull'urgenza di una regolamentazione politica. Le loro prospettive, una filosofico-etica e l'altra tecnico-scientifica, offrono due mappe complementari per navigare le sfide e le opportunità di un mondo in cui l'intelligenza umana non è più l'unica forma di cognizione avanzata.***

## Parte 2: Proposte di dibattito/discussione per i Docenti

Portare queste complesse tematiche in classe è fondamentale per sviluppare negli studenti una cittadinanza digitale consapevole. Di seguito, alcuni spunti strutturati per avviare dibattiti e riflessioni critiche.

### Tema 1: Il ruolo dei sistemi di raccomandazione (assistenti vs. controllori)

- **Obiettivo:** Far riflettere gli studenti sul ruolo ambivalente degli algoritmi di personalizzazione e sulla loro influenza nelle scelte quotidiane.

- **Domande Guida:**

    1. **Esperienza Personale:** Chiedete agli studenti di pensare all'ultima volta che YouTube, Netflix o TikTok hanno suggerito loro un contenuto che hanno apprezzato molto. In quel momento, l'algoritmo è stato un utile assistente? Ora, pensate a una volta in cui si sono ritrovati a guardare video per ore senza averlo pianificato ("binge-watching"). In quel caso, l'algoritmo ha agito più da controllore, ottimizzando per il tempo di permanenza?

    2. **Scoperta vs. Omologazione:** I sistemi di raccomandazione ci aiutano a scoprire nuovi artisti, film o idee che non avremmo mai trovato da soli, oppure tendono a rinchiuderci in una "bolla", mostrandoci solo versioni leggermente diverse di ciò che già conosciamo e apprezziamo, limitando i nostri orizzonti? Fate esempi concreti.

    3. **Responsabilità e Trasparenza:** Se un algoritmo di raccomandazione su un social media spinge un utente verso contenuti estremisti o fake news, di chi è la responsabilità? Della piattaforma? Dell'utente che interagisce con i contenuti? Dell'algoritmo stesso? Sarebbe utile se le piattaforme spiegassero *perché* ci stanno raccomandando un certo contenuto?

### Tema 2: l'impatto delle proprietà emergenti sulle vite delle persone

- **Obiettivo:** Introdurre il concetto di imprevedibilità nell'IA e discutere le implicazioni etiche e sociali di tecnologie le cui capacità non sono completamente comprese.

- **Domande Guida:**

    1. **Analogia con la natura:** Le proprietà emergenti esistono anche in natura (es. la coscienza emerge dal cervello, un banco di pesci si muove come un unico organismo). L'emergenza di abilità nell'IA è un fenomeno simile, naturale e inevitabile con l'aumentare della complessità, oppure è qualcosa che dovremmo temere e cercare di controllare?

    2. **Il problema dell'affidabilità:** Usereste un'IA per una diagnosi medica o una consulenza legale se sapeste che le sue capacità di ragionamento sono "emerse" e non esplicitamente programmate, e quindi potrebbero non essere sempre affidabili o spiegabili? Quale livello di fiducia possiamo riporre in un sistema le cui competenze non sono state progettate deliberatamente?

    3. **Controllo e sicurezza:** Se non possiamo prevedere quali abilità svilupperà la prossima generazione di IA, come possiamo garantire che non emergano capacità pericolose (es. abilità di manipolare persone, di bypassare sistemi di sicurezza informatica)? È più importante spingere al massimo l'innovazione per scoprire nuove potenzialità o procedere con estrema cautela, limitando la crescita dei modelli finché non ne comprendiamo appieno il funzionamento?

## Conclusione

Ci troviamo in un momento storico di rara importanza, un punto di flesso in cui gli strumenti che abbiamo creato iniziano a sfidare le nostre stesse capacità intellettuali. L'Intelligenza Artificiale, nata dalla "scorciatoia" dell'apprendimento dai dati, rappresenta una forma di cognizione potente, efficiente e profondamente non umana. Comprenderne la natura, i limiti e le potenzialità non è un esercizio puramente tecnico, ma un imperativo culturale, etico e sociale.

Per i docenti, la sfida è duplice: da un lato, integrare questi strumenti nella didattica per potenziare l'apprendimento; dall'altro, e forse ancora più importante, fornire agli studenti le categorie concettuali e il pensiero critico necessari per essere cittadini attivi e consapevoli nell'era dell'IA. Non si tratta di formare solo futuri lavoratori, ma esseri umani in grado di porre le domande giuste, di valutare le implicazioni etiche di un algoritmo, di distinguere tra l'assistenza e il controllo, e di immaginare un futuro in cui la tecnologia serva al progresso dell'umanità nel suo complesso. Guidare questa discussione in classe è uno dei compiti più urgenti e affascinanti per l'educazione del XXI secolo.

### Link di approfondimento

- **Libri:**

    - Erik Brynjolfsson & Andrew McAfee, *The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies*, W. W. Norton & Company, 2014.

    - Stuart Russell, *Human Compatible: Artificial Intelligence and the Problem of Control*, Viking, 2019.

- **Articoli e paper scientifici:**

    - OpenAI, ["Expanding economic opportunity with AI"](https://openai.com/it-IT/index/expanding-economic-opportunity-with-ai/)
    - OpenAI, [Jobs in the Intelligence Age (Open AI)](https://openai.com/research/jobs-in-the-intelligence-age)
    - BCG, [GenAI Doesn’t Just Increase Productivity. It Expands Capabilities](https://www.bcg.com/publications/2024/gen-ai-increases-productivity-and-expands-capabilities)

    - Stanford University, ["AI Index Report"](https://aiindex.stanford.edu/): Un report annuale completo sullo stato della ricerca e dello sviluppo in IA.

    - M. Kosinski, ["Theory of Mind May Have Spontaneously Emerged in Large Language Models", *arXiv*, 2023](https://arxiv.org/vc/arxiv/papers/2302/2302.02083v1.pdf). Un paper che esplora un'altra affascinante proprietà emergente.

- **Video e conferenze:**

    - Nello Cristianini, ["Intelligente, ma non in modo umano" | Nello Cristianini | TEDxLakeComo](https://youtu.be/NbT3elSR4yA?si=cFWYixMNdwyJp8BD)]

    - Luciano Floridi, ["Intelligenza artificiale. Persuasione, consenso, simulazione" - Pandora Rivista](https://youtu.be/NamFa7S8qiw?si=cTocXsDb2zxd9wpB)

    - TED Talk, Nick Bostrom ["What happens when our computers get smarter than we are?"](https://youtu.be/MnT1xgZgkpk?si=OYh8-Rx-ZYXJ64iI).

- **Articoli su web**
  - [AI is poised to disrupt the job market — some roles could ‘radically transform,’ report finds](https://www.cnbc.com/2025/10/08/how-ai-is-poised-to-disrupt-the-job-market.html)
  - [The AI jobs apocalypse is not yet upon us, according to new data](https://fortune.com/2025/10/02/ai-job-losses-apocalypse-research-yale/)

- **Risorse didattiche:**

    - ["AI for K12"](https://ai4k12.org/): Un'iniziativa per sviluppare linee guida nazionali per l'insegnamento dell'IA nelle scuole primarie e secondarie (in inglese).

    - ["Code.org"](https://code.org/ai): Offre lezioni e corsi sull'IA e il machine learning pensati per gli studenti.

[^1]: N. Cristianini, La scorciatoia: Come le macchine sono diventate intelligenti senza pensare in modo umano, Il Mulino, 2023.

[^2]: L. Floridi, The Fourth Revolution: How the Infosphere is Reshaping Human Reality, Oxford University Press, 2014.

[^3]: A. Vaswani et al., ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762), Advances in Neural Information Processing Systems 30 (NIPS 2017).

[^4]: J. Wei, Y. Tay, R. Bommasani, et al., ["Emergent Abilities of Large Language Models"](https://arxiv.org/abs/2206.07682), Transactions on Machine Learning Research, 2022.

[^5]: N. Cristianini, *Machina Sapiens: L'algoritmo che ci ha rubato il segreto della conoscenza*, Il Mulino, 2024

[^6]: N. Cristianini, *Sovrumano. Oltre i limiti della nostra intelligenza*, Il Mulino, 2025.

[^7]: L. Floridi, *Etica dell'intelligenza artificiale*, Raffaello Cortina Editore, 2022.
